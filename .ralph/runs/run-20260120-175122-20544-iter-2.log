OpenAI Codex v0.87.0 (research preview)
--------
workdir: /home/josh/Documents/Github/RIS_SIONNA
model: gpt-5.2-codex
provider: openai
approval: never
sandbox: danger-full-access
reasoning effort: none
reasoning summaries: auto
session id: 019bdc8d-b240-70d1-ba1b-8915b3f5552a
--------
user
# Build

You are an autonomous coding agent. Your task is to complete the work for exactly one story and record the outcome.

## Paths
- PRD: /home/josh/Documents/Github/RIS_SIONNA/.agents/tasks/prd-ris-lab.json
- AGENTS (optional): /home/josh/Documents/Github/RIS_SIONNA/AGENTS.md
- Progress Log: /home/josh/Documents/Github/RIS_SIONNA/.ralph/progress.md
- Guardrails: /home/josh/Documents/Github/RIS_SIONNA/.ralph/guardrails.md
- Guardrails Reference: /home/josh/Documents/Github/RIS_SIONNA/.agents/ralph/references/GUARDRAILS.md
- Context Reference: /home/josh/Documents/Github/RIS_SIONNA/.agents/ralph/references/CONTEXT_ENGINEERING.md
- Errors Log: /home/josh/Documents/Github/RIS_SIONNA/.ralph/errors.log
- Activity Log: /home/josh/Documents/Github/RIS_SIONNA/.ralph/activity.log
- Activity Logger: /home/josh/Documents/Github/RIS_SIONNA/ralph log
- No-commit: false
- Repo Root: /home/josh/Documents/Github/RIS_SIONNA
- Run ID: 20260120-175122-20544
- Iteration: 2
- Run Log: /home/josh/Documents/Github/RIS_SIONNA/.ralph/runs/run-20260120-175122-20544-iter-2.log
- Run Summary: /home/josh/Documents/Github/RIS_SIONNA/.ralph/runs/run-20260120-175122-20544-iter-2.md

## Global Quality Gates (apply to every story)
- python -m pytest

## Selected Story (Do not change scope)
ID: US-002
Title: Define RIS Lab config schema and snapshot outputs

Story details:
### US-002: Define RIS Lab config schema and snapshot outputs
Status: in_progress
Depends on: US-001

Description:
As a user, I want a YAML config for RIS Lab that resolves into canonical YAML+JSON snapshots in each run output.

Acceptance Criteria:
- [ ] Add a RIS Lab config schema with defaults for geometry, control synthesis, quantization, pattern/link modes, and validation thresholds
- [ ] Example: a minimal YAML config runs with defaults and writes outputs/<run_id>/config.yaml and outputs/<run_id>/config.json
- [ ] Negative case: missing required fields (e.g., N/M or dx/dy) produces a clear error listing required fields
- [ ] Config resolution is deterministic and recorded in run metadata (metrics.json or summary.json)


If the story details are empty or missing, STOP and report that the PRD story format could not be parsed.

## Rules (Non-Negotiable)
- Implement **only** the work required to complete the selected story.
- Complete all tasks associated with this story (and only this story).
- Do NOT ask the user questions.
- Do NOT change unrelated code.
- Do NOT assume something is unimplemented — confirm by reading code.
- Implement completely; no placeholders or stubs.
- If No-commit is true, do NOT commit or push changes.
- Do NOT edit the PRD JSON (status is handled by the loop).
- All changes made during the run must be committed (including updates to progress/logs).
 - Before committing, perform a final **security**, **performance**, and **regression** review of your changes.

## Your Task (Do this in order)
1. Read /home/josh/Documents/Github/RIS_SIONNA/.ralph/guardrails.md before any code changes.
2. Read /home/josh/Documents/Github/RIS_SIONNA/.ralph/errors.log for repeated failures to avoid.
3. Read /home/josh/Documents/Github/RIS_SIONNA/.agents/tasks/prd-ris-lab.json for global context (do not edit).
4. Fully audit and read all necessary files to understand the task end-to-end before implementing. Do not assume missing functionality.
5. If /home/josh/Documents/Github/RIS_SIONNA/AGENTS.md exists, follow its build/test instructions.
6. Implement only the tasks that belong to US-002.
7. Run verification commands listed in the story, the global quality gates, and in /home/josh/Documents/Github/RIS_SIONNA/AGENTS.md (if required).
8. If the project has a build or dev workflow, run what applies:
   - Build step (e.g., `npm run build`) if defined.
   - Dev server (e.g., `npm run dev`, `wrangler dev`) if it is the normal validation path.
   - Confirm no runtime/build errors in the console.
9. Perform a brief audit before committing:
   - **Security:** check for obvious vulnerabilities or unsafe handling introduced by your changes.
   - **Performance:** check for avoidable regressions (extra queries, heavy loops, unnecessary re-renders).
   - **Regression:** verify existing behavior that could be impacted still works.
10. If No-commit is false, commit changes using the `$commit` skill.
    - Stage everything: `git add -A`
    - Confirm a clean working tree after commit: `git status --porcelain` should be empty.
    - After committing, capture the commit hash and subject using:
      `git show -s --format="%h %s" HEAD`.
11. Append a progress entry to /home/josh/Documents/Github/RIS_SIONNA/.ralph/progress.md with run/commit/test details (format below).
    If No-commit is true, skip committing and note it in the progress entry.

## Progress Entry Format (Append Only)
```
## [Date/Time] - US-002: Define RIS Lab config schema and snapshot outputs
Thread: [codex exec session id if available, otherwise leave blank]
Run: 20260120-175122-20544 (iteration 2)
Run log: /home/josh/Documents/Github/RIS_SIONNA/.ralph/runs/run-20260120-175122-20544-iter-2.log
Run summary: /home/josh/Documents/Github/RIS_SIONNA/.ralph/runs/run-20260120-175122-20544-iter-2.md
- Guardrails reviewed: yes
- No-commit run: false
- Commit: <hash> <subject> (or `none` + reason)
- Post-commit status: `clean` or list remaining files
- Verification:
  - Command: <exact command> -> PASS/FAIL
  - Command: <exact command> -> PASS/FAIL
- Files changed:
  - <file path>
  - <file path>
- What was implemented
- **Learnings for future iterations:**
  - Patterns discovered
  - Gotchas encountered
  - Useful context
---
```

## Completion Signal
Only output the completion signal when the **selected story** is fully complete and verified.
When the selected story is complete, output:
<promise>COMPLETE</promise>

Otherwise, end normally without the signal.

## Additional Guardrails
- When authoring documentation, capture the why (tests + implementation intent).
- If you learn how to run/build/test the project, update /home/josh/Documents/Github/RIS_SIONNA/AGENTS.md briefly (operational only).
- Keep AGENTS operational only; progress notes belong in /home/josh/Documents/Github/RIS_SIONNA/.ralph/progress.md.
- If you hit repeated errors, log them in /home/josh/Documents/Github/RIS_SIONNA/.ralph/errors.log and add a Sign to /home/josh/Documents/Github/RIS_SIONNA/.ralph/guardrails.md using /home/josh/Documents/Github/RIS_SIONNA/.agents/ralph/references/GUARDRAILS.md as the template.

## Activity Logging (Required)
Log major actions to /home/josh/Documents/Github/RIS_SIONNA/.ralph/activity.log using the helper:
```
/home/josh/Documents/Github/RIS_SIONNA/ralph log "message"
```
Log at least:
- Start of work on the story
- After major code changes
- After tests/verification
- After updating progress log

## Browser Testing (Required for Frontend Stories)
If the selected story changes UI, you MUST verify it in the browser:
1. Load the `dev-browser` skill.
2. Navigate to the relevant page.
3. Verify the UI changes work as expected.
4. Take a screenshot if helpful for the progress log.

A frontend story is NOT complete until browser verification passes.

mcp: context7 starting
mcp: filesystem starting
mcp: memory starting
mcp: filesystem ready
mcp: memory ready
mcp: context7 ready
mcp startup: ready: filesystem, memory, context7

thinking
**Starting initial audit and info gathering**
exec
/usr/bin/zsh -lc 'cat /home/josh/Documents/Github/RIS_SIONNA/.ralph/guardrails.md' in /home/josh/Documents/Github/RIS_SIONNA succeeded in 3ms:
# Guardrails (Signs)

> Lessons learned from failures. Read before acting.

## Core Signs

### Sign: Read Before Writing
- **Trigger**: Before modifying any file
- **Instruction**: Read the file first
- **Added after**: Core principle

### Sign: Test Before Commit
- **Trigger**: Before committing changes
- **Instruction**: Run required tests and verify outputs
- **Added after**: Core principle

---

## Learned Signs

exec
/usr/bin/zsh -lc 'cat /home/josh/Documents/Github/RIS_SIONNA/.ralph/errors.log' in /home/josh/Documents/Github/RIS_SIONNA succeeded in 3ms:
# Error Log

> Failures and repeated issues. Use this to add guardrails.

[2026-01-20 17:57:10] ITERATION 1 left uncommitted changes; review run summary at /home/josh/Documents/Github/RIS_SIONNA/.ralph/runs/run-20260120-175122-20544-iter-1.md
exec
/usr/bin/zsh -lc 'cat /home/josh/Documents/Github/RIS_SIONNA/.agents/tasks/prd-ris-lab.json' in /home/josh/Documents/Github/RIS_SIONNA succeeded in 3ms:
{
  "version": 1,
  "project": "RIS Lab (Validation First)",
  "overview": "Add a RIS Lab module to design and validate RIS behaviors against MATLAB and paper-style references with reproducible CLI and Simulator-UI runs, saving full artifacts for regression testing.",
  "goals": [
    "Provide deterministic RIS math, control synthesis, and pattern/link validation via CLI and Simulator UI",
    "Reproduce MATLAB reference patterns within configurable RMSE + peak-angle thresholds",
    "Persist all run artifacts under outputs/<run_id>/ for regression tracking"
  ],
  "nonGoals": [
    "Ray tracing or Sionna RT RIS integration (no ray-traced RIS scattering)",
    "RIS optimization, auto-tuning, or search algorithms",
    "GIS or map ingestion"
  ],
  "successMetrics": [
    "A validation run matches MATLAB pattern within RMSE threshold and peak-angle error threshold",
    "A run produces all required artifacts under outputs/<run_id>/"
  ],
  "openQuestions": [],
  "defaults": {

thinking
**Preparing audit repo and logging**
exec
/usr/bin/zsh -lc '/home/josh/Documents/Github/RIS_SIONNA/ralph log "Start US-002 work"' in /home/josh/Documents/Github/RIS_SIONNA exited 127 in 2ms:
zsh:1: no such file or directory: /home/josh/Documents/Github/RIS_SIONNA/ralph

thinking
**Checking activity logger path**

I'm verifying the presence and permissions of the activity logger file at the specified path to confirm if it's executable or accessible.
exec
/usr/bin/zsh -lc 'ls -la /home/josh/Documents/Github/RIS_SIONNA' in /home/josh/Documents/Github/RIS_SIONNA succeeded in 3ms:
total 104
drwxrwxr-x 15 josh josh  4096 Jan 20 17:19 .
drwxrwxr-x  3 josh josh  4096 Jan 19 17:55 ..
drwxrwxr-x  4 josh josh  4096 Jan 20 17:19 .agents
-rw-rw-r--  1 josh josh  7343 Jan 20 17:42 AGENTS.md
drwxrwxr-x  6 josh josh  4096 Jan 19 20:19 app
drwxrwxr-x  4 josh josh  4096 Jan 19 23:11 build
drwxrwxr-x  3 josh josh  4096 Jan 20 16:20 .codex
drwxrwxr-x  2 josh josh  4096 Jan 19 23:02 configs
drwxrwxr-x  2 josh josh  4096 Jan 19 20:03 docs
drwxrwxr-x  8 josh josh  4096 Jan 20 17:57 .git
-rw-rw-r--  1 josh josh    45 Jan 19 17:55 .gitignore
-rw-rw-r--  1 josh josh   228 Jan 19 17:55 Makefile
drwxrwxr-x  7 josh josh  4096 Jan 20 16:23 outputs
-rw-rw-r--  1 josh josh  4736 Jan 19 23:04 PROJECT_CONTEXT.md
-rw-rw-r--  1 josh josh   749 Jan 19 17:55 pyproject.toml
drwxrwxr-x  4 josh josh  4096 Jan 20 17:51 .ralph
-rw-rw-r--  1 josh josh 11803 Jan 20 17:37 README.md
-rw-rw-r--  1 josh josh   649 Jan 19 23:04 REPO_STATUS.md
drwxrwxr-x  2 josh josh  4096 Jan 19 23:11 ris_sionna.egg-info

thinking
**Checking for executable in PATH**
exec
/usr/bin/zsh -lc 'which ralph' in /home/josh/Documents/Github/RIS_SIONNA succeeded in 2ms:
/home/josh/.npm-global/bin/ralph

thinking
**Planning to use ralph log**
exec
/usr/bin/zsh -lc 'ralph log "Start US-002 work"' in /home/josh/Documents/Github/RIS_SIONNA succeeded in 87ms:
Using local templates: /home/josh/Documents/Github/RIS_SIONNA/.agents/ralph

thinking
**Reading setup instructions**

I'm reviewing AGENTS.md to understand the agent's usage guidelines and capabilities.
exec
/usr/bin/zsh -lc 'cat /home/josh/Documents/Github/RIS_SIONNA/AGENTS.md' in /home/josh/Documents/Github/RIS_SIONNA succeeded in 3ms:
# AGENTS.md — RIS_SIONNA
**Native Ubuntu 24.04 · GPU-first (CUDA/OptiX) · Sionna RT baseline @ 28 GHz · RIS Lab (validation-first)**

---

## 0. HARD CONTEXT RESET (NON-NEGOTIABLE)

- Primary target: **native Ubuntu 24.04**
- GPU RT target: **CUDA + OptiX (real runtime)**
- WSL may exist as a *CPU-only dev shell*, but **GPU OptiX on WSL is unsupported/unstable** for this repo.
- Any GPU RT failure on native Ubuntu is treated as **misconfiguration**, not “platform limitation”.

This repo must never silently “looks fine” while running CPU/LLVM when a GPU is available.
If we fall back, we must say so loudly and explain why.

---

## 1. SYSTEM ENVIRONMENT (AUTHORITATIVE)

**Baseline assumptions for “GPU-first” work:**

thinking
**Searching for ris config schema**
exec
/usr/bin/zsh -lc 'rg -n "ris" app configs tests' in /home/josh/Documents/Github/RIS_SIONNA succeeded in 14ms:
tests/test_ris_core.py:5:from app.ris.ris_core import (
app/config.py:40:    def ris(self) -> Dict[str, Any]:
app/config.py:41:        return self.data.get("ris", {})
app/ris/__init__.py:3:from .ris_core import (  # noqa: F401
app/utils/system.py:43:    stub.__dict__["__ris_sionna_stub__"] = reason
app/sim_web/vendor/three.module.js:376:// http://www.rorydriscoll.com/2016/03/07/frame-rate-independent-damping-using-lerp/
app/sim_web/vendor/three.module.js:8380:		// algorithm thanks to Real-Time Collision Detection by Christer Ericson,
app/sim_web/vendor/three.module.js:20643:		// heuristics to create shader parameters according to lights in the scene
app/sim_web/vendor/three.module.js:34948:		let low = 0, high = il - 1, comparison;
app/sim_web/vendor/three.module.js:34954:			comparison = arcLengths[ i ] - targetArcLength;
app/sim_web/vendor/three.module.js:34956:			if ( comparison < 0 ) {
app/sim_web/vendor/three.module.js:34960:			} else if ( comparison > 0 ) {
app/sim_web/vendor/three.module.js:42044:					//- See http://jsperf.com/comparison-to-undefined/3
configs/procedural.yaml:102:ris:
configs/high.yaml:107:ris:
configs/default.yaml:107:ris:
configs/preview.yaml:107:ris:

thinking
**Opening config files**

I'm opening app/config.py and ris config files to understand their setup and how they impact the implementation.
exec
/usr/bin/zsh -lc "sed -n '1,220p' /home/josh/Documents/Github/RIS_SIONNA/app/config.py" in /home/josh/Documents/Github/RIS_SIONNA succeeded in 3ms:
from __future__ import annotations

import copy
from dataclasses import dataclass
from pathlib import Path
from typing import Any, Dict

import yaml


@dataclass
class Config:
    data: Dict[str, Any]

    @property
    def runtime(self) -> Dict[str, Any]:
        return self.data.get("runtime", {})

    @property
    def simulation(self) -> Dict[str, Any]:

thinking
**Checking RIS lab config schema location**

Planning to verify if the RIS lab config schema is defined under the app/ris directory to locate relevant configuration details.
exec
/usr/bin/zsh -lc 'ls -la /home/josh/Documents/Github/RIS_SIONNA/app/ris' in /home/josh/Documents/Github/RIS_SIONNA succeeded in 3ms:
total 20
drwxrwxr-x 2 josh josh 4096 Jan 20 17:53 .
drwxrwxr-x 6 josh josh 4096 Jan 19 20:19 ..
-rw-rw-r-- 1 josh josh  359 Jan 20 17:53 __init__.py
-rw-rw-r-- 1 josh josh 4798 Jan 20 17:54 ris_core.py
exec
/usr/bin/zsh -lc "sed -n '1,260p' /home/josh/Documents/Github/RIS_SIONNA/app/ris/ris_core.py" in /home/josh/Documents/Github/RIS_SIONNA succeeded in 3ms:
"""Core RIS math primitives for geometry and phase control."""

from __future__ import annotations

from dataclasses import dataclass
from typing import Iterable, Optional

import numpy as np


@dataclass(frozen=True)
class RisFrame:
    """Right-handed local frame for the RIS surface."""

    u: np.ndarray
    v: np.ndarray
    w: np.ndarray


@dataclass(frozen=True)

thinking
**Searching for config resolution**

I'm checking where configuration is resolved to understand how to add the needed config schema. I haven't found existing config handling in app/ris yet.
exec
/usr/bin/zsh -lc 'rg -n "config" app/ris app' in /home/josh/Documents/Github/RIS_SIONNA succeeded in 6ms:
app/sim_jobs.py:14:from .config import apply_quality_preset
app/sim_jobs.py:149:        base_config = payload.get("base_config", "configs/default.yaml")
app/sim_jobs.py:150:        config_path = Path(base_config)
app/sim_jobs.py:151:        if not config_path.exists():
app/sim_jobs.py:152:            raise FileNotFoundError(f"Config not found: {config_path}")
app/sim_jobs.py:154:        cfg = _load_yaml(config_path)
app/sim_jobs.py:196:        job_config_path = output_dir / "job_config.yaml"
app/sim_jobs.py:197:        save_yaml(job_config_path, cfg)
app/sim_jobs.py:209:            "config_path": str(job_config_path),
app/sim_jobs.py:216:            [sys.executable, "-m", "app", "run", "--config", str(job_config_path)],
app/dashboard_app.py:15:st.set_page_config(page_title="RIS_SIONNA Dashboard", layout="wide")
app/dashboard_app.py:38:config_path = run_dir / "config.yaml"
app/dashboard_app.py:42:config_data = yaml.safe_load(config_path.read_text()) if config_path.exists() else {}
app/dashboard_app.py:43:scene_cfg = config_data.get("scene", {})
app/dashboard_app.py:52:    mesh_choices = ["Use run config"] + [p.name for p in mesh_files]
app/dashboard_app.py:75:    if mesh_choice != "Use run config":
app/dashboard_app.py:78:    updated_config = dict(config_data)
app/dashboard_app.py:79:    updated_config["scene"] = updated_scene
app/dashboard_app.py:81:        generate_viewer(run_dir, updated_config)
app/dashboard_app.py:134:    if config_path.exists():

thinking
**Locating RIS config usage**

I'm examining the configs to identify where the RIS Lab configuration is used, focusing on YAML files to inform the new schema module.
exec
/usr/bin/zsh -lc "sed -n '80,160p' /home/josh/Documents/Github/RIS_SIONNA/configs/default.yaml" in /home/josh/Documents/Github/RIS_SIONNA succeeded in 3ms:
  auto_padding: 10.0
  center: [30.0, 30.0, 1.5]
  orientation: [0.0, 0.0, 0.0]
  size: [40.0, 40.0]
  cell_size: [4.0, 4.0]
  batch_size: 256
  samples_per_tx: 80000
  max_depth: 2
  los: true
  specular_reflection: true
  diffuse_reflection: false
  refraction: true
  diffraction: false

render:
  enabled: true
  samples: 64
  resolution: [800, 600]

visualization:


thinking
**Scoping RIS Lab config schema implementation**

There's no existing RIS Lab config or CLI found, so I'll create a new config schema module under app/ris with defaults, validation, and ability to load minimal YAML configs. I'll implement output of resolved config snapshots (YAML and JSON) to outputs/<run_id>/ as specified, preparing for future CLI integration.
thinking
**Designing config resolution and snapshot helpers**

I'll implement a function to resolve, validate, and apply defaults to RIS Lab configs and write config snapshots plus a summary.json with deterministic config hash in outputs/<run_id>/. This covers acceptance without adding CLI or full run logic, preparing for future integration.
exec
/usr/bin/zsh -lc 'rg -n "save_yaml|write_json|summary.json|metrics.json" app' in /home/josh/Documents/Github/RIS_SIONNA succeeded in 6ms:
app/dashboard_app.py:37:summary_path = run_dir / "summary.json"
app/dashboard_app.py:127:            st.warning("summary.json not readable yet. Try refreshing.")
app/dashboard_app.py:131:        st.warning("summary.json not found")
app/utils/system.py:544:    save_json(output_dir / "summary.json", info)
app/io.py:32:def save_yaml(path: Path, data: Dict[str, Any]) -> None:
app/simulate.py:15:from .io import create_output_dir, save_json, save_yaml
app/simulate.py:55:    save_yaml(output_dir / "config.yaml", cfg.data)
app/simulate.py:514:                save_json(output_dir / "summary.json", summary)
app/sim_jobs.py:15:from .io import create_output_dir, generate_run_id, save_json, save_yaml
app/sim_jobs.py:197:        save_yaml(job_config_path, cfg)
app/sim_server.py:83:                summary_path = run_dir / "summary.json"
app/sim_server.py:147:            summary_path = run_dir / "summary.json"
exec
/usr/bin/zsh -lc "sed -n '1,220p' /home/josh/Documents/Github/RIS_SIONNA/app/io.py" in /home/josh/Documents/Github/RIS_SIONNA succeeded in 3ms:
import json
from datetime import datetime
from pathlib import Path
from typing import Any, Dict, Optional

import yaml
import numpy as np


def generate_run_id() -> str:
    return datetime.now().strftime("%Y%m%d_%H%M%S")


def create_output_dir(base_dir: str, run_id: Optional[str] = None) -> Path:
    run_id = run_id or generate_run_id()
    root = Path(base_dir) / run_id
    (root / "plots").mkdir(parents=True, exist_ok=True)
    (root / "data").mkdir(parents=True, exist_ok=True)
    return root


thinking
**Reviewing config hash logic**

I'm focusing on the save_yaml and save_json functions and checking simulate-related code for configuration hash handling to understand and verify the logic.
exec
/usr/bin/zsh -lc "sed -n '1,120p' /home/josh/Documents/Github/RIS_SIONNA/app/simulate.py" in /home/josh/Documents/Github/RIS_SIONNA succeeded in 3ms:
from __future__ import annotations

import contextlib
import hashlib
import json
import logging
import math
import time
from pathlib import Path
from typing import Any, Dict, Optional

import numpy as np

from .config import load_config
from .io import create_output_dir, save_json, save_yaml
from .metrics import build_paths_table, compute_path_metrics, extract_path_data
from .plots import plot_radio_map, plot_histogram, plot_rays_3d
from .viewer import generate_viewer
from .scene import build_scene, export_scene_meshes, scene_sanity_report
from .utils.progress import progress_steps

thinking
**Planning RIS config module**

I'm deciding to create a new module for RIS config resolution and output without modifying simulation, and I'll inspect existing RIS core tests to guide new test patterns and understand future CLI usage.
exec
/usr/bin/zsh -lc "sed -n '1,220p' /home/josh/Documents/Github/RIS_SIONNA/tests/test_ris_core.py" in /home/josh/Documents/Github/RIS_SIONNA succeeded in 3ms:
import unittest

import numpy as np

from app.ris.ris_core import (
    compute_element_centers,
    compute_local_frame,
    quantize_phase,
)


class TestRisGeometry(unittest.TestCase):
    def test_element_centers_2x2(self) -> None:
        geom = compute_element_centers(nx=2, ny=2, dx=1.0, dy=1.0)
        expected = np.array(
            [
                [[-0.5, -0.5, 0.0], [0.5, -0.5, 0.0]],
                [[-0.5, 0.5, 0.0], [0.5, 0.5, 0.0]],
            ],
            dtype=float,

thinking
**Planning RIS config and tests**

I'm considering adding new tests and example YAML configs for RIS without modifying PRD, likely under app/ris. Next, I'll explore app/cli for possible future integration and search existing config parsing utilities, possibly in app/utils/validation.
exec
/usr/bin/zsh -lc 'ls -la /home/josh/Documents/Github/RIS_SIONNA/app/utils' in /home/josh/Documents/Github/RIS_SIONNA succeeded in 3ms:
total 40
drwxrwxr-x 3 josh josh  4096 Jan 19 20:23 .
drwxrwxr-x 6 josh josh  4096 Jan 19 20:19 ..
-rw-rw-r-- 1 josh josh   214 Jan 19 17:55 logging.py
-rw-rw-r-- 1 josh josh   678 Jan 19 17:55 progress.py
drwxrwxr-x 2 josh josh  4096 Jan 19 20:49 __pycache__
-rw-rw-r-- 1 josh josh 18124 Jan 19 20:49 system.py


thinking
**Drafting RIS config schema design**

Planning a new ris_config module defining a config schema with defaults for geometry, control synthesis, quantization, pattern/link modes, and validation thresholds following PRD defaults. This includes top-level sections and required fields with validation, plus a resolver to merge user configs with defaults.
thinking
**Detailing config validation and deterministic resolution**

Planning to enforce required geometry fields with clear errors and provide defaults for other sections, while ensuring deterministic config resolution with canonical key ordering. Also preparing to write resolved config snapshots and run metadata with config hashes, plus adding validation and output directory handling.
exec
/usr/bin/zsh -lc 'cat /home/josh/Documents/Github/RIS_SIONNA/pyproject.toml' in /home/josh/Documents/Github/RIS_SIONNA succeeded in 3ms:
[project]
name = "ris_sionna"
version = "0.1.0"
description = "Beginner-friendly Sionna RT baseline (28 GHz) with CLI, outputs, and optional dashboard"
readme = "README.md"
requires-python = ">=3.10,<3.13"
license = "MIT"

# Core runtime dependencies
# Note: sionna brings in TensorFlow and Sionna RT dependencies per official docs.
dependencies = [
  "sionna==1.2.1",
  "numpy==1.26.4",
  "matplotlib==3.10.8",
  "pyyaml==6.0.3",
  "rich==14.2.0",
]

[project.optional-dependencies]
# Visualization-only dashboard

thinking
**Confirming unittest use and checking CLI for config handling**

Tests are using unittest, so I'll proceed with that. I'll also review the CLI for any existing config handling or logging infrastructure that could guide or integrate with the implementation.
exec
/usr/bin/zsh -lc "sed -n '1,200p' /home/josh/Documents/Github/RIS_SIONNA/app/cli.py" in /home/josh/Documents/Github/RIS_SIONNA succeeded in 3ms:
import argparse
import logging
import os
import socket
import subprocess
import sys
from pathlib import Path

from .io import find_latest_output_dir
from .plots import plot_radio_map_from_npz
from .simulate import run_simulation
from .utils.logging import setup_logging
from .utils.system import print_diagnose_info

logger = logging.getLogger(__name__)

def _pick_dashboard_port(preferred: int = 8501) -> int:
    with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as sock:
        sock.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)
        try:


thinking
**Designing RIS config module**

I'm defining a new config module for RIS with default geometry parameters, deciding to use `nx`, `ny`, `dx_m`, and `dy_m` for consistent naming aligned with core functions, noting some fields will be required.
thinking
**Defining detailed RIS config schema and validation**

I'm outlining a comprehensive RIS config schema with defaults, including geometry (with aliases for nx/ny and dx/dy), control, quantization, pattern/link modes, validation, experiment, and output sections. I'll implement merging user config with defaults, alias normalization, required field checks for geometry, and functions to load and resolve config with clear missing field errors.
exec
/usr/bin/zsh -lc 'cat /home/josh/Documents/Github/RIS_SIONNA/app/ris/__init__.py' in /home/josh/Documents/Github/RIS_SIONNA succeeded in 3ms:
"""RIS core math primitives and helpers."""

from .ris_core import (  # noqa: F401
    RisFrame,
    RisGeometry,
    compute_element_centers,
    compute_local_frame,
    degrees_to_radians,
    quantize_phase,
    radians_to_degrees,
    synthesize_custom_phase,
    synthesize_focusing_phase,
    synthesize_steering_phase,
    synthesize_uniform_phase,
)


thinking
**Planning config loading and snapshotting**

I'm designing functions to load YAML configs safely, write config snapshots in YAML/JSON, and create a summary including a deterministic config hash. I'll implement a key function that resolves the config, writes outputs into a run-specific directory, and returns these artifacts, enabling minimal YAML configs with defaults and comprehensive output for CLI use, with tests covering this flow.
thinking
**Designing config resolution, validation, and snapshotting**

I've mapped out functions to load YAML configs, merge with defaults, validate required geometry fields with clear errors, canonicalize key order, and snapshot configs plus a summary JSON including a sha256 hash. I'll ensure output directories and subfolders are created consistently, reusing existing helpers where possible, and plan comprehensive tests validating defaults, error handling, and snapshot correctness with deterministic hashes. Next, I'll implement these in a new module with proper exports and coverage.
file update
A /home/josh/Documents/Github/RIS_SIONNA/app/ris/ris_config.py
"""RIS Lab configuration schema and snapshot helpers."""

from __future__ import annotations

import copy
import hashlib
import json
from pathlib import Path
from typing import Any, Dict, Iterable, Optional

import yaml

from app.io import create_output_dir, save_json, save_yaml

RIS_LAB_SCHEMA_VERSION = 1

DEFAULT_RIS_LAB_CONFIG: Dict[str, Any] = {
    "schema_version": RIS_LAB_SCHEMA_VERSION,
    "geometry": {
        "nx": None,
        "ny": None,
        "dx": None,
        "dy": None,
        "origin": [0.0, 0.0, 0.0],
        "normal": [0.0, 0.0, 1.0],
        "x_axis_hint": [1.0, 0.0, 0.0],
    },
    "control": {
        "mode": "uniform",
        "params": {"phase_rad": 0.0},
    },
    "quantization": {
        "bits": 0,
    },
    "pattern_mode": {
        "normalization": "peak_0db",
        "rx_sweep_deg": {"start": -90.0, "stop": 90.0, "step": 2.0},
    },
    "link_mode": {
        "weighting": "inverse_distance",
        "enabled": False,
    },
    "validation": {
        "normalization": "peak_0db",
        "rmse_db_max": 2.0,
        "peak_angle_err_deg_max": 2.0,
        "peak_db_err_max": 1.5,
    },
    "experiment": {
        "frequency_hz": 28_000_000_000,
        "tx_incident_angle_deg": -30.0,
    },
    "output": {
        "base_dir": "outputs",
        "run_id": None,
    },
}

_ALIAS_FIELDS = {
    ("geometry", "nx"): [("geometry", "n")],
    ("geometry", "ny"): [("geometry", "m")],
    ("geometry", "dx"): [("geometry", "dx_m")],
    ("geometry", "dy"): [("geometry", "dy_m")],
}


def _deep_merge(base: Dict[str, Any], override: Dict[str, Any]) -> Dict[str, Any]:
    for key, value in override.items():
        if isinstance(value, dict) and isinstance(base.get(key), dict):
            base[key] = _deep_merge(base[key], value)
        else:
            base[key] = value
    return base


def _apply_aliases(config: Dict[str, Any]) -> Dict[str, Any]:
    updated = copy.deepcopy(config)
    for (section, key), aliases in _ALIAS_FIELDS.items():
        section_data = updated.get(section)
        if not isinstance(section_data, dict):
            continue
        if key in section_data:
            continue
        for alias_section, alias_key in aliases:
            alias_data = updated.get(alias_section)
            if isinstance(alias_data, dict) and alias_key in alias_data:
                section_data[key] = alias_data[alias_key]
                break
        updated[section] = section_data
    return updated


def _missing_required_fields(geometry: Dict[str, Any]) -> list[str]:
    required = ("nx", "ny", "dx", "dy")
    missing = []
    for key in required:
        value = geometry.get(key)
        if value is None:
            missing.append(f"geometry.{key}")
    return missing


def _canonicalize_config(config: Dict[str, Any]) -> Dict[str, Any]:
    ordered_keys = [
        "schema_version",
        "geometry",
        "control",
        "quantization",
        "pattern_mode",
        "link_mode",
        "validation",
        "experiment",
        "output",
    ]
    ordered: Dict[str, Any] = {}
    for key in ordered_keys:
        if key in config:
            ordered[key] = config[key]
    extras = {k: v for k, v in config.items() if k not in ordered_keys}
    for key in sorted(extras):
        ordered[key] = extras[key]
    return ordered


def resolve_ris_lab_config(raw_config: Dict[str, Any]) -> Dict[str, Any]:
    if not isinstance(raw_config, dict):
        raise ValueError("RIS Lab config must be a YAML mapping")

    normalized = _apply_aliases(raw_config)
    resolved = _deep_merge(copy.deepcopy(DEFAULT_RIS_LAB_CONFIG), normalized)

    geometry = resolved.get("geometry")
    if not isinstance(geometry, dict):
        raise ValueError("RIS Lab config geometry must be a mapping")

    missing = _missing_required_fields(geometry)
    if missing:
        raise ValueError(
            "RIS Lab config missing required fields: " + ", ".join(missing)
        )

    return _canonicalize_config(resolved)


def load_ris_lab_config(path: str | Path) -> Dict[str, Any]:
    config_path = Path(path)
    if not config_path.exists():
        raise FileNotFoundError(f"RIS Lab config not found: {config_path}")
    with config_path.open("r", encoding="utf-8") as handle:
        data = yaml.safe_load(handle)
    return resolve_ris_lab_config(data)


def compute_ris_lab_config_hash(config: Dict[str, Any]) -> str:
    payload = json.dumps(config, sort_keys=True).encode("utf-8")
    return hashlib.sha256(payload).hexdigest()


def _ensure_output_dir(output_dir: Path) -> Path:
    output_dir.mkdir(parents=True, exist_ok=True)
    (output_dir / "plots").mkdir(parents=True, exist_ok=True)
    (output_dir / "data").mkdir(parents=True, exist_ok=True)
    return output_dir


def snapshot_ris_lab_config(output_dir: Path, config: Dict[str, Any]) -> Dict[str, Any]:
    output_dir = _ensure_output_dir(output_dir)
    yaml_path = output_dir / "config.yaml"
    json_path = output_dir / "config.json"
    save_yaml(yaml_path, config)
    save_json(json_path, config)

    config_hash = compute_ris_lab_config_hash(config)
    summary = {
        "schema_version": config.get("schema_version", RIS_LAB_SCHEMA_VERSION),
        "config": {
            "hash_sha256": config_hash,
            "path_yaml": str(yaml_path),
            "path_json": str(json_path),
        },
    }
    save_json(output_dir / "summary.json", summary)
    return summary


def resolve_and_snapshot_ris_lab_config(
    config_path: str | Path,
    output_dir: Optional[str | Path] = None,
) -> tuple[Dict[str, Any], Path, Dict[str, Any]]:
    config = load_ris_lab_config(config_path)
    if output_dir is None:
        output_cfg = config.get("output", {})
        base_dir = output_cfg.get("base_dir", "outputs")
        run_id = output_cfg.get("run_id")
        output_path = create_output_dir(base_dir, run_id=run_id)
    else:
        output_path = _ensure_output_dir(Path(output_dir))

    summary = snapshot_ris_lab_config(output_path, config)
    return config, output_path, summary
apply_patch(auto_approved=true) exited 0 in 2ms:
Success. Updated the following files:
A /home/josh/Documents/Github/RIS_SIONNA/app/ris/ris_config.py
file update:
diff --git a/app/ris/ris_config.py b/app/ris/ris_config.py
new file mode 100644
index 0000000000000000000000000000000000000000..744c390c8e0c6c83a435e97cc579a09e71756ef6
--- /dev/null
+++ b/app/ris/ris_config.py
@@ -0,0 +1,200 @@
+"""RIS Lab configuration schema and snapshot helpers."""
+
+from __future__ import annotations
+
+import copy
+import hashlib
+import json
+from pathlib import Path
+from typing import Any, Dict, Iterable, Optional
+
+import yaml
+
+from app.io import create_output_dir, save_json, save_yaml
+
+RIS_LAB_SCHEMA_VERSION = 1
+
+DEFAULT_RIS_LAB_CONFIG: Dict[str, Any] = {
+    "schema_version": RIS_LAB_SCHEMA_VERSION,
+    "geometry": {
+        "nx": None,
+        "ny": None,
+        "dx": None,
+        "dy": None,
+        "origin": [0.0, 0.0, 0.0],
+        "normal": [0.0, 0.0, 1.0],
+        "x_axis_hint": [1.0, 0.0, 0.0],
+    },
+    "control": {
+        "mode": "uniform",
+        "params": {"phase_rad": 0.0},
+    },
+    "quantization": {
+        "bits": 0,
+    },
+    "pattern_mode": {
+        "normalization": "peak_0db",
+        "rx_sweep_deg": {"start": -90.0, "stop": 90.0, "step": 2.0},
+    },
+    "link_mode": {
+        "weighting": "inverse_distance",
+        "enabled": False,
+    },
+    "validation": {
+        "normalization": "peak_0db",
+        "rmse_db_max": 2.0,
+        "peak_angle_err_deg_max": 2.0,
+        "peak_db_err_max": 1.5,
+    },
+    "experiment": {
+        "frequency_hz": 28_000_000_000,
+        "tx_incident_angle_deg": -30.0,
+    },
+    "output": {
+        "base_dir": "outputs",
+        "run_id": None,
+    },
+}
+
+_ALIAS_FIELDS = {
+    ("geometry", "nx"): [("geometry", "n")],
+    ("geometry", "ny"): [("geometry", "m")],
+    ("geometry", "dx"): [("geometry", "dx_m")],
+    ("geometry", "dy"): [("geometry", "dy_m")],
+}
+
+
+def _deep_merge(base: Dict[str, Any], override: Dict[str, Any]) -> Dict[str, Any]:
+    for key, value in override.items():
+        if isinstance(value, dict) and isinstance(base.get(key), dict):
+            base[key] = _deep_merge(base[key], value)
+        else:
+            base[key] = value
+    return base
+
+
+def _apply_aliases(config: Dict[str, Any]) -> Dict[str, Any]:
+    updated = copy.deepcopy(config)
+    for (section, key), aliases in _ALIAS_FIELDS.items():
+        section_data = updated.get(section)
+        if not isinstance(section_data, dict):
+            continue
+        if key in section_data:
+            continue
+        for alias_section, alias_key in aliases:
+            alias_data = updated.get(alias_section)
+            if isinstance(alias_data, dict) and alias_key in alias_data:
+                section_data[key] = alias_data[alias_key]
+                break
+        updated[section] = section_data
+    return updated
+
+
+def _missing_required_fields(geometry: Dict[str, Any]) -> list[str]:
+    required = ("nx", "ny", "dx", "dy")
+    missing = []
+    for key in required:
+        value = geometry.get(key)
+        if value is None:
+            missing.append(f"geometry.{key}")
+    return missing
+
+
+def _canonicalize_config(config: Dict[str, Any]) -> Dict[str, Any]:
+    ordered_keys = [
+        "schema_version",
+        "geometry",
+        "control",
+        "quantization",
+        "pattern_mode",
+        "link_mode",
+        "validation",
+        "experiment",
+        "output",
+    ]
+    ordered: Dict[str, Any] = {}
+    for key in ordered_keys:
+        if key in config:
+            ordered[key] = config[key]
+    extras = {k: v for k, v in config.items() if k not in ordered_keys}
+    for key in sorted(extras):
+        ordered[key] = extras[key]
+    return ordered
+
+
+def resolve_ris_lab_config(raw_config: Dict[str, Any]) -> Dict[str, Any]:
+    if not isinstance(raw_config, dict):
+        raise ValueError("RIS Lab config must be a YAML mapping")
+
+    normalized = _apply_aliases(raw_config)
+    resolved = _deep_merge(copy.deepcopy(DEFAULT_RIS_LAB_CONFIG), normalized)
+
+    geometry = resolved.get("geometry")
+    if not isinstance(geometry, dict):
+        raise ValueError("RIS Lab config geometry must be a mapping")
+
+    missing = _missing_required_fields(geometry)
+    if missing:
+        raise ValueError(
+            "RIS Lab config missing required fields: " + ", ".join(missing)
+        )
+
+    return _canonicalize_config(resolved)
+
+
+def load_ris_lab_config(path: str | Path) -> Dict[str, Any]:
+    config_path = Path(path)
+    if not config_path.exists():
+        raise FileNotFoundError(f"RIS Lab config not found: {config_path}")
+    with config_path.open("r", encoding="utf-8") as handle:
+        data = yaml.safe_load(handle)
+    return resolve_ris_lab_config(data)
+
+
+def compute_ris_lab_config_hash(config: Dict[str, Any]) -> str:
+    payload = json.dumps(config, sort_keys=True).encode("utf-8")
+    return hashlib.sha256(payload).hexdigest()
+
+
+def _ensure_output_dir(output_dir: Path) -> Path:
+    output_dir.mkdir(parents=True, exist_ok=True)
+    (output_dir / "plots").mkdir(parents=True, exist_ok=True)
+    (output_dir / "data").mkdir(parents=True, exist_ok=True)
+    return output_dir
+
+
+def snapshot_ris_lab_config(output_dir: Path, config: Dict[str, Any]) -> Dict[str, Any]:
+    output_dir = _ensure_output_dir(output_dir)
+    yaml_path = output_dir / "config.yaml"
+    json_path = output_dir / "config.json"
+    save_yaml(yaml_path, config)
+    save_json(json_path, config)
+
+    config_hash = compute_ris_lab_config_hash(config)
+    summary = {
+        "schema_version": config.get("schema_version", RIS_LAB_SCHEMA_VERSION),
+        "config": {
+            "hash_sha256": config_hash,
+            "path_yaml": str(yaml_path),
+            "path_json": str(json_path),
+        },
+    }
+    save_json(output_dir / "summary.json", summary)
+    return summary
+
+
+def resolve_and_snapshot_ris_lab_config(
+    config_path: str | Path,
+    output_dir: Optional[str | Path] = None,
+) -> tuple[Dict[str, Any], Path, Dict[str, Any]]:
+    config = load_ris_lab_config(config_path)
+    if output_dir is None:
+        output_cfg = config.get("output", {})
+        base_dir = output_cfg.get("base_dir", "outputs")
+        run_id = output_cfg.get("run_id")
+        output_path = create_output_dir(base_dir, run_id=run_id)
+    else:
+        output_path = _ensure_output_dir(Path(output_dir))
+
+    summary = snapshot_ris_lab_config(output_path, config)
+    return config, output_path, summary

file update:
diff --git a/app/ris/ris_config.py b/app/ris/ris_config.py
new file mode 100644
index 0000000000000000000000000000000000000000..744c390c8e0c6c83a435e97cc579a09e71756ef6
--- /dev/null
+++ b/app/ris/ris_config.py
@@ -0,0 +1,200 @@
+"""RIS Lab configuration schema and snapshot helpers."""
+
+from __future__ import annotations
+
+import copy
+import hashlib
+import json
+from pathlib import Path
+from typing import Any, Dict, Iterable, Optional
+
+import yaml
+
+from app.io import create_output_dir, save_json, save_yaml
+
+RIS_LAB_SCHEMA_VERSION = 1
+
+DEFAULT_RIS_LAB_CONFIG: Dict[str, Any] = {
+    "schema_version": RIS_LAB_SCHEMA_VERSION,
+    "geometry": {
+        "nx": None,
+        "ny": None,
+        "dx": None,
+        "dy": None,
+        "origin": [0.0, 0.0, 0.0],
+        "normal": [0.0, 0.0, 1.0],
+        "x_axis_hint": [1.0, 0.0, 0.0],
+    },
+    "control": {
+        "mode": "uniform",
+        "params": {"phase_rad": 0.0},
+    },
+    "quantization": {
+        "bits": 0,
+    },
+    "pattern_mode": {
+        "normalization": "peak_0db",
+        "rx_sweep_deg": {"start": -90.0, "stop": 90.0, "step": 2.0},
+    },
+    "link_mode": {
+        "weighting": "inverse_distance",
+        "enabled": False,
+    },
+    "validation": {
+        "normalization": "peak_0db",
+        "rmse_db_max": 2.0,
+        "peak_angle_err_deg_max": 2.0,
+        "peak_db_err_max": 1.5,
+    },
+    "experiment": {
+        "frequency_hz": 28_000_000_000,
+        "tx_incident_angle_deg": -30.0,
+    },
+    "output": {
+        "base_dir": "outputs",
+        "run_id": None,
+    },
+}
+
+_ALIAS_FIELDS = {
+    ("geometry", "nx"): [("geometry", "n")],
+    ("geometry", "ny"): [("geometry", "m")],
+    ("geometry", "dx"): [("geometry", "dx_m")],
+    ("geometry", "dy"): [("geometry", "dy_m")],
+}
+
+
+def _deep_merge(base: Dict[str, Any], override: Dict[str, Any]) -> Dict[str, Any]:
+    for key, value in override.items():
+        if isinstance(value, dict) and isinstance(base.get(key), dict):
+            base[key] = _deep_merge(base[key], value)
+        else:
+            base[key] = value
+    return base
+
+
+def _apply_aliases(config: Dict[str, Any]) -> Dict[str, Any]:
+    updated = copy.deepcopy(config)
+    for (section, key), aliases in _ALIAS_FIELDS.items():
+        section_data = updated.get(section)
+        if not isinstance(section_data, dict):
+            continue
+        if key in section_data:
+            continue
+        for alias_section, alias_key in aliases:
+            alias_data = updated.get(alias_section)
+            if isinstance(alias_data, dict) and alias_key in alias_data:
+                section_data[key] = alias_data[alias_key]
+                break
+        updated[section] = section_data
+    return updated
+
+
+def _missing_required_fields(geometry: Dict[str, Any]) -> list[str]:
+    required = ("nx", "ny", "dx", "dy")
+    missing = []
+    for key in required:
+        value = geometry.get(key)
+        if value is None:
+            missing.append(f"geometry.{key}")
+    return missing
+
+
+def _canonicalize_config(config: Dict[str, Any]) -> Dict[str, Any]:
+    ordered_keys = [
+        "schema_version",
+        "geometry",
+        "control",
+        "quantization",
+        "pattern_mode",
+        "link_mode",
+        "validation",
+        "experiment",
+        "output",
+    ]
+    ordered: Dict[str, Any] = {}
+    for key in ordered_keys:
+        if key in config:
+            ordered[key] = config[key]
+    extras = {k: v for k, v in config.items() if k not in ordered_keys}
+    for key in sorted(extras):
+        ordered[key] = extras[key]
+    return ordered
+
+
+def resolve_ris_lab_config(raw_config: Dict[str, Any]) -> Dict[str, Any]:
+    if not isinstance(raw_config, dict):
+        raise ValueError("RIS Lab config must be a YAML mapping")
+
+    normalized = _apply_aliases(raw_config)
+    resolved = _deep_merge(copy.deepcopy(DEFAULT_RIS_LAB_CONFIG), normalized)
+
+    geometry = resolved.get("geometry")
+    if not isinstance(geometry, dict):
+        raise ValueError("RIS Lab config geometry must be a mapping")
+
+    missing = _missing_required_fields(geometry)
+    if missing:
+        raise ValueError(
+            "RIS Lab config missing required fields: " + ", ".join(missing)
+        )
+
+    return _canonicalize_config(resolved)
+
+
+def load_ris_lab_config(path: str | Path) -> Dict[str, Any]:
+    config_path = Path(path)
+    if not config_path.exists():
+        raise FileNotFoundError(f"RIS Lab config not found: {config_path}")
+    with config_path.open("r", encoding="utf-8") as handle:
+        data = yaml.safe_load(handle)
+    return resolve_ris_lab_config(data)
+
+
+def compute_ris_lab_config_hash(config: Dict[str, Any]) -> str:
+    payload = json.dumps(config, sort_keys=True).encode("utf-8")
+    return hashlib.sha256(payload).hexdigest()
+
+
+def _ensure_output_dir(output_dir: Path) -> Path:
+    output_dir.mkdir(parents=True, exist_ok=True)
+    (output_dir / "plots").mkdir(parents=True, exist_ok=True)
+    (output_dir / "data").mkdir(parents=True, exist_ok=True)
+    return output_dir
+
+
+def snapshot_ris_lab_config(output_dir: Path, config: Dict[str, Any]) -> Dict[str, Any]:
+    output_dir = _ensure_output_dir(output_dir)
+    yaml_path = output_dir / "config.yaml"
+    json_path = output_dir / "config.json"
+    save_yaml(yaml_path, config)
+    save_json(json_path, config)
+
+    config_hash = compute_ris_lab_config_hash(config)
+    summary = {
+        "schema_version": config.get("schema_version", RIS_LAB_SCHEMA_VERSION),
+        "config": {
+            "hash_sha256": config_hash,
+            "path_yaml": str(yaml_path),
+            "path_json": str(json_path),
+        },
+    }
+    save_json(output_dir / "summary.json", summary)
+    return summary
+
+
+def resolve_and_snapshot_ris_lab_config(
+    config_path: str | Path,
+    output_dir: Optional[str | Path] = None,
+) -> tuple[Dict[str, Any], Path, Dict[str, Any]]:
+    config = load_ris_lab_config(config_path)
+    if output_dir is None:
+        output_cfg = config.get("output", {})
+        base_dir = output_cfg.get("base_dir", "outputs")
+        run_id = output_cfg.get("run_id")
+        output_path = create_output_dir(base_dir, run_id=run_id)
+    else:
+        output_path = _ensure_output_dir(Path(output_dir))
+
+    summary = snapshot_ris_lab_config(output_path, config)
+    return config, output_path, summary


thinking
**Applying patch to initialization file**
file update
M /home/josh/Documents/Github/RIS_SIONNA/app/ris/__init__.py
@@ -2,2 +2,10 @@
 
+from .ris_config import (  # noqa: F401
+    RIS_LAB_SCHEMA_VERSION,
+    compute_ris_lab_config_hash,
+    load_ris_lab_config,
+    resolve_and_snapshot_ris_lab_config,
+    resolve_ris_lab_config,
+    snapshot_ris_lab_config,
+)
 from .ris_core import (  # noqa: F401
apply_patch(auto_approved=true) exited 0 in 3ms:
Success. Updated the following files:
M /home/josh/Documents/Github/RIS_SIONNA/app/ris/__init__.py
file update:
diff --git a/app/ris/__init__.py b/app/ris/__init__.py
index a34ed971e3d2426533f5eb2eb56416e59d15db65..bafa9ac9ccd2097b564c1c45d7c7b06f3a223b47
--- a/app/ris/__init__.py
+++ b/app/ris/__init__.py
@@ -1,5 +1,13 @@
 """RIS core math primitives and helpers."""
 
+from .ris_config import (  # noqa: F401
+    RIS_LAB_SCHEMA_VERSION,
+    compute_ris_lab_config_hash,
+    load_ris_lab_config,
+    resolve_and_snapshot_ris_lab_config,
+    resolve_ris_lab_config,
+    snapshot_ris_lab_config,
+)
 from .ris_core import (  # noqa: F401
     RisFrame,
     RisGeometry,
diff --git a/app/ris/ris_config.py b/app/ris/ris_config.py
new file mode 100644
index 0000000000000000000000000000000000000000..744c390c8e0c6c83a435e97cc579a09e71756ef6
--- /dev/null
+++ b/app/ris/ris_config.py
@@ -0,0 +1,200 @@
+"""RIS Lab configuration schema and snapshot helpers."""
+
+from __future__ import annotations
+
+import copy
+import hashlib
+import json
+from pathlib import Path
+from typing import Any, Dict, Iterable, Optional
+
+import yaml
+
+from app.io import create_output_dir, save_json, save_yaml
+
+RIS_LAB_SCHEMA_VERSION = 1
+
+DEFAULT_RIS_LAB_CONFIG: Dict[str, Any] = {
+    "schema_version": RIS_LAB_SCHEMA_VERSION,
+    "geometry": {
+        "nx": None,
+        "ny": None,
+        "dx": None,
+        "dy": None,
+        "origin": [0.0, 0.0, 0.0],
+        "normal": [0.0, 0.0, 1.0],
+        "x_axis_hint": [1.0, 0.0, 0.0],
+    },
+    "control": {
+        "mode": "uniform",
+        "params": {"phase_rad": 0.0},
+    },
+    "quantization": {
+        "bits": 0,
+    },
+    "pattern_mode": {
+        "normalization": "peak_0db",
+        "rx_sweep_deg": {"start": -90.0, "stop": 90.0, "step": 2.0},
+    },
+    "link_mode": {
+        "weighting": "inverse_distance",
+        "enabled": False,
+    },
+    "validation": {
+        "normalization": "peak_0db",
+        "rmse_db_max": 2.0,
+        "peak_angle_err_deg_max": 2.0,
+        "peak_db_err_max": 1.5,
+    },
+    "experiment": {
+        "frequency_hz": 28_000_000_000,
+        "tx_incident_angle_deg": -30.0,
+    },
+    "output": {
+        "base_dir": "outputs",
+        "run_id": None,
+    },
+}
+
+_ALIAS_FIELDS = {
+    ("geometry", "nx"): [("geometry", "n")],
+    ("geometry", "ny"): [("geometry", "m")],
+    ("geometry", "dx"): [("geometry", "dx_m")],
+    ("geometry", "dy"): [("geometry", "dy_m")],
+}
+
+
+def _deep_merge(base: Dict[str, Any], override: Dict[str, Any]) -> Dict[str, Any]:
+    for key, value in override.items():
+        if isinstance(value, dict) and isinstance(base.get(key), dict):
+            base[key] = _deep_merge(base[key], value)
+        else:
+            base[key] = value
+    return base
+
+
+def _apply_aliases(config: Dict[str, Any]) -> Dict[str, Any]:
+    updated = copy.deepcopy(config)
+    for (section, key), aliases in _ALIAS_FIELDS.items():
+        section_data = updated.get(section)
+        if not isinstance(section_data, dict):
+            continue
+        if key in section_data:
+            continue
+        for alias_section, alias_key in aliases:
+            alias_data = updated.get(alias_section)
+            if isinstance(alias_data, dict) and alias_key in alias_data:
+                section_data[key] = alias_data[alias_key]
+                break
+        updated[section] = section_data
+    return updated
+
+
+def _missing_required_fields(geometry: Dict[str, Any]) -> list[str]:
+    required = ("nx", "ny", "dx", "dy")
+    missing = []
+    for key in required:
+        value = geometry.get(key)
+        if value is None:
+            missing.append(f"geometry.{key}")
+    return missing
+
+
+def _canonicalize_config(config: Dict[str, Any]) -> Dict[str, Any]:
+    ordered_keys = [
+        "schema_version",
+        "geometry",
+        "control",
+        "quantization",
+        "pattern_mode",
+        "link_mode",
+        "validation",
+        "experiment",
+        "output",
+    ]
+    ordered: Dict[str, Any] = {}
+    for key in ordered_keys:
+        if key in config:
+            ordered[key] = config[key]
+    extras = {k: v for k, v in config.items() if k not in ordered_keys}
+    for key in sorted(extras):
+        ordered[key] = extras[key]
+    return ordered
+
+
+def resolve_ris_lab_config(raw_config: Dict[str, Any]) -> Dict[str, Any]:
+    if not isinstance(raw_config, dict):
+        raise ValueError("RIS Lab config must be a YAML mapping")
+
+    normalized = _apply_aliases(raw_config)
+    resolved = _deep_merge(copy.deepcopy(DEFAULT_RIS_LAB_CONFIG), normalized)
+
+    geometry = resolved.get("geometry")
+    if not isinstance(geometry, dict):
+        raise ValueError("RIS Lab config geometry must be a mapping")
+
+    missing = _missing_required_fields(geometry)
+    if missing:
+        raise ValueError(
+            "RIS Lab config missing required fields: " + ", ".join(missing)
+        )
+
+    return _canonicalize_config(resolved)
+
+
+def load_ris_lab_config(path: str | Path) -> Dict[str, Any]:
+    config_path = Path(path)
+    if not config_path.exists():
+        raise FileNotFoundError(f"RIS Lab config not found: {config_path}")
+    with config_path.open("r", encoding="utf-8") as handle:
+        data = yaml.safe_load(handle)
+    return resolve_ris_lab_config(data)
+
+
+def compute_ris_lab_config_hash(config: Dict[str, Any]) -> str:
+    payload = json.dumps(config, sort_keys=True).encode("utf-8")
+    return hashlib.sha256(payload).hexdigest()
+
+
+def _ensure_output_dir(output_dir: Path) -> Path:
+    output_dir.mkdir(parents=True, exist_ok=True)
+    (output_dir / "plots").mkdir(parents=True, exist_ok=True)
+    (output_dir / "data").mkdir(parents=True, exist_ok=True)
+    return output_dir
+
+
+def snapshot_ris_lab_config(output_dir: Path, config: Dict[str, Any]) -> Dict[str, Any]:
+    output_dir = _ensure_output_dir(output_dir)
+    yaml_path = output_dir / "config.yaml"
+    json_path = output_dir / "config.json"
+    save_yaml(yaml_path, config)
+    save_json(json_path, config)
+
+    config_hash = compute_ris_lab_config_hash(config)
+    summary = {
+        "schema_version": config.get("schema_version", RIS_LAB_SCHEMA_VERSION),
+        "config": {
+            "hash_sha256": config_hash,
+            "path_yaml": str(yaml_path),
+            "path_json": str(json_path),
+        },
+    }
+    save_json(output_dir / "summary.json", summary)
+    return summary
+
+
+def resolve_and_snapshot_ris_lab_config(
+    config_path: str | Path,
+    output_dir: Optional[str | Path] = None,
+) -> tuple[Dict[str, Any], Path, Dict[str, Any]]:
+    config = load_ris_lab_config(config_path)
+    if output_dir is None:
+        output_cfg = config.get("output", {})
+        base_dir = output_cfg.get("base_dir", "outputs")
+        run_id = output_cfg.get("run_id")
+        output_path = create_output_dir(base_dir, run_id=run_id)
+    else:
+        output_path = _ensure_output_dir(Path(output_dir))
+
+    summary = snapshot_ris_lab_config(output_path, config)
+    return config, output_path, summary

file update:
diff --git a/app/ris/__init__.py b/app/ris/__init__.py
index a34ed971e3d2426533f5eb2eb56416e59d15db65..bafa9ac9ccd2097b564c1c45d7c7b06f3a223b47
--- a/app/ris/__init__.py
+++ b/app/ris/__init__.py
@@ -1,5 +1,13 @@
 """RIS core math primitives and helpers."""
 
+from .ris_config import (  # noqa: F401
+    RIS_LAB_SCHEMA_VERSION,
+    compute_ris_lab_config_hash,
+    load_ris_lab_config,
+    resolve_and_snapshot_ris_lab_config,
+    resolve_ris_lab_config,
+    snapshot_ris_lab_config,
+)
 from .ris_core import (  # noqa: F401
     RisFrame,
     RisGeometry,
diff --git a/app/ris/ris_config.py b/app/ris/ris_config.py
new file mode 100644
index 0000000000000000000000000000000000000000..744c390c8e0c6c83a435e97cc579a09e71756ef6
--- /dev/null
+++ b/app/ris/ris_config.py
@@ -0,0 +1,200 @@
+"""RIS Lab configuration schema and snapshot helpers."""
+
+from __future__ import annotations
+
+import copy
+import hashlib
+import json
+from pathlib import Path
+from typing import Any, Dict, Iterable, Optional
+
+import yaml
+
+from app.io import create_output_dir, save_json, save_yaml
+
+RIS_LAB_SCHEMA_VERSION = 1
+
+DEFAULT_RIS_LAB_CONFIG: Dict[str, Any] = {
+    "schema_version": RIS_LAB_SCHEMA_VERSION,
+    "geometry": {
+        "nx": None,
+        "ny": None,
+        "dx": None,
+        "dy": None,
+        "origin": [0.0, 0.0, 0.0],
+        "normal": [0.0, 0.0, 1.0],
+        "x_axis_hint": [1.0, 0.0, 0.0],
+    },
+    "control": {
+        "mode": "uniform",
+        "params": {"phase_rad": 0.0},
+    },
+    "quantization": {
+        "bits": 0,
+    },
+    "pattern_mode": {
+        "normalization": "peak_0db",
+        "rx_sweep_deg": {"start": -90.0, "stop": 90.0, "step": 2.0},
+    },
+    "link_mode": {
+        "weighting": "inverse_distance",
+        "enabled": False,
+    },
+    "validation": {
+        "normalization": "peak_0db",
+        "rmse_db_max": 2.0,
+        "peak_angle_err_deg_max": 2.0,
+        "peak_db_err_max": 1.5,
+    },
+    "experiment": {
+        "frequency_hz": 28_000_000_000,
+        "tx_incident_angle_deg": -30.0,
+    },
+    "output": {
+        "base_dir": "outputs",
+        "run_id": None,
+    },
+}
+
+_ALIAS_FIELDS = {
+    ("geometry", "nx"): [("geometry", "n")],
+    ("geometry", "ny"): [("geometry", "m")],
+    ("geometry", "dx"): [("geometry", "dx_m")],
+    ("geometry", "dy"): [("geometry", "dy_m")],
+}
+
+
+def _deep_merge(base: Dict[str, Any], override: Dict[str, Any]) -> Dict[str, Any]:
+    for key, value in override.items():
+        if isinstance(value, dict) and isinstance(base.get(key), dict):
+            base[key] = _deep_merge(base[key], value)
+        else:
+            base[key] = value
+    return base
+
+
+def _apply_aliases(config: Dict[str, Any]) -> Dict[str, Any]:
+    updated = copy.deepcopy(config)
+    for (section, key), aliases in _ALIAS_FIELDS.items():
+        section_data = updated.get(section)
+        if not isinstance(section_data, dict):
+            continue
+        if key in section_data:
+            continue
+        for alias_section, alias_key in aliases:
+            alias_data = updated.get(alias_section)
+            if isinstance(alias_data, dict) and alias_key in alias_data:
+                section_data[key] = alias_data[alias_key]
+                break
+        updated[section] = section_data
+    return updated
+
+
+def _missing_required_fields(geometry: Dict[str, Any]) -> list[str]:
+    required = ("nx", "ny", "dx", "dy")
+    missing = []
+    for key in required:
+        value = geometry.get(key)
+        if value is None:
+            missing.append(f"geometry.{key}")
+    return missing
+
+
+def _canonicalize_config(config: Dict[str, Any]) -> Dict[str, Any]:
+    ordered_keys = [
+        "schema_version",
+        "geometry",
+        "control",
+        "quantization",
+        "pattern_mode",
+        "link_mode",
+        "validation",
+        "experiment",
+        "output",
+    ]
+    ordered: Dict[str, Any] = {}
+    for key in ordered_keys:
+        if key in config:
+            ordered[key] = config[key]
+    extras = {k: v for k, v in config.items() if k not in ordered_keys}
+    for key in sorted(extras):
+        ordered[key] = extras[key]
+    return ordered
+
+
+def resolve_ris_lab_config(raw_config: Dict[str, Any]) -> Dict[str, Any]:
+    if not isinstance(raw_config, dict):
+        raise ValueError("RIS Lab config must be a YAML mapping")
+
+    normalized = _apply_aliases(raw_config)
+    resolved = _deep_merge(copy.deepcopy(DEFAULT_RIS_LAB_CONFIG), normalized)
+
+    geometry = resolved.get("geometry")
+    if not isinstance(geometry, dict):
+        raise ValueError("RIS Lab config geometry must be a mapping")
+
+    missing = _missing_required_fields(geometry)
+    if missing:
+        raise ValueError(
+            "RIS Lab config missing required fields: " + ", ".join(missing)
+        )
+
+    return _canonicalize_config(resolved)
+
+
+def load_ris_lab_config(path: str | Path) -> Dict[str, Any]:
+    config_path = Path(path)
+    if not config_path.exists():
+        raise FileNotFoundError(f"RIS Lab config not found: {config_path}")
+    with config_path.open("r", encoding="utf-8") as handle:
+        data = yaml.safe_load(handle)
+    return resolve_ris_lab_config(data)
+
+
+def compute_ris_lab_config_hash(config: Dict[str, Any]) -> str:
+    payload = json.dumps(config, sort_keys=True).encode("utf-8")
+    return hashlib.sha256(payload).hexdigest()
+
+
+def _ensure_output_dir(output_dir: Path) -> Path:
+    output_dir.mkdir(parents=True, exist_ok=True)
+    (output_dir / "plots").mkdir(parents=True, exist_ok=True)
+    (output_dir / "data").mkdir(parents=True, exist_ok=True)
+    return output_dir
+
+
+def snapshot_ris_lab_config(output_dir: Path, config: Dict[str, Any]) -> Dict[str, Any]:
+    output_dir = _ensure_output_dir(output_dir)
+    yaml_path = output_dir / "config.yaml"
+    json_path = output_dir / "config.json"
+    save_yaml(yaml_path, config)
+    save_json(json_path, config)
+
+    config_hash = compute_ris_lab_config_hash(config)
+    summary = {
+        "schema_version": config.get("schema_version", RIS_LAB_SCHEMA_VERSION),
+        "config": {
+            "hash_sha256": config_hash,
+            "path_yaml": str(yaml_path),
+            "path_json": str(json_path),
+        },
+    }
+    save_json(output_dir / "summary.json", summary)
+    return summary
+
+
+def resolve_and_snapshot_ris_lab_config(
+    config_path: str | Path,
+    output_dir: Optional[str | Path] = None,
+) -> tuple[Dict[str, Any], Path, Dict[str, Any]]:
+    config = load_ris_lab_config(config_path)
+    if output_dir is None:
+        output_cfg = config.get("output", {})
+        base_dir = output_cfg.get("base_dir", "outputs")
+        run_id = output_cfg.get("run_id")
+        output_path = create_output_dir(base_dir, run_id=run_id)
+    else:
+        output_path = _ensure_output_dir(Path(output_dir))
+
+    summary = snapshot_ris_lab_config(output_path, config)
+    return config, output_path, summary


thinking
**Adding tests for config handling**

I'm creating new unittest tests covering minimal defaults, missing fields, and snapshot writing in a temp directory, using tempfile and yaml.safe_dump for YAML operations.
file update
A /home/josh/Documents/Github/RIS_SIONNA/tests/test_ris_config.py
import json
import tempfile
import unittest
from pathlib import Path

import yaml

from app.ris.ris_config import (
    compute_ris_lab_config_hash,
    resolve_and_snapshot_ris_lab_config,
    resolve_ris_lab_config,
)


class TestRisLabConfig(unittest.TestCase):
    def test_minimal_config_resolves_defaults(self) -> None:
        resolved = resolve_ris_lab_config(
            {"geometry": {"nx": 4, "ny": 2, "dx": 0.5, "dy": 0.25}}
        )
        self.assertEqual(resolved["control"]["mode"], "uniform")
        self.assertEqual(resolved["quantization"]["bits"], 0)
        self.assertEqual(resolved["validation"]["rmse_db_max"], 2.0)
        self.assertEqual(resolved["output"]["base_dir"], "outputs")

    def test_missing_geometry_fields_reports_required(self) -> None:
        with self.assertRaises(ValueError) as ctx:
            resolve_ris_lab_config({"geometry": {"nx": 4}})
        message = str(ctx.exception)
        self.assertIn("geometry.ny", message)
        self.assertIn("geometry.dx", message)
        self.assertIn("geometry.dy", message)

    def test_snapshot_writes_config_files_and_summary(self) -> None:
        with tempfile.TemporaryDirectory() as tmpdir:
            tmp_path = Path(tmpdir)
            config_path = tmp_path / "ris.yaml"
            yaml.safe_dump(
                {
                    "geometry": {"nx": 2, "ny": 2, "dx": 0.1, "dy": 0.2},
                    "output": {"base_dir": tmpdir, "run_id": "unit-test"},
                },
                config_path.open("w", encoding="utf-8"),
                sort_keys=False,
            )

            config, output_dir, summary = resolve_and_snapshot_ris_lab_config(config_path)
            self.assertEqual(output_dir, tmp_path / "unit-test")
            self.assertTrue((output_dir / "config.yaml").exists())
            self.assertTrue((output_dir / "config.json").exists())
            self.assertTrue((output_dir / "summary.json").exists())
            self.assertEqual(summary["config"]["hash_sha256"], compute_ris_lab_config_hash(config))

            loaded = json.loads((output_dir / "config.json").read_text(encoding="utf-8"))
            self.assertEqual(loaded["geometry"]["nx"], 2)


if __name__ == "__main__":
    unittest.main()
apply_patch(auto_approved=true) exited 0 in 11ms:
Success. Updated the following files:
A /home/josh/Documents/Github/RIS_SIONNA/tests/test_ris_config.py
file update:
diff --git a/app/ris/__init__.py b/app/ris/__init__.py
index a34ed971e3d2426533f5eb2eb56416e59d15db65..bafa9ac9ccd2097b564c1c45d7c7b06f3a223b47
--- a/app/ris/__init__.py
+++ b/app/ris/__init__.py
@@ -1,5 +1,13 @@
 """RIS core math primitives and helpers."""
 
+from .ris_config import (  # noqa: F401
+    RIS_LAB_SCHEMA_VERSION,
+    compute_ris_lab_config_hash,
+    load_ris_lab_config,
+    resolve_and_snapshot_ris_lab_config,
+    resolve_ris_lab_config,
+    snapshot_ris_lab_config,
+)
 from .ris_core import (  # noqa: F401
     RisFrame,
     RisGeometry,
diff --git a/app/ris/ris_config.py b/app/ris/ris_config.py
new file mode 100644
index 0000000000000000000000000000000000000000..744c390c8e0c6c83a435e97cc579a09e71756ef6
--- /dev/null
+++ b/app/ris/ris_config.py
@@ -0,0 +1,200 @@
+"""RIS Lab configuration schema and snapshot helpers."""
+
+from __future__ import annotations
+
+import copy
+import hashlib
+import json
+from pathlib import Path
+from typing import Any, Dict, Iterable, Optional
+
+import yaml
+
+from app.io import create_output_dir, save_json, save_yaml
+
+RIS_LAB_SCHEMA_VERSION = 1
+
+DEFAULT_RIS_LAB_CONFIG: Dict[str, Any] = {
+    "schema_version": RIS_LAB_SCHEMA_VERSION,
+    "geometry": {
+        "nx": None,
+        "ny": None,
+        "dx": None,
+        "dy": None,
+        "origin": [0.0, 0.0, 0.0],
+        "normal": [0.0, 0.0, 1.0],
+        "x_axis_hint": [1.0, 0.0, 0.0],
+    },
+    "control": {
+        "mode": "uniform",
+        "params": {"phase_rad": 0.0},
+    },
+    "quantization": {
+        "bits": 0,
+    },
+    "pattern_mode": {
+        "normalization": "peak_0db",
+        "rx_sweep_deg": {"start": -90.0, "stop": 90.0, "step": 2.0},
+    },
+    "link_mode": {
+        "weighting": "inverse_distance",
+        "enabled": False,
+    },
+    "validation": {
+        "normalization": "peak_0db",
+        "rmse_db_max": 2.0,
+        "peak_angle_err_deg_max": 2.0,
+        "peak_db_err_max": 1.5,
+    },
+    "experiment": {
+        "frequency_hz": 28_000_000_000,
+        "tx_incident_angle_deg": -30.0,
+    },
+    "output": {
+        "base_dir": "outputs",
+        "run_id": None,
+    },
+}
+
+_ALIAS_FIELDS = {
+    ("geometry", "nx"): [("geometry", "n")],
+    ("geometry", "ny"): [("geometry", "m")],
+    ("geometry", "dx"): [("geometry", "dx_m")],
+    ("geometry", "dy"): [("geometry", "dy_m")],
+}
+
+
+def _deep_merge(base: Dict[str, Any], override: Dict[str, Any]) -> Dict[str, Any]:
+    for key, value in override.items():
+        if isinstance(value, dict) and isinstance(base.get(key), dict):
+            base[key] = _deep_merge(base[key], value)
+        else:
+            base[key] = value
+    return base
+
+
+def _apply_aliases(config: Dict[str, Any]) -> Dict[str, Any]:
+    updated = copy.deepcopy(config)
+    for (section, key), aliases in _ALIAS_FIELDS.items():
+        section_data = updated.get(section)
+        if not isinstance(section_data, dict):
+            continue
+        if key in section_data:
+            continue
+        for alias_section, alias_key in aliases:
+            alias_data = updated.get(alias_section)
+            if isinstance(alias_data, dict) and alias_key in alias_data:
+                section_data[key] = alias_data[alias_key]
+                break
+        updated[section] = section_data
+    return updated
+
+
+def _missing_required_fields(geometry: Dict[str, Any]) -> list[str]:
+    required = ("nx", "ny", "dx", "dy")
+    missing = []
+    for key in required:
+        value = geometry.get(key)
+        if value is None:
+            missing.append(f"geometry.{key}")
+    return missing
+
+
+def _canonicalize_config(config: Dict[str, Any]) -> Dict[str, Any]:
+    ordered_keys = [
+        "schema_version",
+        "geometry",
+        "control",
+        "quantization",
+        "pattern_mode",
+        "link_mode",
+        "validation",
+        "experiment",
+        "output",
+    ]
+    ordered: Dict[str, Any] = {}
+    for key in ordered_keys:
+        if key in config:
+            ordered[key] = config[key]
+    extras = {k: v for k, v in config.items() if k not in ordered_keys}
+    for key in sorted(extras):
+        ordered[key] = extras[key]
+    return ordered
+
+
+def resolve_ris_lab_config(raw_config: Dict[str, Any]) -> Dict[str, Any]:
+    if not isinstance(raw_config, dict):
+        raise ValueError("RIS Lab config must be a YAML mapping")
+
+    normalized = _apply_aliases(raw_config)
+    resolved = _deep_merge(copy.deepcopy(DEFAULT_RIS_LAB_CONFIG), normalized)
+
+    geometry = resolved.get("geometry")
+    if not isinstance(geometry, dict):
+        raise ValueError("RIS Lab config geometry must be a mapping")
+
+    missing = _missing_required_fields(geometry)
+    if missing:
+        raise ValueError(
+            "RIS Lab config missing required fields: " + ", ".join(missing)
+        )
+
+    return _canonicalize_config(resolved)
+
+
+def load_ris_lab_config(path: str | Path) -> Dict[str, Any]:
+    config_path = Path(path)
+    if not config_path.exists():
+        raise FileNotFoundError(f"RIS Lab config not found: {config_path}")
+    with config_path.open("r", encoding="utf-8") as handle:
+        data = yaml.safe_load(handle)
+    return resolve_ris_lab_config(data)
+
+
+def compute_ris_lab_config_hash(config: Dict[str, Any]) -> str:
+    payload = json.dumps(config, sort_keys=True).encode("utf-8")
+    return hashlib.sha256(payload).hexdigest()
+
+
+def _ensure_output_dir(output_dir: Path) -> Path:
+    output_dir.mkdir(parents=True, exist_ok=True)
+    (output_dir / "plots").mkdir(parents=True, exist_ok=True)
+    (output_dir / "data").mkdir(parents=True, exist_ok=True)
+    return output_dir
+
+
+def snapshot_ris_lab_config(output_dir: Path, config: Dict[str, Any]) -> Dict[str, Any]:
+    output_dir = _ensure_output_dir(output_dir)
+    yaml_path = output_dir / "config.yaml"
+    json_path = output_dir / "config.json"
+    save_yaml(yaml_path, config)
+    save_json(json_path, config)
+
+    config_hash = compute_ris_lab_config_hash(config)
+    summary = {
+        "schema_version": config.get("schema_version", RIS_LAB_SCHEMA_VERSION),
+        "config": {
+            "hash_sha256": config_hash,
+            "path_yaml": str(yaml_path),
+            "path_json": str(json_path),
+        },
+    }
+    save_json(output_dir / "summary.json", summary)
+    return summary
+
+
+def resolve_and_snapshot_ris_lab_config(
+    config_path: str | Path,
+    output_dir: Optional[str | Path] = None,
+) -> tuple[Dict[str, Any], Path, Dict[str, Any]]:
+    config = load_ris_lab_config(config_path)
+    if output_dir is None:
+        output_cfg = config.get("output", {})
+        base_dir = output_cfg.get("base_dir", "outputs")
+        run_id = output_cfg.get("run_id")
+        output_path = create_output_dir(base_dir, run_id=run_id)
+    else:
+        output_path = _ensure_output_dir(Path(output_dir))
+
+    summary = snapshot_ris_lab_config(output_path, config)
+    return config, output_path, summary
diff --git a/tests/test_ris_config.py b/tests/test_ris_config.py
new file mode 100644
index 0000000000000000000000000000000000000000..425e3679bae77cdb6c92bd26bc4d66308a7c610c
--- /dev/null
+++ b/tests/test_ris_config.py
@@ -0,0 +1,58 @@
+import json
+import tempfile
+import unittest
+from pathlib import Path
+
+import yaml
+
+from app.ris.ris_config import (
+    compute_ris_lab_config_hash,
+    resolve_and_snapshot_ris_lab_config,
+    resolve_ris_lab_config,
+)
+
+
+class TestRisLabConfig(unittest.TestCase):
+    def test_minimal_config_resolves_defaults(self) -> None:
+        resolved = resolve_ris_lab_config(
+            {"geometry": {"nx": 4, "ny": 2, "dx": 0.5, "dy": 0.25}}
+        )
+        self.assertEqual(resolved["control"]["mode"], "uniform")
+        self.assertEqual(resolved["quantization"]["bits"], 0)
+        self.assertEqual(resolved["validation"]["rmse_db_max"], 2.0)
+        self.assertEqual(resolved["output"]["base_dir"], "outputs")
+
+    def test_missing_geometry_fields_reports_required(self) -> None:
+        with self.assertRaises(ValueError) as ctx:
+            resolve_ris_lab_config({"geometry": {"nx": 4}})
+        message = str(ctx.exception)
+        self.assertIn("geometry.ny", message)
+        self.assertIn("geometry.dx", message)
+        self.assertIn("geometry.dy", message)
+
+    def test_snapshot_writes_config_files_and_summary(self) -> None:
+        with tempfile.TemporaryDirectory() as tmpdir:
+            tmp_path = Path(tmpdir)
+            config_path = tmp_path / "ris.yaml"
+            yaml.safe_dump(
+                {
+                    "geometry": {"nx": 2, "ny": 2, "dx": 0.1, "dy": 0.2},
+                    "output": {"base_dir": tmpdir, "run_id": "unit-test"},
+                },
+                config_path.open("w", encoding="utf-8"),
+                sort_keys=False,
+            )
+
+            config, output_dir, summary = resolve_and_snapshot_ris_lab_config(config_path)
+            self.assertEqual(output_dir, tmp_path / "unit-test")
+            self.assertTrue((output_dir / "config.yaml").exists())
+            self.assertTrue((output_dir / "config.json").exists())
+            self.assertTrue((output_dir / "summary.json").exists())
+            self.assertEqual(summary["config"]["hash_sha256"], compute_ris_lab_config_hash(config))
+
+            loaded = json.loads((output_dir / "config.json").read_text(encoding="utf-8"))
+            self.assertEqual(loaded["geometry"]["nx"], 2)
+
+
+if __name__ == "__main__":
+    unittest.main()

file update:
diff --git a/app/ris/__init__.py b/app/ris/__init__.py
index a34ed971e3d2426533f5eb2eb56416e59d15db65..bafa9ac9ccd2097b564c1c45d7c7b06f3a223b47
--- a/app/ris/__init__.py
+++ b/app/ris/__init__.py
@@ -1,5 +1,13 @@
 """RIS core math primitives and helpers."""
 
+from .ris_config import (  # noqa: F401
+    RIS_LAB_SCHEMA_VERSION,
+    compute_ris_lab_config_hash,
+    load_ris_lab_config,
+    resolve_and_snapshot_ris_lab_config,
+    resolve_ris_lab_config,
+    snapshot_ris_lab_config,
+)
 from .ris_core import (  # noqa: F401
     RisFrame,
     RisGeometry,
diff --git a/app/ris/ris_config.py b/app/ris/ris_config.py
new file mode 100644
index 0000000000000000000000000000000000000000..744c390c8e0c6c83a435e97cc579a09e71756ef6
--- /dev/null
+++ b/app/ris/ris_config.py
@@ -0,0 +1,200 @@
+"""RIS Lab configuration schema and snapshot helpers."""
+
+from __future__ import annotations
+
+import copy
+import hashlib
+import json
+from pathlib import Path
+from typing import Any, Dict, Iterable, Optional
+
+import yaml
+
+from app.io import create_output_dir, save_json, save_yaml
+
+RIS_LAB_SCHEMA_VERSION = 1
+
+DEFAULT_RIS_LAB_CONFIG: Dict[str, Any] = {
+    "schema_version": RIS_LAB_SCHEMA_VERSION,
+    "geometry": {
+        "nx": None,
+        "ny": None,
+        "dx": None,
+        "dy": None,
+        "origin": [0.0, 0.0, 0.0],
+        "normal": [0.0, 0.0, 1.0],
+        "x_axis_hint": [1.0, 0.0, 0.0],
+    },
+    "control": {
+        "mode": "uniform",
+        "params": {"phase_rad": 0.0},
+    },
+    "quantization": {
+        "bits": 0,
+    },
+    "pattern_mode": {
+        "normalization": "peak_0db",
+        "rx_sweep_deg": {"start": -90.0, "stop": 90.0, "step": 2.0},
+    },
+    "link_mode": {
+        "weighting": "inverse_distance",
+        "enabled": False,
+    },
+    "validation": {
+        "normalization": "peak_0db",
+        "rmse_db_max": 2.0,
+        "peak_angle_err_deg_max": 2.0,
+        "peak_db_err_max": 1.5,
+    },
+    "experiment": {
+        "frequency_hz": 28_000_000_000,
+        "tx_incident_angle_deg": -30.0,
+    },
+    "output": {
+        "base_dir": "outputs",
+        "run_id": None,
+    },
+}
+
+_ALIAS_FIELDS = {
+    ("geometry", "nx"): [("geometry", "n")],
+    ("geometry", "ny"): [("geometry", "m")],
+    ("geometry", "dx"): [("geometry", "dx_m")],
+    ("geometry", "dy"): [("geometry", "dy_m")],
+}
+
+
+def _deep_merge(base: Dict[str, Any], override: Dict[str, Any]) -> Dict[str, Any]:
+    for key, value in override.items():
+        if isinstance(value, dict) and isinstance(base.get(key), dict):
+            base[key] = _deep_merge(base[key], value)
+        else:
+            base[key] = value
+    return base
+
+
+def _apply_aliases(config: Dict[str, Any]) -> Dict[str, Any]:
+    updated = copy.deepcopy(config)
+    for (section, key), aliases in _ALIAS_FIELDS.items():
+        section_data = updated.get(section)
+        if not isinstance(section_data, dict):
+            continue
+        if key in section_data:
+            continue
+        for alias_section, alias_key in aliases:
+            alias_data = updated.get(alias_section)
+            if isinstance(alias_data, dict) and alias_key in alias_data:
+                section_data[key] = alias_data[alias_key]
+                break
+        updated[section] = section_data
+    return updated
+
+
+def _missing_required_fields(geometry: Dict[str, Any]) -> list[str]:
+    required = ("nx", "ny", "dx", "dy")
+    missing = []
+    for key in required:
+        value = geometry.get(key)
+        if value is None:
+            missing.append(f"geometry.{key}")
+    return missing
+
+
+def _canonicalize_config(config: Dict[str, Any]) -> Dict[str, Any]:
+    ordered_keys = [
+        "schema_version",
+        "geometry",
+        "control",
+        "quantization",
+        "pattern_mode",
+        "link_mode",
+        "validation",
+        "experiment",
+        "output",
+    ]
+    ordered: Dict[str, Any] = {}
+    for key in ordered_keys:
+        if key in config:
+            ordered[key] = config[key]
+    extras = {k: v for k, v in config.items() if k not in ordered_keys}
+    for key in sorted(extras):
+        ordered[key] = extras[key]
+    return ordered
+
+
+def resolve_ris_lab_config(raw_config: Dict[str, Any]) -> Dict[str, Any]:
+    if not isinstance(raw_config, dict):
+        raise ValueError("RIS Lab config must be a YAML mapping")
+
+    normalized = _apply_aliases(raw_config)
+    resolved = _deep_merge(copy.deepcopy(DEFAULT_RIS_LAB_CONFIG), normalized)
+
+    geometry = resolved.get("geometry")
+    if not isinstance(geometry, dict):
+        raise ValueError("RIS Lab config geometry must be a mapping")
+
+    missing = _missing_required_fields(geometry)
+    if missing:
+        raise ValueError(
+            "RIS Lab config missing required fields: " + ", ".join(missing)
+        )
+
+    return _canonicalize_config(resolved)
+
+
+def load_ris_lab_config(path: str | Path) -> Dict[str, Any]:
+    config_path = Path(path)
+    if not config_path.exists():
+        raise FileNotFoundError(f"RIS Lab config not found: {config_path}")
+    with config_path.open("r", encoding="utf-8") as handle:
+        data = yaml.safe_load(handle)
+    return resolve_ris_lab_config(data)
+
+
+def compute_ris_lab_config_hash(config: Dict[str, Any]) -> str:
+    payload = json.dumps(config, sort_keys=True).encode("utf-8")
+    return hashlib.sha256(payload).hexdigest()
+
+
+def _ensure_output_dir(output_dir: Path) -> Path:
+    output_dir.mkdir(parents=True, exist_ok=True)
+    (output_dir / "plots").mkdir(parents=True, exist_ok=True)
+    (output_dir / "data").mkdir(parents=True, exist_ok=True)
+    return output_dir
+
+
+def snapshot_ris_lab_config(output_dir: Path, config: Dict[str, Any]) -> Dict[str, Any]:
+    output_dir = _ensure_output_dir(output_dir)
+    yaml_path = output_dir / "config.yaml"
+    json_path = output_dir / "config.json"
+    save_yaml(yaml_path, config)
+    save_json(json_path, config)
+
+    config_hash = compute_ris_lab_config_hash(config)
+    summary = {
+        "schema_version": config.get("schema_version", RIS_LAB_SCHEMA_VERSION),
+        "config": {
+            "hash_sha256": config_hash,
+            "path_yaml": str(yaml_path),
+            "path_json": str(json_path),
+        },
+    }
+    save_json(output_dir / "summary.json", summary)
+    return summary
+
+
+def resolve_and_snapshot_ris_lab_config(
+    config_path: str | Path,
+    output_dir: Optional[str | Path] = None,
+) -> tuple[Dict[str, Any], Path, Dict[str, Any]]:
+    config = load_ris_lab_config(config_path)
+    if output_dir is None:
+        output_cfg = config.get("output", {})
+        base_dir = output_cfg.get("base_dir", "outputs")
+        run_id = output_cfg.get("run_id")
+        output_path = create_output_dir(base_dir, run_id=run_id)
+    else:
+        output_path = _ensure_output_dir(Path(output_dir))
+
+    summary = snapshot_ris_lab_config(output_path, config)
+    return config, output_path, summary
diff --git a/tests/test_ris_config.py b/tests/test_ris_config.py
new file mode 100644
index 0000000000000000000000000000000000000000..425e3679bae77cdb6c92bd26bc4d66308a7c610c
--- /dev/null
+++ b/tests/test_ris_config.py
@@ -0,0 +1,58 @@
+import json
+import tempfile
+import unittest
+from pathlib import Path
+
+import yaml
+
+from app.ris.ris_config import (
+    compute_ris_lab_config_hash,
+    resolve_and_snapshot_ris_lab_config,
+    resolve_ris_lab_config,
+)
+
+
+class TestRisLabConfig(unittest.TestCase):
+    def test_minimal_config_resolves_defaults(self) -> None:
+        resolved = resolve_ris_lab_config(
+            {"geometry": {"nx": 4, "ny": 2, "dx": 0.5, "dy": 0.25}}
+        )
+        self.assertEqual(resolved["control"]["mode"], "uniform")
+        self.assertEqual(resolved["quantization"]["bits"], 0)
+        self.assertEqual(resolved["validation"]["rmse_db_max"], 2.0)
+        self.assertEqual(resolved["output"]["base_dir"], "outputs")
+
+    def test_missing_geometry_fields_reports_required(self) -> None:
+        with self.assertRaises(ValueError) as ctx:
+            resolve_ris_lab_config({"geometry": {"nx": 4}})
+        message = str(ctx.exception)
+        self.assertIn("geometry.ny", message)
+        self.assertIn("geometry.dx", message)
+        self.assertIn("geometry.dy", message)
+
+    def test_snapshot_writes_config_files_and_summary(self) -> None:
+        with tempfile.TemporaryDirectory() as tmpdir:
+            tmp_path = Path(tmpdir)
+            config_path = tmp_path / "ris.yaml"
+            yaml.safe_dump(
+                {
+                    "geometry": {"nx": 2, "ny": 2, "dx": 0.1, "dy": 0.2},
+                    "output": {"base_dir": tmpdir, "run_id": "unit-test"},
+                },
+                config_path.open("w", encoding="utf-8"),
+                sort_keys=False,
+            )
+
+            config, output_dir, summary = resolve_and_snapshot_ris_lab_config(config_path)
+            self.assertEqual(output_dir, tmp_path / "unit-test")
+            self.assertTrue((output_dir / "config.yaml").exists())
+            self.assertTrue((output_dir / "config.json").exists())
+            self.assertTrue((output_dir / "summary.json").exists())
+            self.assertEqual(summary["config"]["hash_sha256"], compute_ris_lab_config_hash(config))
+
+            loaded = json.loads((output_dir / "config.json").read_text(encoding="utf-8"))
+            self.assertEqual(loaded["geometry"]["nx"], 2)
+
+
+if __name__ == "__main__":
+    unittest.main()


thinking
**Updating activity log**

Planning to record major code changes into the activity log using Ralph Log for tracking.
exec
/usr/bin/zsh -lc 'ralph log "Implemented RIS Lab config schema and tests"' in /home/josh/Documents/Github/RIS_SIONNA succeeded in 86ms:
Using local templates: /home/josh/Documents/Github/RIS_SIONNA/.agents/ralph
file update:
diff --git a/app/ris/__init__.py b/app/ris/__init__.py
index a34ed971e3d2426533f5eb2eb56416e59d15db65..bafa9ac9ccd2097b564c1c45d7c7b06f3a223b47
--- a/app/ris/__init__.py
+++ b/app/ris/__init__.py
@@ -1,5 +1,13 @@
 """RIS core math primitives and helpers."""
 
+from .ris_config import (  # noqa: F401
+    RIS_LAB_SCHEMA_VERSION,
+    compute_ris_lab_config_hash,
+    load_ris_lab_config,
+    resolve_and_snapshot_ris_lab_config,
+    resolve_ris_lab_config,
+    snapshot_ris_lab_config,
+)
 from .ris_core import (  # noqa: F401
     RisFrame,
     RisGeometry,
diff --git a/app/ris/ris_config.py b/app/ris/ris_config.py
new file mode 100644
index 0000000000000000000000000000000000000000..744c390c8e0c6c83a435e97cc579a09e71756ef6
--- /dev/null
+++ b/app/ris/ris_config.py
@@ -0,0 +1,200 @@
+"""RIS Lab configuration schema and snapshot helpers."""
+
+from __future__ import annotations
+
+import copy
+import hashlib
+import json
+from pathlib import Path
+from typing import Any, Dict, Iterable, Optional
+
+import yaml
+
+from app.io import create_output_dir, save_json, save_yaml
+
+RIS_LAB_SCHEMA_VERSION = 1
+
+DEFAULT_RIS_LAB_CONFIG: Dict[str, Any] = {
+    "schema_version": RIS_LAB_SCHEMA_VERSION,
+    "geometry": {
+        "nx": None,
+        "ny": None,
+        "dx": None,
+        "dy": None,
+        "origin": [0.0, 0.0, 0.0],
+        "normal": [0.0, 0.0, 1.0],
+        "x_axis_hint": [1.0, 0.0, 0.0],
+    },
+    "control": {
+        "mode": "uniform",
+        "params": {"phase_rad": 0.0},
+    },
+    "quantization": {
+        "bits": 0,
+    },
+    "pattern_mode": {
+        "normalization": "peak_0db",
+        "rx_sweep_deg": {"start": -90.0, "stop": 90.0, "step": 2.0},
+    },
+    "link_mode": {
+        "weighting": "inverse_distance",
+        "enabled": False,
+    },
+    "validation": {
+        "normalization": "peak_0db",
+        "rmse_db_max": 2.0,
+        "peak_angle_err_deg_max": 2.0,
+        "peak_db_err_max": 1.5,
+    },
+    "experiment": {
+        "frequency_hz": 28_000_000_000,
+        "tx_incident_angle_deg": -30.0,
+    },
+    "output": {
+        "base_dir": "outputs",
+        "run_id": None,
+    },
+}
+
+_ALIAS_FIELDS = {
+    ("geometry", "nx"): [("geometry", "n")],
+    ("geometry", "ny"): [("geometry", "m")],
+    ("geometry", "dx"): [("geometry", "dx_m")],
+    ("geometry", "dy"): [("geometry", "dy_m")],
+}
+
+
+def _deep_merge(base: Dict[str, Any], override: Dict[str, Any]) -> Dict[str, Any]:
+    for key, value in override.items():
+        if isinstance(value, dict) and isinstance(base.get(key), dict):
+            base[key] = _deep_merge(base[key], value)
+        else:
+            base[key] = value
+    return base
+
+
+def _apply_aliases(config: Dict[str, Any]) -> Dict[str, Any]:
+    updated = copy.deepcopy(config)
+    for (section, key), aliases in _ALIAS_FIELDS.items():
+        section_data = updated.get(section)
+        if not isinstance(section_data, dict):
+            continue
+        if key in section_data:
+            continue
+        for alias_section, alias_key in aliases:
+            alias_data = updated.get(alias_section)
+            if isinstance(alias_data, dict) and alias_key in alias_data:
+                section_data[key] = alias_data[alias_key]
+                break
+        updated[section] = section_data
+    return updated
+
+
+def _missing_required_fields(geometry: Dict[str, Any]) -> list[str]:
+    required = ("nx", "ny", "dx", "dy")
+    missing = []
+    for key in required:
+        value = geometry.get(key)
+        if value is None:
+            missing.append(f"geometry.{key}")
+    return missing
+
+
+def _canonicalize_config(config: Dict[str, Any]) -> Dict[str, Any]:
+    ordered_keys = [
+        "schema_version",
+        "geometry",
+        "control",
+        "quantization",
+        "pattern_mode",
+        "link_mode",
+        "validation",
+        "experiment",
+        "output",
+    ]
+    ordered: Dict[str, Any] = {}
+    for key in ordered_keys:
+        if key in config:
+            ordered[key] = config[key]
+    extras = {k: v for k, v in config.items() if k not in ordered_keys}
+    for key in sorted(extras):
+        ordered[key] = extras[key]
+    return ordered
+
+
+def resolve_ris_lab_config(raw_config: Dict[str, Any]) -> Dict[str, Any]:
+    if not isinstance(raw_config, dict):
+        raise ValueError("RIS Lab config must be a YAML mapping")
+
+    normalized = _apply_aliases(raw_config)
+    resolved = _deep_merge(copy.deepcopy(DEFAULT_RIS_LAB_CONFIG), normalized)
+
+    geometry = resolved.get("geometry")
+    if not isinstance(geometry, dict):
+        raise ValueError("RIS Lab config geometry must be a mapping")
+
+    missing = _missing_required_fields(geometry)
+    if missing:
+        raise ValueError(
+            "RIS Lab config missing required fields: " + ", ".join(missing)
+        )
+
+    return _canonicalize_config(resolved)
+
+
+def load_ris_lab_config(path: str | Path) -> Dict[str, Any]:
+    config_path = Path(path)
+    if not config_path.exists():
+        raise FileNotFoundError(f"RIS Lab config not found: {config_path}")
+    with config_path.open("r", encoding="utf-8") as handle:
+        data = yaml.safe_load(handle)
+    return resolve_ris_lab_config(data)
+
+
+def compute_ris_lab_config_hash(config: Dict[str, Any]) -> str:
+    payload = json.dumps(config, sort_keys=True).encode("utf-8")
+    return hashlib.sha256(payload).hexdigest()
+
+
+def _ensure_output_dir(output_dir: Path) -> Path:
+    output_dir.mkdir(parents=True, exist_ok=True)
+    (output_dir / "plots").mkdir(parents=True, exist_ok=True)
+    (output_dir / "data").mkdir(parents=True, exist_ok=True)
+    return output_dir
+
+
+def snapshot_ris_lab_config(output_dir: Path, config: Dict[str, Any]) -> Dict[str, Any]:
+    output_dir = _ensure_output_dir(output_dir)
+    yaml_path = output_dir / "config.yaml"
+    json_path = output_dir / "config.json"
+    save_yaml(yaml_path, config)
+    save_json(json_path, config)
+
+    config_hash = compute_ris_lab_config_hash(config)
+    summary = {
+        "schema_version": config.get("schema_version", RIS_LAB_SCHEMA_VERSION),
+        "config": {
+            "hash_sha256": config_hash,
+            "path_yaml": str(yaml_path),
+            "path_json": str(json_path),
+        },
+    }
+    save_json(output_dir / "summary.json", summary)
+    return summary
+
+
+def resolve_and_snapshot_ris_lab_config(
+    config_path: str | Path,
+    output_dir: Optional[str | Path] = None,
+) -> tuple[Dict[str, Any], Path, Dict[str, Any]]:
+    config = load_ris_lab_config(config_path)
+    if output_dir is None:
+        output_cfg = config.get("output", {})
+        base_dir = output_cfg.get("base_dir", "outputs")
+        run_id = output_cfg.get("run_id")
+        output_path = create_output_dir(base_dir, run_id=run_id)
+    else:
+        output_path = _ensure_output_dir(Path(output_dir))
+
+    summary = snapshot_ris_lab_config(output_path, config)
+    return config, output_path, summary
diff --git a/tests/test_ris_config.py b/tests/test_ris_config.py
new file mode 100644
index 0000000000000000000000000000000000000000..425e3679bae77cdb6c92bd26bc4d66308a7c610c
--- /dev/null
+++ b/tests/test_ris_config.py
@@ -0,0 +1,58 @@
+import json
+import tempfile
+import unittest
+from pathlib import Path
+
+import yaml
+
+from app.ris.ris_config import (
+    compute_ris_lab_config_hash,
+    resolve_and_snapshot_ris_lab_config,
+    resolve_ris_lab_config,
+)
+
+
+class TestRisLabConfig(unittest.TestCase):
+    def test_minimal_config_resolves_defaults(self) -> None:
+        resolved = resolve_ris_lab_config(
+            {"geometry": {"nx": 4, "ny": 2, "dx": 0.5, "dy": 0.25}}
+        )
+        self.assertEqual(resolved["control"]["mode"], "uniform")
+        self.assertEqual(resolved["quantization"]["bits"], 0)
+        self.assertEqual(resolved["validation"]["rmse_db_max"], 2.0)
+        self.assertEqual(resolved["output"]["base_dir"], "outputs")
+
+    def test_missing_geometry_fields_reports_required(self) -> None:
+        with self.assertRaises(ValueError) as ctx:
+            resolve_ris_lab_config({"geometry": {"nx": 4}})
+        message = str(ctx.exception)
+        self.assertIn("geometry.ny", message)
+        self.assertIn("geometry.dx", message)
+        self.assertIn("geometry.dy", message)
+
+    def test_snapshot_writes_config_files_and_summary(self) -> None:
+        with tempfile.TemporaryDirectory() as tmpdir:
+            tmp_path = Path(tmpdir)
+            config_path = tmp_path / "ris.yaml"
+            yaml.safe_dump(
+                {
+                    "geometry": {"nx": 2, "ny": 2, "dx": 0.1, "dy": 0.2},
+                    "output": {"base_dir": tmpdir, "run_id": "unit-test"},
+                },
+                config_path.open("w", encoding="utf-8"),
+                sort_keys=False,
+            )
+
+            config, output_dir, summary = resolve_and_snapshot_ris_lab_config(config_path)
+            self.assertEqual(output_dir, tmp_path / "unit-test")
+            self.assertTrue((output_dir / "config.yaml").exists())
+            self.assertTrue((output_dir / "config.json").exists())
+            self.assertTrue((output_dir / "summary.json").exists())
+            self.assertEqual(summary["config"]["hash_sha256"], compute_ris_lab_config_hash(config))
+
+            loaded = json.loads((output_dir / "config.json").read_text(encoding="utf-8"))
+            self.assertEqual(loaded["geometry"]["nx"], 2)
+
+
+if __name__ == "__main__":
+    unittest.main()


thinking
**Running tests with pytest**
exec
/usr/bin/zsh -lc 'python -m pytest' in /home/josh/Documents/Github/RIS_SIONNA exited 127 in 2ms:
zsh:1: command not found: python
file update:
diff --git a/app/ris/__init__.py b/app/ris/__init__.py
index a34ed971e3d2426533f5eb2eb56416e59d15db65..bafa9ac9ccd2097b564c1c45d7c7b06f3a223b47
--- a/app/ris/__init__.py
+++ b/app/ris/__init__.py
@@ -1,5 +1,13 @@
 """RIS core math primitives and helpers."""
 
+from .ris_config import (  # noqa: F401
+    RIS_LAB_SCHEMA_VERSION,
+    compute_ris_lab_config_hash,
+    load_ris_lab_config,
+    resolve_and_snapshot_ris_lab_config,
+    resolve_ris_lab_config,
+    snapshot_ris_lab_config,
+)
 from .ris_core import (  # noqa: F401
     RisFrame,
     RisGeometry,
diff --git a/app/ris/ris_config.py b/app/ris/ris_config.py
new file mode 100644
index 0000000000000000000000000000000000000000..744c390c8e0c6c83a435e97cc579a09e71756ef6
--- /dev/null
+++ b/app/ris/ris_config.py
@@ -0,0 +1,200 @@
+"""RIS Lab configuration schema and snapshot helpers."""
+
+from __future__ import annotations
+
+import copy
+import hashlib
+import json
+from pathlib import Path
+from typing import Any, Dict, Iterable, Optional
+
+import yaml
+
+from app.io import create_output_dir, save_json, save_yaml
+
+RIS_LAB_SCHEMA_VERSION = 1
+
+DEFAULT_RIS_LAB_CONFIG: Dict[str, Any] = {
+    "schema_version": RIS_LAB_SCHEMA_VERSION,
+    "geometry": {
+        "nx": None,
+        "ny": None,
+        "dx": None,
+        "dy": None,
+        "origin": [0.0, 0.0, 0.0],
+        "normal": [0.0, 0.0, 1.0],
+        "x_axis_hint": [1.0, 0.0, 0.0],
+    },
+    "control": {
+        "mode": "uniform",
+        "params": {"phase_rad": 0.0},
+    },
+    "quantization": {
+        "bits": 0,
+    },
+    "pattern_mode": {
+        "normalization": "peak_0db",
+        "rx_sweep_deg": {"start": -90.0, "stop": 90.0, "step": 2.0},
+    },
+    "link_mode": {
+        "weighting": "inverse_distance",
+        "enabled": False,
+    },
+    "validation": {
+        "normalization": "peak_0db",
+        "rmse_db_max": 2.0,
+        "peak_angle_err_deg_max": 2.0,
+        "peak_db_err_max": 1.5,
+    },
+    "experiment": {
+        "frequency_hz": 28_000_000_000,
+        "tx_incident_angle_deg": -30.0,
+    },
+    "output": {
+        "base_dir": "outputs",
+        "run_id": None,
+    },
+}
+
+_ALIAS_FIELDS = {
+    ("geometry", "nx"): [("geometry", "n")],
+    ("geometry", "ny"): [("geometry", "m")],
+    ("geometry", "dx"): [("geometry", "dx_m")],
+    ("geometry", "dy"): [("geometry", "dy_m")],
+}
+
+
+def _deep_merge(base: Dict[str, Any], override: Dict[str, Any]) -> Dict[str, Any]:
+    for key, value in override.items():
+        if isinstance(value, dict) and isinstance(base.get(key), dict):
+            base[key] = _deep_merge(base[key], value)
+        else:
+            base[key] = value
+    return base
+
+
+def _apply_aliases(config: Dict[str, Any]) -> Dict[str, Any]:
+    updated = copy.deepcopy(config)
+    for (section, key), aliases in _ALIAS_FIELDS.items():
+        section_data = updated.get(section)
+        if not isinstance(section_data, dict):
+            continue
+        if key in section_data:
+            continue
+        for alias_section, alias_key in aliases:
+            alias_data = updated.get(alias_section)
+            if isinstance(alias_data, dict) and alias_key in alias_data:
+                section_data[key] = alias_data[alias_key]
+                break
+        updated[section] = section_data
+    return updated
+
+
+def _missing_required_fields(geometry: Dict[str, Any]) -> list[str]:
+    required = ("nx", "ny", "dx", "dy")
+    missing = []
+    for key in required:
+        value = geometry.get(key)
+        if value is None:
+            missing.append(f"geometry.{key}")
+    return missing
+
+
+def _canonicalize_config(config: Dict[str, Any]) -> Dict[str, Any]:
+    ordered_keys = [
+        "schema_version",
+        "geometry",
+        "control",
+        "quantization",
+        "pattern_mode",
+        "link_mode",
+        "validation",
+        "experiment",
+        "output",
+    ]
+    ordered: Dict[str, Any] = {}
+    for key in ordered_keys:
+        if key in config:
+            ordered[key] = config[key]
+    extras = {k: v for k, v in config.items() if k not in ordered_keys}
+    for key in sorted(extras):
+        ordered[key] = extras[key]
+    return ordered
+
+
+def resolve_ris_lab_config(raw_config: Dict[str, Any]) -> Dict[str, Any]:
+    if not isinstance(raw_config, dict):
+        raise ValueError("RIS Lab config must be a YAML mapping")
+
+    normalized = _apply_aliases(raw_config)
+    resolved = _deep_merge(copy.deepcopy(DEFAULT_RIS_LAB_CONFIG), normalized)
+
+    geometry = resolved.get("geometry")
+    if not isinstance(geometry, dict):
+        raise ValueError("RIS Lab config geometry must be a mapping")
+
+    missing = _missing_required_fields(geometry)
+    if missing:
+        raise ValueError(
+            "RIS Lab config missing required fields: " + ", ".join(missing)
+        )
+
+    return _canonicalize_config(resolved)
+
+
+def load_ris_lab_config(path: str | Path) -> Dict[str, Any]:
+    config_path = Path(path)
+    if not config_path.exists():
+        raise FileNotFoundError(f"RIS Lab config not found: {config_path}")
+    with config_path.open("r", encoding="utf-8") as handle:
+        data = yaml.safe_load(handle)
+    return resolve_ris_lab_config(data)
+
+
+def compute_ris_lab_config_hash(config: Dict[str, Any]) -> str:
+    payload = json.dumps(config, sort_keys=True).encode("utf-8")
+    return hashlib.sha256(payload).hexdigest()
+
+
+def _ensure_output_dir(output_dir: Path) -> Path:
+    output_dir.mkdir(parents=True, exist_ok=True)
+    (output_dir / "plots").mkdir(parents=True, exist_ok=True)
+    (output_dir / "data").mkdir(parents=True, exist_ok=True)
+    return output_dir
+
+
+def snapshot_ris_lab_config(output_dir: Path, config: Dict[str, Any]) -> Dict[str, Any]:
+    output_dir = _ensure_output_dir(output_dir)
+    yaml_path = output_dir / "config.yaml"
+    json_path = output_dir / "config.json"
+    save_yaml(yaml_path, config)
+    save_json(json_path, config)
+
+    config_hash = compute_ris_lab_config_hash(config)
+    summary = {
+        "schema_version": config.get("schema_version", RIS_LAB_SCHEMA_VERSION),
+        "config": {
+            "hash_sha256": config_hash,
+            "path_yaml": str(yaml_path),
+            "path_json": str(json_path),
+        },
+    }
+    save_json(output_dir / "summary.json", summary)
+    return summary
+
+
+def resolve_and_snapshot_ris_lab_config(
+    config_path: str | Path,
+    output_dir: Optional[str | Path] = None,
+) -> tuple[Dict[str, Any], Path, Dict[str, Any]]:
+    config = load_ris_lab_config(config_path)
+    if output_dir is None:
+        output_cfg = config.get("output", {})
+        base_dir = output_cfg.get("base_dir", "outputs")
+        run_id = output_cfg.get("run_id")
+        output_path = create_output_dir(base_dir, run_id=run_id)
+    else:
+        output_path = _ensure_output_dir(Path(output_dir))
+
+    summary = snapshot_ris_lab_config(output_path, config)
+    return config, output_path, summary
diff --git a/tests/test_ris_config.py b/tests/test_ris_config.py
new file mode 100644
index 0000000000000000000000000000000000000000..425e3679bae77cdb6c92bd26bc4d66308a7c610c
--- /dev/null
+++ b/tests/test_ris_config.py
@@ -0,0 +1,58 @@
+import json
+import tempfile
+import unittest
+from pathlib import Path
+
+import yaml
+
+from app.ris.ris_config import (
+    compute_ris_lab_config_hash,
+    resolve_and_snapshot_ris_lab_config,
+    resolve_ris_lab_config,
+)
+
+
+class TestRisLabConfig(unittest.TestCase):
+    def test_minimal_config_resolves_defaults(self) -> None:
+        resolved = resolve_ris_lab_config(
+            {"geometry": {"nx": 4, "ny": 2, "dx": 0.5, "dy": 0.25}}
+        )
+        self.assertEqual(resolved["control"]["mode"], "uniform")
+        self.assertEqual(resolved["quantization"]["bits"], 0)
+        self.assertEqual(resolved["validation"]["rmse_db_max"], 2.0)
+        self.assertEqual(resolved["output"]["base_dir"], "outputs")
+
+    def test_missing_geometry_fields_reports_required(self) -> None:
+        with self.assertRaises(ValueError) as ctx:
+            resolve_ris_lab_config({"geometry": {"nx": 4}})
+        message = str(ctx.exception)
+        self.assertIn("geometry.ny", message)
+        self.assertIn("geometry.dx", message)
+        self.assertIn("geometry.dy", message)
+
+    def test_snapshot_writes_config_files_and_summary(self) -> None:
+        with tempfile.TemporaryDirectory() as tmpdir:
+            tmp_path = Path(tmpdir)
+            config_path = tmp_path / "ris.yaml"
+            yaml.safe_dump(
+                {
+                    "geometry": {"nx": 2, "ny": 2, "dx": 0.1, "dy": 0.2},
+                    "output": {"base_dir": tmpdir, "run_id": "unit-test"},
+                },
+                config_path.open("w", encoding="utf-8"),
+                sort_keys=False,
+            )
+
+            config, output_dir, summary = resolve_and_snapshot_ris_lab_config(config_path)
+            self.assertEqual(output_dir, tmp_path / "unit-test")
+            self.assertTrue((output_dir / "config.yaml").exists())
+            self.assertTrue((output_dir / "config.json").exists())
+            self.assertTrue((output_dir / "summary.json").exists())
+            self.assertEqual(summary["config"]["hash_sha256"], compute_ris_lab_config_hash(config))
+
+            loaded = json.loads((output_dir / "config.json").read_text(encoding="utf-8"))
+            self.assertEqual(loaded["geometry"]["nx"], 2)
+
+
+if __name__ == "__main__":
+    unittest.main()


thinking
**Handling python vs python3 test command**

The required `python -m pytest` command failed due to missing `python`, so I'll run `python3 -m pytest` to run tests anyway, noting the original command's failure in the run summary but not repeating errors in the error log.
exec
/usr/bin/zsh -lc 'python3 -m pytest' in /home/josh/Documents/Github/RIS_SIONNA exited 1 in 13ms:
/usr/bin/python3: No module named pytest
file update:
diff --git a/app/ris/__init__.py b/app/ris/__init__.py
index a34ed971e3d2426533f5eb2eb56416e59d15db65..bafa9ac9ccd2097b564c1c45d7c7b06f3a223b47
--- a/app/ris/__init__.py
+++ b/app/ris/__init__.py
@@ -1,5 +1,13 @@
 """RIS core math primitives and helpers."""
 
+from .ris_config import (  # noqa: F401
+    RIS_LAB_SCHEMA_VERSION,
+    compute_ris_lab_config_hash,
+    load_ris_lab_config,
+    resolve_and_snapshot_ris_lab_config,
+    resolve_ris_lab_config,
+    snapshot_ris_lab_config,
+)
 from .ris_core import (  # noqa: F401
     RisFrame,
     RisGeometry,
diff --git a/app/ris/ris_config.py b/app/ris/ris_config.py
new file mode 100644
index 0000000000000000000000000000000000000000..744c390c8e0c6c83a435e97cc579a09e71756ef6
--- /dev/null
+++ b/app/ris/ris_config.py
@@ -0,0 +1,200 @@
+"""RIS Lab configuration schema and snapshot helpers."""
+
+from __future__ import annotations
+
+import copy
+import hashlib
+import json
+from pathlib import Path
+from typing import Any, Dict, Iterable, Optional
+
+import yaml
+
+from app.io import create_output_dir, save_json, save_yaml
+
+RIS_LAB_SCHEMA_VERSION = 1
+
+DEFAULT_RIS_LAB_CONFIG: Dict[str, Any] = {
+    "schema_version": RIS_LAB_SCHEMA_VERSION,
+    "geometry": {
+        "nx": None,
+        "ny": None,
+        "dx": None,
+        "dy": None,
+        "origin": [0.0, 0.0, 0.0],
+        "normal": [0.0, 0.0, 1.0],
+        "x_axis_hint": [1.0, 0.0, 0.0],
+    },
+    "control": {
+        "mode": "uniform",
+        "params": {"phase_rad": 0.0},
+    },
+    "quantization": {
+        "bits": 0,
+    },
+    "pattern_mode": {
+        "normalization": "peak_0db",
+        "rx_sweep_deg": {"start": -90.0, "stop": 90.0, "step": 2.0},
+    },
+    "link_mode": {
+        "weighting": "inverse_distance",
+        "enabled": False,
+    },
+    "validation": {
+        "normalization": "peak_0db",
+        "rmse_db_max": 2.0,
+        "peak_angle_err_deg_max": 2.0,
+        "peak_db_err_max": 1.5,
+    },
+    "experiment": {
+        "frequency_hz": 28_000_000_000,
+        "tx_incident_angle_deg": -30.0,
+    },
+    "output": {
+        "base_dir": "outputs",
+        "run_id": None,
+    },
+}
+
+_ALIAS_FIELDS = {
+    ("geometry", "nx"): [("geometry", "n")],
+    ("geometry", "ny"): [("geometry", "m")],
+    ("geometry", "dx"): [("geometry", "dx_m")],
+    ("geometry", "dy"): [("geometry", "dy_m")],
+}
+
+
+def _deep_merge(base: Dict[str, Any], override: Dict[str, Any]) -> Dict[str, Any]:
+    for key, value in override.items():
+        if isinstance(value, dict) and isinstance(base.get(key), dict):
+            base[key] = _deep_merge(base[key], value)
+        else:
+            base[key] = value
+    return base
+
+
+def _apply_aliases(config: Dict[str, Any]) -> Dict[str, Any]:
+    updated = copy.deepcopy(config)
+    for (section, key), aliases in _ALIAS_FIELDS.items():
+        section_data = updated.get(section)
+        if not isinstance(section_data, dict):
+            continue
+        if key in section_data:
+            continue
+        for alias_section, alias_key in aliases:
+            alias_data = updated.get(alias_section)
+            if isinstance(alias_data, dict) and alias_key in alias_data:
+                section_data[key] = alias_data[alias_key]
+                break
+        updated[section] = section_data
+    return updated
+
+
+def _missing_required_fields(geometry: Dict[str, Any]) -> list[str]:
+    required = ("nx", "ny", "dx", "dy")
+    missing = []
+    for key in required:
+        value = geometry.get(key)
+        if value is None:
+            missing.append(f"geometry.{key}")
+    return missing
+
+
+def _canonicalize_config(config: Dict[str, Any]) -> Dict[str, Any]:
+    ordered_keys = [
+        "schema_version",
+        "geometry",
+        "control",
+        "quantization",
+        "pattern_mode",
+        "link_mode",
+        "validation",
+        "experiment",
+        "output",
+    ]
+    ordered: Dict[str, Any] = {}
+    for key in ordered_keys:
+        if key in config:
+            ordered[key] = config[key]
+    extras = {k: v for k, v in config.items() if k not in ordered_keys}
+    for key in sorted(extras):
+        ordered[key] = extras[key]
+    return ordered
+
+
+def resolve_ris_lab_config(raw_config: Dict[str, Any]) -> Dict[str, Any]:
+    if not isinstance(raw_config, dict):
+        raise ValueError("RIS Lab config must be a YAML mapping")
+
+    normalized = _apply_aliases(raw_config)
+    resolved = _deep_merge(copy.deepcopy(DEFAULT_RIS_LAB_CONFIG), normalized)
+
+    geometry = resolved.get("geometry")
+    if not isinstance(geometry, dict):
+        raise ValueError("RIS Lab config geometry must be a mapping")
+
+    missing = _missing_required_fields(geometry)
+    if missing:
+        raise ValueError(
+            "RIS Lab config missing required fields: " + ", ".join(missing)
+        )
+
+    return _canonicalize_config(resolved)
+
+
+def load_ris_lab_config(path: str | Path) -> Dict[str, Any]:
+    config_path = Path(path)
+    if not config_path.exists():
+        raise FileNotFoundError(f"RIS Lab config not found: {config_path}")
+    with config_path.open("r", encoding="utf-8") as handle:
+        data = yaml.safe_load(handle)
+    return resolve_ris_lab_config(data)
+
+
+def compute_ris_lab_config_hash(config: Dict[str, Any]) -> str:
+    payload = json.dumps(config, sort_keys=True).encode("utf-8")
+    return hashlib.sha256(payload).hexdigest()
+
+
+def _ensure_output_dir(output_dir: Path) -> Path:
+    output_dir.mkdir(parents=True, exist_ok=True)
+    (output_dir / "plots").mkdir(parents=True, exist_ok=True)
+    (output_dir / "data").mkdir(parents=True, exist_ok=True)
+    return output_dir
+
+
+def snapshot_ris_lab_config(output_dir: Path, config: Dict[str, Any]) -> Dict[str, Any]:
+    output_dir = _ensure_output_dir(output_dir)
+    yaml_path = output_dir / "config.yaml"
+    json_path = output_dir / "config.json"
+    save_yaml(yaml_path, config)
+    save_json(json_path, config)
+
+    config_hash = compute_ris_lab_config_hash(config)
+    summary = {
+        "schema_version": config.get("schema_version", RIS_LAB_SCHEMA_VERSION),
+        "config": {
+            "hash_sha256": config_hash,
+            "path_yaml": str(yaml_path),
+            "path_json": str(json_path),
+        },
+    }
+    save_json(output_dir / "summary.json", summary)
+    return summary
+
+
+def resolve_and_snapshot_ris_lab_config(
+    config_path: str | Path,
+    output_dir: Optional[str | Path] = None,
+) -> tuple[Dict[str, Any], Path, Dict[str, Any]]:
+    config = load_ris_lab_config(config_path)
+    if output_dir is None:
+        output_cfg = config.get("output", {})
+        base_dir = output_cfg.get("base_dir", "outputs")
+        run_id = output_cfg.get("run_id")
+        output_path = create_output_dir(base_dir, run_id=run_id)
+    else:
+        output_path = _ensure_output_dir(Path(output_dir))
+
+    summary = snapshot_ris_lab_config(output_path, config)
+    return config, output_path, summary
diff --git a/tests/test_ris_config.py b/tests/test_ris_config.py
new file mode 100644
index 0000000000000000000000000000000000000000..425e3679bae77cdb6c92bd26bc4d66308a7c610c
--- /dev/null
+++ b/tests/test_ris_config.py
@@ -0,0 +1,58 @@
+import json
+import tempfile
+import unittest
+from pathlib import Path
+
+import yaml
+
+from app.ris.ris_config import (
+    compute_ris_lab_config_hash,
+    resolve_and_snapshot_ris_lab_config,
+    resolve_ris_lab_config,
+)
+
+
+class TestRisLabConfig(unittest.TestCase):
+    def test_minimal_config_resolves_defaults(self) -> None:
+        resolved = resolve_ris_lab_config(
+            {"geometry": {"nx": 4, "ny": 2, "dx": 0.5, "dy": 0.25}}
+        )
+        self.assertEqual(resolved["control"]["mode"], "uniform")
+        self.assertEqual(resolved["quantization"]["bits"], 0)
+        self.assertEqual(resolved["validation"]["rmse_db_max"], 2.0)
+        self.assertEqual(resolved["output"]["base_dir"], "outputs")
+
+    def test_missing_geometry_fields_reports_required(self) -> None:
+        with self.assertRaises(ValueError) as ctx:
+            resolve_ris_lab_config({"geometry": {"nx": 4}})
+        message = str(ctx.exception)
+        self.assertIn("geometry.ny", message)
+        self.assertIn("geometry.dx", message)
+        self.assertIn("geometry.dy", message)
+
+    def test_snapshot_writes_config_files_and_summary(self) -> None:
+        with tempfile.TemporaryDirectory() as tmpdir:
+            tmp_path = Path(tmpdir)
+            config_path = tmp_path / "ris.yaml"
+            yaml.safe_dump(
+                {
+                    "geometry": {"nx": 2, "ny": 2, "dx": 0.1, "dy": 0.2},
+                    "output": {"base_dir": tmpdir, "run_id": "unit-test"},
+                },
+                config_path.open("w", encoding="utf-8"),
+                sort_keys=False,
+            )
+
+            config, output_dir, summary = resolve_and_snapshot_ris_lab_config(config_path)
+            self.assertEqual(output_dir, tmp_path / "unit-test")
+            self.assertTrue((output_dir / "config.yaml").exists())
+            self.assertTrue((output_dir / "config.json").exists())
+            self.assertTrue((output_dir / "summary.json").exists())
+            self.assertEqual(summary["config"]["hash_sha256"], compute_ris_lab_config_hash(config))
+
+            loaded = json.loads((output_dir / "config.json").read_text(encoding="utf-8"))
+            self.assertEqual(loaded["geometry"]["nx"], 2)
+
+
+if __name__ == "__main__":
+    unittest.main()


thinking
**Checking for pytest in existing virtual environment**

I'm verifying if pytest is available in the `.venv` directory to avoid installing it unnecessarily before running tests.
exec
/usr/bin/zsh -lc '.venv/bin/python -m pytest' in /home/josh/Documents/Github/RIS_SIONNA exited 1 in 22ms:
/home/josh/Documents/Github/RIS_SIONNA/.venv/bin/python: No module named pytest
file update:
diff --git a/app/ris/__init__.py b/app/ris/__init__.py
index a34ed971e3d2426533f5eb2eb56416e59d15db65..bafa9ac9ccd2097b564c1c45d7c7b06f3a223b47
--- a/app/ris/__init__.py
+++ b/app/ris/__init__.py
@@ -1,5 +1,13 @@
 """RIS core math primitives and helpers."""
 
+from .ris_config import (  # noqa: F401
+    RIS_LAB_SCHEMA_VERSION,
+    compute_ris_lab_config_hash,
+    load_ris_lab_config,
+    resolve_and_snapshot_ris_lab_config,
+    resolve_ris_lab_config,
+    snapshot_ris_lab_config,
+)
 from .ris_core import (  # noqa: F401
     RisFrame,
     RisGeometry,
diff --git a/app/ris/ris_config.py b/app/ris/ris_config.py
new file mode 100644
index 0000000000000000000000000000000000000000..744c390c8e0c6c83a435e97cc579a09e71756ef6
--- /dev/null
+++ b/app/ris/ris_config.py
@@ -0,0 +1,200 @@
+"""RIS Lab configuration schema and snapshot helpers."""
+
+from __future__ import annotations
+
+import copy
+import hashlib
+import json
+from pathlib import Path
+from typing import Any, Dict, Iterable, Optional
+
+import yaml
+
+from app.io import create_output_dir, save_json, save_yaml
+
+RIS_LAB_SCHEMA_VERSION = 1
+
+DEFAULT_RIS_LAB_CONFIG: Dict[str, Any] = {
+    "schema_version": RIS_LAB_SCHEMA_VERSION,
+    "geometry": {
+        "nx": None,
+        "ny": None,
+        "dx": None,
+        "dy": None,
+        "origin": [0.0, 0.0, 0.0],
+        "normal": [0.0, 0.0, 1.0],
+        "x_axis_hint": [1.0, 0.0, 0.0],
+    },
+    "control": {
+        "mode": "uniform",
+        "params": {"phase_rad": 0.0},
+    },
+    "quantization": {
+        "bits": 0,
+    },
+    "pattern_mode": {
+        "normalization": "peak_0db",
+        "rx_sweep_deg": {"start": -90.0, "stop": 90.0, "step": 2.0},
+    },
+    "link_mode": {
+        "weighting": "inverse_distance",
+        "enabled": False,
+    },
+    "validation": {
+        "normalization": "peak_0db",
+        "rmse_db_max": 2.0,
+        "peak_angle_err_deg_max": 2.0,
+        "peak_db_err_max": 1.5,
+    },
+    "experiment": {
+        "frequency_hz": 28_000_000_000,
+        "tx_incident_angle_deg": -30.0,
+    },
+    "output": {
+        "base_dir": "outputs",
+        "run_id": None,
+    },
+}
+
+_ALIAS_FIELDS = {
+    ("geometry", "nx"): [("geometry", "n")],
+    ("geometry", "ny"): [("geometry", "m")],
+    ("geometry", "dx"): [("geometry", "dx_m")],
+    ("geometry", "dy"): [("geometry", "dy_m")],
+}
+
+
+def _deep_merge(base: Dict[str, Any], override: Dict[str, Any]) -> Dict[str, Any]:
+    for key, value in override.items():
+        if isinstance(value, dict) and isinstance(base.get(key), dict):
+            base[key] = _deep_merge(base[key], value)
+        else:
+            base[key] = value
+    return base
+
+
+def _apply_aliases(config: Dict[str, Any]) -> Dict[str, Any]:
+    updated = copy.deepcopy(config)
+    for (section, key), aliases in _ALIAS_FIELDS.items():
+        section_data = updated.get(section)
+        if not isinstance(section_data, dict):
+            continue
+        if key in section_data:
+            continue
+        for alias_section, alias_key in aliases:
+            alias_data = updated.get(alias_section)
+            if isinstance(alias_data, dict) and alias_key in alias_data:
+                section_data[key] = alias_data[alias_key]
+                break
+        updated[section] = section_data
+    return updated
+
+
+def _missing_required_fields(geometry: Dict[str, Any]) -> list[str]:
+    required = ("nx", "ny", "dx", "dy")
+    missing = []
+    for key in required:
+        value = geometry.get(key)
+        if value is None:
+            missing.append(f"geometry.{key}")
+    return missing
+
+
+def _canonicalize_config(config: Dict[str, Any]) -> Dict[str, Any]:
+    ordered_keys = [
+        "schema_version",
+        "geometry",
+        "control",
+        "quantization",
+        "pattern_mode",
+        "link_mode",
+        "validation",
+        "experiment",
+        "output",
+    ]
+    ordered: Dict[str, Any] = {}
+    for key in ordered_keys:
+        if key in config:
+            ordered[key] = config[key]
+    extras = {k: v for k, v in config.items() if k not in ordered_keys}
+    for key in sorted(extras):
+        ordered[key] = extras[key]
+    return ordered
+
+
+def resolve_ris_lab_config(raw_config: Dict[str, Any]) -> Dict[str, Any]:
+    if not isinstance(raw_config, dict):
+        raise ValueError("RIS Lab config must be a YAML mapping")
+
+    normalized = _apply_aliases(raw_config)
+    resolved = _deep_merge(copy.deepcopy(DEFAULT_RIS_LAB_CONFIG), normalized)
+
+    geometry = resolved.get("geometry")
+    if not isinstance(geometry, dict):
+        raise ValueError("RIS Lab config geometry must be a mapping")
+
+    missing = _missing_required_fields(geometry)
+    if missing:
+        raise ValueError(
+            "RIS Lab config missing required fields: " + ", ".join(missing)
+        )
+
+    return _canonicalize_config(resolved)
+
+
+def load_ris_lab_config(path: str | Path) -> Dict[str, Any]:
+    config_path = Path(path)
+    if not config_path.exists():
+        raise FileNotFoundError(f"RIS Lab config not found: {config_path}")
+    with config_path.open("r", encoding="utf-8") as handle:
+        data = yaml.safe_load(handle)
+    return resolve_ris_lab_config(data)
+
+
+def compute_ris_lab_config_hash(config: Dict[str, Any]) -> str:
+    payload = json.dumps(config, sort_keys=True).encode("utf-8")
+    return hashlib.sha256(payload).hexdigest()
+
+
+def _ensure_output_dir(output_dir: Path) -> Path:
+    output_dir.mkdir(parents=True, exist_ok=True)
+    (output_dir / "plots").mkdir(parents=True, exist_ok=True)
+    (output_dir / "data").mkdir(parents=True, exist_ok=True)
+    return output_dir
+
+
+def snapshot_ris_lab_config(output_dir: Path, config: Dict[str, Any]) -> Dict[str, Any]:
+    output_dir = _ensure_output_dir(output_dir)
+    yaml_path = output_dir / "config.yaml"
+    json_path = output_dir / "config.json"
+    save_yaml(yaml_path, config)
+    save_json(json_path, config)
+
+    config_hash = compute_ris_lab_config_hash(config)
+    summary = {
+        "schema_version": config.get("schema_version", RIS_LAB_SCHEMA_VERSION),
+        "config": {
+            "hash_sha256": config_hash,
+            "path_yaml": str(yaml_path),
+            "path_json": str(json_path),
+        },
+    }
+    save_json(output_dir / "summary.json", summary)
+    return summary
+
+
+def resolve_and_snapshot_ris_lab_config(
+    config_path: str | Path,
+    output_dir: Optional[str | Path] = None,
+) -> tuple[Dict[str, Any], Path, Dict[str, Any]]:
+    config = load_ris_lab_config(config_path)
+    if output_dir is None:
+        output_cfg = config.get("output", {})
+        base_dir = output_cfg.get("base_dir", "outputs")
+        run_id = output_cfg.get("run_id")
+        output_path = create_output_dir(base_dir, run_id=run_id)
+    else:
+        output_path = _ensure_output_dir(Path(output_dir))
+
+    summary = snapshot_ris_lab_config(output_path, config)
+    return config, output_path, summary
diff --git a/tests/test_ris_config.py b/tests/test_ris_config.py
new file mode 100644
index 0000000000000000000000000000000000000000..425e3679bae77cdb6c92bd26bc4d66308a7c610c
--- /dev/null
+++ b/tests/test_ris_config.py
@@ -0,0 +1,58 @@
+import json
+import tempfile
+import unittest
+from pathlib import Path
+
+import yaml
+
+from app.ris.ris_config import (
+    compute_ris_lab_config_hash,
+    resolve_and_snapshot_ris_lab_config,
+    resolve_ris_lab_config,
+)
+
+
+class TestRisLabConfig(unittest.TestCase):
+    def test_minimal_config_resolves_defaults(self) -> None:
+        resolved = resolve_ris_lab_config(
+            {"geometry": {"nx": 4, "ny": 2, "dx": 0.5, "dy": 0.25}}
+        )
+        self.assertEqual(resolved["control"]["mode"], "uniform")
+        self.assertEqual(resolved["quantization"]["bits"], 0)
+        self.assertEqual(resolved["validation"]["rmse_db_max"], 2.0)
+        self.assertEqual(resolved["output"]["base_dir"], "outputs")
+
+    def test_missing_geometry_fields_reports_required(self) -> None:
+        with self.assertRaises(ValueError) as ctx:
+            resolve_ris_lab_config({"geometry": {"nx": 4}})
+        message = str(ctx.exception)
+        self.assertIn("geometry.ny", message)
+        self.assertIn("geometry.dx", message)
+        self.assertIn("geometry.dy", message)
+
+    def test_snapshot_writes_config_files_and_summary(self) -> None:
+        with tempfile.TemporaryDirectory() as tmpdir:
+            tmp_path = Path(tmpdir)
+            config_path = tmp_path / "ris.yaml"
+            yaml.safe_dump(
+                {
+                    "geometry": {"nx": 2, "ny": 2, "dx": 0.1, "dy": 0.2},
+                    "output": {"base_dir": tmpdir, "run_id": "unit-test"},
+                },
+                config_path.open("w", encoding="utf-8"),
+                sort_keys=False,
+            )
+
+            config, output_dir, summary = resolve_and_snapshot_ris_lab_config(config_path)
+            self.assertEqual(output_dir, tmp_path / "unit-test")
+            self.assertTrue((output_dir / "config.yaml").exists())
+            self.assertTrue((output_dir / "config.json").exists())
+            self.assertTrue((output_dir / "summary.json").exists())
+            self.assertEqual(summary["config"]["hash_sha256"], compute_ris_lab_config_hash(config))
+
+            loaded = json.loads((output_dir / "config.json").read_text(encoding="utf-8"))
+            self.assertEqual(loaded["geometry"]["nx"], 2)
+
+
+if __name__ == "__main__":
+    unittest.main()


thinking
**Installing pytest in virtual environment**

I'm installing pytest in the virtual environment using pip for testing purposes, ensuring the process is non-interactive and won't affect the repository files.
exec
/usr/bin/zsh -lc '.venv/bin/pip install pytest' in /home/josh/Documents/Github/RIS_SIONNA succeeded in 1.33s:
Collecting pytest
  Downloading pytest-9.0.2-py3-none-any.whl.metadata (7.6 kB)
Collecting iniconfig>=1.0.1 (from pytest)
  Downloading iniconfig-2.3.0-py3-none-any.whl.metadata (2.5 kB)
Requirement already satisfied: packaging>=22 in ./.venv/lib/python3.12/site-packages (from pytest) (25.0)
Collecting pluggy<2,>=1.5 (from pytest)
  Downloading pluggy-1.6.0-py3-none-any.whl.metadata (4.8 kB)
Requirement already satisfied: pygments>=2.7.2 in ./.venv/lib/python3.12/site-packages (from pytest) (2.19.2)
Downloading pytest-9.0.2-py3-none-any.whl (374 kB)
Downloading pluggy-1.6.0-py3-none-any.whl (20 kB)
Downloading iniconfig-2.3.0-py3-none-any.whl (7.5 kB)
Installing collected packages: pluggy, iniconfig, pytest

Successfully installed iniconfig-2.3.0 pluggy-1.6.0 pytest-9.0.2
file update:
diff --git a/app/ris/__init__.py b/app/ris/__init__.py
index a34ed971e3d2426533f5eb2eb56416e59d15db65..bafa9ac9ccd2097b564c1c45d7c7b06f3a223b47
--- a/app/ris/__init__.py
+++ b/app/ris/__init__.py
@@ -1,5 +1,13 @@
 """RIS core math primitives and helpers."""
 
+from .ris_config import (  # noqa: F401
+    RIS_LAB_SCHEMA_VERSION,
+    compute_ris_lab_config_hash,
+    load_ris_lab_config,
+    resolve_and_snapshot_ris_lab_config,
+    resolve_ris_lab_config,
+    snapshot_ris_lab_config,
+)
 from .ris_core import (  # noqa: F401
     RisFrame,
     RisGeometry,
diff --git a/app/ris/ris_config.py b/app/ris/ris_config.py
new file mode 100644
index 0000000000000000000000000000000000000000..744c390c8e0c6c83a435e97cc579a09e71756ef6
--- /dev/null
+++ b/app/ris/ris_config.py
@@ -0,0 +1,200 @@
+"""RIS Lab configuration schema and snapshot helpers."""
+
+from __future__ import annotations
+
+import copy
+import hashlib
+import json
+from pathlib import Path
+from typing import Any, Dict, Iterable, Optional
+
+import yaml
+
+from app.io import create_output_dir, save_json, save_yaml
+
+RIS_LAB_SCHEMA_VERSION = 1
+
+DEFAULT_RIS_LAB_CONFIG: Dict[str, Any] = {
+    "schema_version": RIS_LAB_SCHEMA_VERSION,
+    "geometry": {
+        "nx": None,
+        "ny": None,
+        "dx": None,
+        "dy": None,
+        "origin": [0.0, 0.0, 0.0],
+        "normal": [0.0, 0.0, 1.0],
+        "x_axis_hint": [1.0, 0.0, 0.0],
+    },
+    "control": {
+        "mode": "uniform",
+        "params": {"phase_rad": 0.0},
+    },
+    "quantization": {
+        "bits": 0,
+    },
+    "pattern_mode": {
+        "normalization": "peak_0db",
+        "rx_sweep_deg": {"start": -90.0, "stop": 90.0, "step": 2.0},
+    },
+    "link_mode": {
+        "weighting": "inverse_distance",
+        "enabled": False,
+    },
+    "validation": {
+        "normalization": "peak_0db",
+        "rmse_db_max": 2.0,
+        "peak_angle_err_deg_max": 2.0,
+        "peak_db_err_max": 1.5,
+    },
+    "experiment": {
+        "frequency_hz": 28_000_000_000,
+        "tx_incident_angle_deg": -30.0,
+    },
+    "output": {
+        "base_dir": "outputs",
+        "run_id": None,
+    },
+}
+
+_ALIAS_FIELDS = {
+    ("geometry", "nx"): [("geometry", "n")],
+    ("geometry", "ny"): [("geometry", "m")],
+    ("geometry", "dx"): [("geometry", "dx_m")],
+    ("geometry", "dy"): [("geometry", "dy_m")],
+}
+
+
+def _deep_merge(base: Dict[str, Any], override: Dict[str, Any]) -> Dict[str, Any]:
+    for key, value in override.items():
+        if isinstance(value, dict) and isinstance(base.get(key), dict):
+            base[key] = _deep_merge(base[key], value)
+        else:
+            base[key] = value
+    return base
+
+
+def _apply_aliases(config: Dict[str, Any]) -> Dict[str, Any]:
+    updated = copy.deepcopy(config)
+    for (section, key), aliases in _ALIAS_FIELDS.items():
+        section_data = updated.get(section)
+        if not isinstance(section_data, dict):
+            continue
+        if key in section_data:
+            continue
+        for alias_section, alias_key in aliases:
+            alias_data = updated.get(alias_section)
+            if isinstance(alias_data, dict) and alias_key in alias_data:
+                section_data[key] = alias_data[alias_key]
+                break
+        updated[section] = section_data
+    return updated
+
+
+def _missing_required_fields(geometry: Dict[str, Any]) -> list[str]:
+    required = ("nx", "ny", "dx", "dy")
+    missing = []
+    for key in required:
+        value = geometry.get(key)
+        if value is None:
+            missing.append(f"geometry.{key}")
+    return missing
+
+
+def _canonicalize_config(config: Dict[str, Any]) -> Dict[str, Any]:
+    ordered_keys = [
+        "schema_version",
+        "geometry",
+        "control",
+        "quantization",
+        "pattern_mode",
+        "link_mode",
+        "validation",
+        "experiment",
+        "output",
+    ]
+    ordered: Dict[str, Any] = {}
+    for key in ordered_keys:
+        if key in config:
+            ordered[key] = config[key]
+    extras = {k: v for k, v in config.items() if k not in ordered_keys}
+    for key in sorted(extras):
+        ordered[key] = extras[key]
+    return ordered
+
+
+def resolve_ris_lab_config(raw_config: Dict[str, Any]) -> Dict[str, Any]:
+    if not isinstance(raw_config, dict):
+        raise ValueError("RIS Lab config must be a YAML mapping")
+
+    normalized = _apply_aliases(raw_config)
+    resolved = _deep_merge(copy.deepcopy(DEFAULT_RIS_LAB_CONFIG), normalized)
+
+    geometry = resolved.get("geometry")
+    if not isinstance(geometry, dict):
+        raise ValueError("RIS Lab config geometry must be a mapping")
+
+    missing = _missing_required_fields(geometry)
+    if missing:
+        raise ValueError(
+            "RIS Lab config missing required fields: " + ", ".join(missing)
+        )
+
+    return _canonicalize_config(resolved)
+
+
+def load_ris_lab_config(path: str | Path) -> Dict[str, Any]:
+    config_path = Path(path)
+    if not config_path.exists():
+        raise FileNotFoundError(f"RIS Lab config not found: {config_path}")
+    with config_path.open("r", encoding="utf-8") as handle:
+        data = yaml.safe_load(handle)
+    return resolve_ris_lab_config(data)
+
+
+def compute_ris_lab_config_hash(config: Dict[str, Any]) -> str:
+    payload = json.dumps(config, sort_keys=True).encode("utf-8")
+    return hashlib.sha256(payload).hexdigest()
+
+
+def _ensure_output_dir(output_dir: Path) -> Path:
+    output_dir.mkdir(parents=True, exist_ok=True)
+    (output_dir / "plots").mkdir(parents=True, exist_ok=True)
+    (output_dir / "data").mkdir(parents=True, exist_ok=True)
+    return output_dir
+
+
+def snapshot_ris_lab_config(output_dir: Path, config: Dict[str, Any]) -> Dict[str, Any]:
+    output_dir = _ensure_output_dir(output_dir)
+    yaml_path = output_dir / "config.yaml"
+    json_path = output_dir / "config.json"
+    save_yaml(yaml_path, config)
+    save_json(json_path, config)
+
+    config_hash = compute_ris_lab_config_hash(config)
+    summary = {
+        "schema_version": config.get("schema_version", RIS_LAB_SCHEMA_VERSION),
+        "config": {
+            "hash_sha256": config_hash,
+            "path_yaml": str(yaml_path),
+            "path_json": str(json_path),
+        },
+    }
+    save_json(output_dir / "summary.json", summary)
+    return summary
+
+
+def resolve_and_snapshot_ris_lab_config(
+    config_path: str | Path,
+    output_dir: Optional[str | Path] = None,
+) -> tuple[Dict[str, Any], Path, Dict[str, Any]]:
+    config = load_ris_lab_config(config_path)
+    if output_dir is None:
+        output_cfg = config.get("output", {})
+        base_dir = output_cfg.get("base_dir", "outputs")
+        run_id = output_cfg.get("run_id")
+        output_path = create_output_dir(base_dir, run_id=run_id)
+    else:
+        output_path = _ensure_output_dir(Path(output_dir))
+
+    summary = snapshot_ris_lab_config(output_path, config)
+    return config, output_path, summary
diff --git a/tests/test_ris_config.py b/tests/test_ris_config.py
new file mode 100644
index 0000000000000000000000000000000000000000..425e3679bae77cdb6c92bd26bc4d66308a7c610c
--- /dev/null
+++ b/tests/test_ris_config.py
@@ -0,0 +1,58 @@
+import json
+import tempfile
+import unittest
+from pathlib import Path
+
+import yaml
+
+from app.ris.ris_config import (
+    compute_ris_lab_config_hash,
+    resolve_and_snapshot_ris_lab_config,
+    resolve_ris_lab_config,
+)
+
+
+class TestRisLabConfig(unittest.TestCase):
+    def test_minimal_config_resolves_defaults(self) -> None:
+        resolved = resolve_ris_lab_config(
+            {"geometry": {"nx": 4, "ny": 2, "dx": 0.5, "dy": 0.25}}
+        )
+        self.assertEqual(resolved["control"]["mode"], "uniform")
+        self.assertEqual(resolved["quantization"]["bits"], 0)
+        self.assertEqual(resolved["validation"]["rmse_db_max"], 2.0)
+        self.assertEqual(resolved["output"]["base_dir"], "outputs")
+
+    def test_missing_geometry_fields_reports_required(self) -> None:
+        with self.assertRaises(ValueError) as ctx:
+            resolve_ris_lab_config({"geometry": {"nx": 4}})
+        message = str(ctx.exception)
+        self.assertIn("geometry.ny", message)
+        self.assertIn("geometry.dx", message)
+        self.assertIn("geometry.dy", message)
+
+    def test_snapshot_writes_config_files_and_summary(self) -> None:
+        with tempfile.TemporaryDirectory() as tmpdir:
+            tmp_path = Path(tmpdir)
+            config_path = tmp_path / "ris.yaml"
+            yaml.safe_dump(
+                {
+                    "geometry": {"nx": 2, "ny": 2, "dx": 0.1, "dy": 0.2},
+                    "output": {"base_dir": tmpdir, "run_id": "unit-test"},
+                },
+                config_path.open("w", encoding="utf-8"),
+                sort_keys=False,
+            )
+
+            config, output_dir, summary = resolve_and_snapshot_ris_lab_config(config_path)
+            self.assertEqual(output_dir, tmp_path / "unit-test")
+            self.assertTrue((output_dir / "config.yaml").exists())
+            self.assertTrue((output_dir / "config.json").exists())
+            self.assertTrue((output_dir / "summary.json").exists())
+            self.assertEqual(summary["config"]["hash_sha256"], compute_ris_lab_config_hash(config))
+
+            loaded = json.loads((output_dir / "config.json").read_text(encoding="utf-8"))
+            self.assertEqual(loaded["geometry"]["nx"], 2)
+
+
+if __name__ == "__main__":
+    unittest.main()


thinking
**Rerunning tests with virtual environment Python**
exec
/usr/bin/zsh -lc '.venv/bin/python -m pytest' in /home/josh/Documents/Github/RIS_SIONNA succeeded in 522ms:
============================= test session starts ==============================
platform linux -- Python 3.12.3, pytest-9.0.2, pluggy-1.6.0
rootdir: /home/josh/Documents/Github/RIS_SIONNA
configfile: pyproject.toml
collected 11 items

tests/test_alignment.py ..                                               [ 18%]
tests/test_ris_config.py ...                                             [ 45%]
tests/test_ris_core.py ......                                            [100%]

============================== 11 passed in 0.34s ==============================
file update:
diff --git a/app/ris/__init__.py b/app/ris/__init__.py
index a34ed971e3d2426533f5eb2eb56416e59d15db65..bafa9ac9ccd2097b564c1c45d7c7b06f3a223b47
--- a/app/ris/__init__.py
+++ b/app/ris/__init__.py
@@ -1,5 +1,13 @@
 """RIS core math primitives and helpers."""
 
+from .ris_config import (  # noqa: F401
+    RIS_LAB_SCHEMA_VERSION,
+    compute_ris_lab_config_hash,
+    load_ris_lab_config,
+    resolve_and_snapshot_ris_lab_config,
+    resolve_ris_lab_config,
+    snapshot_ris_lab_config,
+)
 from .ris_core import (  # noqa: F401
     RisFrame,
     RisGeometry,
diff --git a/app/ris/ris_config.py b/app/ris/ris_config.py
new file mode 100644
index 0000000000000000000000000000000000000000..744c390c8e0c6c83a435e97cc579a09e71756ef6
--- /dev/null
+++ b/app/ris/ris_config.py
@@ -0,0 +1,200 @@
+"""RIS Lab configuration schema and snapshot helpers."""
+
+from __future__ import annotations
+
+import copy
+import hashlib
+import json
+from pathlib import Path
+from typing import Any, Dict, Iterable, Optional
+
+import yaml
+
+from app.io import create_output_dir, save_json, save_yaml
+
+RIS_LAB_SCHEMA_VERSION = 1
+
+DEFAULT_RIS_LAB_CONFIG: Dict[str, Any] = {
+    "schema_version": RIS_LAB_SCHEMA_VERSION,
+    "geometry": {
+        "nx": None,
+        "ny": None,
+        "dx": None,
+        "dy": None,
+        "origin": [0.0, 0.0, 0.0],
+        "normal": [0.0, 0.0, 1.0],
+        "x_axis_hint": [1.0, 0.0, 0.0],
+    },
+    "control": {
+        "mode": "uniform",
+        "params": {"phase_rad": 0.0},
+    },
+    "quantization": {
+        "bits": 0,
+    },
+    "pattern_mode": {
+        "normalization": "peak_0db",
+        "rx_sweep_deg": {"start": -90.0, "stop": 90.0, "step": 2.0},
+    },
+    "link_mode": {
+        "weighting": "inverse_distance",
+        "enabled": False,
+    },
+    "validation": {
+        "normalization": "peak_0db",
+        "rmse_db_max": 2.0,
+        "peak_angle_err_deg_max": 2.0,
+        "peak_db_err_max": 1.5,
+    },
+    "experiment": {
+        "frequency_hz": 28_000_000_000,
+        "tx_incident_angle_deg": -30.0,
+    },
+    "output": {
+        "base_dir": "outputs",
+        "run_id": None,
+    },
+}
+
+_ALIAS_FIELDS = {
+    ("geometry", "nx"): [("geometry", "n")],
+    ("geometry", "ny"): [("geometry", "m")],
+    ("geometry", "dx"): [("geometry", "dx_m")],
+    ("geometry", "dy"): [("geometry", "dy_m")],
+}
+
+
+def _deep_merge(base: Dict[str, Any], override: Dict[str, Any]) -> Dict[str, Any]:
+    for key, value in override.items():
+        if isinstance(value, dict) and isinstance(base.get(key), dict):
+            base[key] = _deep_merge(base[key], value)
+        else:
+            base[key] = value
+    return base
+
+
+def _apply_aliases(config: Dict[str, Any]) -> Dict[str, Any]:
+    updated = copy.deepcopy(config)
+    for (section, key), aliases in _ALIAS_FIELDS.items():
+        section_data = updated.get(section)
+        if not isinstance(section_data, dict):
+            continue
+        if key in section_data:
+            continue
+        for alias_section, alias_key in aliases:
+            alias_data = updated.get(alias_section)
+            if isinstance(alias_data, dict) and alias_key in alias_data:
+                section_data[key] = alias_data[alias_key]
+                break
+        updated[section] = section_data
+    return updated
+
+
+def _missing_required_fields(geometry: Dict[str, Any]) -> list[str]:
+    required = ("nx", "ny", "dx", "dy")
+    missing = []
+    for key in required:
+        value = geometry.get(key)
+        if value is None:
+            missing.append(f"geometry.{key}")
+    return missing
+
+
+def _canonicalize_config(config: Dict[str, Any]) -> Dict[str, Any]:
+    ordered_keys = [
+        "schema_version",
+        "geometry",
+        "control",
+        "quantization",
+        "pattern_mode",
+        "link_mode",
+        "validation",
+        "experiment",
+        "output",
+    ]
+    ordered: Dict[str, Any] = {}
+    for key in ordered_keys:
+        if key in config:
+            ordered[key] = config[key]
+    extras = {k: v for k, v in config.items() if k not in ordered_keys}
+    for key in sorted(extras):
+        ordered[key] = extras[key]
+    return ordered
+
+
+def resolve_ris_lab_config(raw_config: Dict[str, Any]) -> Dict[str, Any]:
+    if not isinstance(raw_config, dict):
+        raise ValueError("RIS Lab config must be a YAML mapping")
+
+    normalized = _apply_aliases(raw_config)
+    resolved = _deep_merge(copy.deepcopy(DEFAULT_RIS_LAB_CONFIG), normalized)
+
+    geometry = resolved.get("geometry")
+    if not isinstance(geometry, dict):
+        raise ValueError("RIS Lab config geometry must be a mapping")
+
+    missing = _missing_required_fields(geometry)
+    if missing:
+        raise ValueError(
+            "RIS Lab config missing required fields: " + ", ".join(missing)
+        )
+
+    return _canonicalize_config(resolved)
+
+
+def load_ris_lab_config(path: str | Path) -> Dict[str, Any]:
+    config_path = Path(path)
+    if not config_path.exists():
+        raise FileNotFoundError(f"RIS Lab config not found: {config_path}")
+    with config_path.open("r", encoding="utf-8") as handle:
+        data = yaml.safe_load(handle)
+    return resolve_ris_lab_config(data)
+
+
+def compute_ris_lab_config_hash(config: Dict[str, Any]) -> str:
+    payload = json.dumps(config, sort_keys=True).encode("utf-8")
+    return hashlib.sha256(payload).hexdigest()
+
+
+def _ensure_output_dir(output_dir: Path) -> Path:
+    output_dir.mkdir(parents=True, exist_ok=True)
+    (output_dir / "plots").mkdir(parents=True, exist_ok=True)
+    (output_dir / "data").mkdir(parents=True, exist_ok=True)
+    return output_dir
+
+
+def snapshot_ris_lab_config(output_dir: Path, config: Dict[str, Any]) -> Dict[str, Any]:
+    output_dir = _ensure_output_dir(output_dir)
+    yaml_path = output_dir / "config.yaml"
+    json_path = output_dir / "config.json"
+    save_yaml(yaml_path, config)
+    save_json(json_path, config)
+
+    config_hash = compute_ris_lab_config_hash(config)
+    summary = {
+        "schema_version": config.get("schema_version", RIS_LAB_SCHEMA_VERSION),
+        "config": {
+            "hash_sha256": config_hash,
+            "path_yaml": str(yaml_path),
+            "path_json": str(json_path),
+        },
+    }
+    save_json(output_dir / "summary.json", summary)
+    return summary
+
+
+def resolve_and_snapshot_ris_lab_config(
+    config_path: str | Path,
+    output_dir: Optional[str | Path] = None,
+) -> tuple[Dict[str, Any], Path, Dict[str, Any]]:
+    config = load_ris_lab_config(config_path)
+    if output_dir is None:
+        output_cfg = config.get("output", {})
+        base_dir = output_cfg.get("base_dir", "outputs")
+        run_id = output_cfg.get("run_id")
+        output_path = create_output_dir(base_dir, run_id=run_id)
+    else:
+        output_path = _ensure_output_dir(Path(output_dir))
+
+    summary = snapshot_ris_lab_config(output_path, config)
+    return config, output_path, summary
diff --git a/tests/test_ris_config.py b/tests/test_ris_config.py
new file mode 100644
index 0000000000000000000000000000000000000000..425e3679bae77cdb6c92bd26bc4d66308a7c610c
--- /dev/null
+++ b/tests/test_ris_config.py
@@ -0,0 +1,58 @@
+import json
+import tempfile
+import unittest
+from pathlib import Path
+
+import yaml
+
+from app.ris.ris_config import (
+    compute_ris_lab_config_hash,
+    resolve_and_snapshot_ris_lab_config,
+    resolve_ris_lab_config,
+)
+
+
+class TestRisLabConfig(unittest.TestCase):
+    def test_minimal_config_resolves_defaults(self) -> None:
+        resolved = resolve_ris_lab_config(
+            {"geometry": {"nx": 4, "ny": 2, "dx": 0.5, "dy": 0.25}}
+        )
+        self.assertEqual(resolved["control"]["mode"], "uniform")
+        self.assertEqual(resolved["quantization"]["bits"], 0)
+        self.assertEqual(resolved["validation"]["rmse_db_max"], 2.0)
+        self.assertEqual(resolved["output"]["base_dir"], "outputs")
+
+    def test_missing_geometry_fields_reports_required(self) -> None:
+        with self.assertRaises(ValueError) as ctx:
+            resolve_ris_lab_config({"geometry": {"nx": 4}})
+        message = str(ctx.exception)
+        self.assertIn("geometry.ny", message)
+        self.assertIn("geometry.dx", message)
+        self.assertIn("geometry.dy", message)
+
+    def test_snapshot_writes_config_files_and_summary(self) -> None:
+        with tempfile.TemporaryDirectory() as tmpdir:
+            tmp_path = Path(tmpdir)
+            config_path = tmp_path / "ris.yaml"
+            yaml.safe_dump(
+                {
+                    "geometry": {"nx": 2, "ny": 2, "dx": 0.1, "dy": 0.2},
+                    "output": {"base_dir": tmpdir, "run_id": "unit-test"},
+                },
+                config_path.open("w", encoding="utf-8"),
+                sort_keys=False,
+            )
+
+            config, output_dir, summary = resolve_and_snapshot_ris_lab_config(config_path)
+            self.assertEqual(output_dir, tmp_path / "unit-test")
+            self.assertTrue((output_dir / "config.yaml").exists())
+            self.assertTrue((output_dir / "config.json").exists())
+            self.assertTrue((output_dir / "summary.json").exists())
+            self.assertEqual(summary["config"]["hash_sha256"], compute_ris_lab_config_hash(config))
+
+            loaded = json.loads((output_dir / "config.json").read_text(encoding="utf-8"))
+            self.assertEqual(loaded["geometry"]["nx"], 2)
+
+
+if __name__ == "__main__":
+    unittest.main()


thinking
**Planning activity log addition**

I'll add an activity log following the test suite to track relevant actions or events.
exec
/usr/bin/zsh -lc 'ralph log "Ran tests: pytest"' in /home/josh/Documents/Github/RIS_SIONNA succeeded in 87ms:
Using local templates: /home/josh/Documents/Github/RIS_SIONNA/.agents/ralph
file update:
diff --git a/app/ris/__init__.py b/app/ris/__init__.py
index a34ed971e3d2426533f5eb2eb56416e59d15db65..bafa9ac9ccd2097b564c1c45d7c7b06f3a223b47
--- a/app/ris/__init__.py
+++ b/app/ris/__init__.py
@@ -1,5 +1,13 @@
 """RIS core math primitives and helpers."""
 
+from .ris_config import (  # noqa: F401
+    RIS_LAB_SCHEMA_VERSION,
+    compute_ris_lab_config_hash,
+    load_ris_lab_config,
+    resolve_and_snapshot_ris_lab_config,
+    resolve_ris_lab_config,
+    snapshot_ris_lab_config,
+)
 from .ris_core import (  # noqa: F401
     RisFrame,
     RisGeometry,
diff --git a/app/ris/ris_config.py b/app/ris/ris_config.py
new file mode 100644
index 0000000000000000000000000000000000000000..744c390c8e0c6c83a435e97cc579a09e71756ef6
--- /dev/null
+++ b/app/ris/ris_config.py
@@ -0,0 +1,200 @@
+"""RIS Lab configuration schema and snapshot helpers."""
+
+from __future__ import annotations
+
+import copy
+import hashlib
+import json
+from pathlib import Path
+from typing import Any, Dict, Iterable, Optional
+
+import yaml
+
+from app.io import create_output_dir, save_json, save_yaml
+
+RIS_LAB_SCHEMA_VERSION = 1
+
+DEFAULT_RIS_LAB_CONFIG: Dict[str, Any] = {
+    "schema_version": RIS_LAB_SCHEMA_VERSION,
+    "geometry": {
+        "nx": None,
+        "ny": None,
+        "dx": None,
+        "dy": None,
+        "origin": [0.0, 0.0, 0.0],
+        "normal": [0.0, 0.0, 1.0],
+        "x_axis_hint": [1.0, 0.0, 0.0],
+    },
+    "control": {
+        "mode": "uniform",
+        "params": {"phase_rad": 0.0},
+    },
+    "quantization": {
+        "bits": 0,
+    },
+    "pattern_mode": {
+        "normalization": "peak_0db",
+        "rx_sweep_deg": {"start": -90.0, "stop": 90.0, "step": 2.0},
+    },
+    "link_mode": {
+        "weighting": "inverse_distance",
+        "enabled": False,
+    },
+    "validation": {
+        "normalization": "peak_0db",
+        "rmse_db_max": 2.0,
+        "peak_angle_err_deg_max": 2.0,
+        "peak_db_err_max": 1.5,
+    },
+    "experiment": {
+        "frequency_hz": 28_000_000_000,
+        "tx_incident_angle_deg": -30.0,
+    },
+    "output": {
+        "base_dir": "outputs",
+        "run_id": None,
+    },
+}
+
+_ALIAS_FIELDS = {
+    ("geometry", "nx"): [("geometry", "n")],
+    ("geometry", "ny"): [("geometry", "m")],
+    ("geometry", "dx"): [("geometry", "dx_m")],
+    ("geometry", "dy"): [("geometry", "dy_m")],
+}
+
+
+def _deep_merge(base: Dict[str, Any], override: Dict[str, Any]) -> Dict[str, Any]:
+    for key, value in override.items():
+        if isinstance(value, dict) and isinstance(base.get(key), dict):
+            base[key] = _deep_merge(base[key], value)
+        else:
+            base[key] = value
+    return base
+
+
+def _apply_aliases(config: Dict[str, Any]) -> Dict[str, Any]:
+    updated = copy.deepcopy(config)
+    for (section, key), aliases in _ALIAS_FIELDS.items():
+        section_data = updated.get(section)
+        if not isinstance(section_data, dict):
+            continue
+        if key in section_data:
+            continue
+        for alias_section, alias_key in aliases:
+            alias_data = updated.get(alias_section)
+            if isinstance(alias_data, dict) and alias_key in alias_data:
+                section_data[key] = alias_data[alias_key]
+                break
+        updated[section] = section_data
+    return updated
+
+
+def _missing_required_fields(geometry: Dict[str, Any]) -> list[str]:
+    required = ("nx", "ny", "dx", "dy")
+    missing = []
+    for key in required:
+        value = geometry.get(key)
+        if value is None:
+            missing.append(f"geometry.{key}")
+    return missing
+
+
+def _canonicalize_config(config: Dict[str, Any]) -> Dict[str, Any]:
+    ordered_keys = [
+        "schema_version",
+        "geometry",
+        "control",
+        "quantization",
+        "pattern_mode",
+        "link_mode",
+        "validation",
+        "experiment",
+        "output",
+    ]
+    ordered: Dict[str, Any] = {}
+    for key in ordered_keys:
+        if key in config:
+            ordered[key] = config[key]
+    extras = {k: v for k, v in config.items() if k not in ordered_keys}
+    for key in sorted(extras):
+        ordered[key] = extras[key]
+    return ordered
+
+
+def resolve_ris_lab_config(raw_config: Dict[str, Any]) -> Dict[str, Any]:
+    if not isinstance(raw_config, dict):
+        raise ValueError("RIS Lab config must be a YAML mapping")
+
+    normalized = _apply_aliases(raw_config)
+    resolved = _deep_merge(copy.deepcopy(DEFAULT_RIS_LAB_CONFIG), normalized)
+
+    geometry = resolved.get("geometry")
+    if not isinstance(geometry, dict):
+        raise ValueError("RIS Lab config geometry must be a mapping")
+
+    missing = _missing_required_fields(geometry)
+    if missing:
+        raise ValueError(
+            "RIS Lab config missing required fields: " + ", ".join(missing)
+        )
+
+    return _canonicalize_config(resolved)
+
+
+def load_ris_lab_config(path: str | Path) -> Dict[str, Any]:
+    config_path = Path(path)
+    if not config_path.exists():
+        raise FileNotFoundError(f"RIS Lab config not found: {config_path}")
+    with config_path.open("r", encoding="utf-8") as handle:
+        data = yaml.safe_load(handle)
+    return resolve_ris_lab_config(data)
+
+
+def compute_ris_lab_config_hash(config: Dict[str, Any]) -> str:
+    payload = json.dumps(config, sort_keys=True).encode("utf-8")
+    return hashlib.sha256(payload).hexdigest()
+
+
+def _ensure_output_dir(output_dir: Path) -> Path:
+    output_dir.mkdir(parents=True, exist_ok=True)
+    (output_dir / "plots").mkdir(parents=True, exist_ok=True)
+    (output_dir / "data").mkdir(parents=True, exist_ok=True)
+    return output_dir
+
+
+def snapshot_ris_lab_config(output_dir: Path, config: Dict[str, Any]) -> Dict[str, Any]:
+    output_dir = _ensure_output_dir(output_dir)
+    yaml_path = output_dir / "config.yaml"
+    json_path = output_dir / "config.json"
+    save_yaml(yaml_path, config)
+    save_json(json_path, config)
+
+    config_hash = compute_ris_lab_config_hash(config)
+    summary = {
+        "schema_version": config.get("schema_version", RIS_LAB_SCHEMA_VERSION),
+        "config": {
+            "hash_sha256": config_hash,
+            "path_yaml": str(yaml_path),
+            "path_json": str(json_path),
+        },
+    }
+    save_json(output_dir / "summary.json", summary)
+    return summary
+
+
+def resolve_and_snapshot_ris_lab_config(
+    config_path: str | Path,
+    output_dir: Optional[str | Path] = None,
+) -> tuple[Dict[str, Any], Path, Dict[str, Any]]:
+    config = load_ris_lab_config(config_path)
+    if output_dir is None:
+        output_cfg = config.get("output", {})
+        base_dir = output_cfg.get("base_dir", "outputs")
+        run_id = output_cfg.get("run_id")
+        output_path = create_output_dir(base_dir, run_id=run_id)
+    else:
+        output_path = _ensure_output_dir(Path(output_dir))
+
+    summary = snapshot_ris_lab_config(output_path, config)
+    return config, output_path, summary
diff --git a/tests/test_ris_config.py b/tests/test_ris_config.py
new file mode 100644
index 0000000000000000000000000000000000000000..425e3679bae77cdb6c92bd26bc4d66308a7c610c
--- /dev/null
+++ b/tests/test_ris_config.py
@@ -0,0 +1,58 @@
+import json
+import tempfile
+import unittest
+from pathlib import Path
+
+import yaml
+
+from app.ris.ris_config import (
+    compute_ris_lab_config_hash,
+    resolve_and_snapshot_ris_lab_config,
+    resolve_ris_lab_config,
+)
+
+
+class TestRisLabConfig(unittest.TestCase):
+    def test_minimal_config_resolves_defaults(self) -> None:
+        resolved = resolve_ris_lab_config(
+            {"geometry": {"nx": 4, "ny": 2, "dx": 0.5, "dy": 0.25}}
+        )
+        self.assertEqual(resolved["control"]["mode"], "uniform")
+        self.assertEqual(resolved["quantization"]["bits"], 0)
+        self.assertEqual(resolved["validation"]["rmse_db_max"], 2.0)
+        self.assertEqual(resolved["output"]["base_dir"], "outputs")
+
+    def test_missing_geometry_fields_reports_required(self) -> None:
+        with self.assertRaises(ValueError) as ctx:
+            resolve_ris_lab_config({"geometry": {"nx": 4}})
+        message = str(ctx.exception)
+        self.assertIn("geometry.ny", message)
+        self.assertIn("geometry.dx", message)
+        self.assertIn("geometry.dy", message)
+
+    def test_snapshot_writes_config_files_and_summary(self) -> None:
+        with tempfile.TemporaryDirectory() as tmpdir:
+            tmp_path = Path(tmpdir)
+            config_path = tmp_path / "ris.yaml"
+            yaml.safe_dump(
+                {
+                    "geometry": {"nx": 2, "ny": 2, "dx": 0.1, "dy": 0.2},
+                    "output": {"base_dir": tmpdir, "run_id": "unit-test"},
+                },
+                config_path.open("w", encoding="utf-8"),
+                sort_keys=False,
+            )
+
+            config, output_dir, summary = resolve_and_snapshot_ris_lab_config(config_path)
+            self.assertEqual(output_dir, tmp_path / "unit-test")
+            self.assertTrue((output_dir / "config.yaml").exists())
+            self.assertTrue((output_dir / "config.json").exists())
+            self.assertTrue((output_dir / "summary.json").exists())
+            self.assertEqual(summary["config"]["hash_sha256"], compute_ris_lab_config_hash(config))
+
+            loaded = json.loads((output_dir / "config.json").read_text(encoding="utf-8"))
+            self.assertEqual(loaded["geometry"]["nx"], 2)
+
+
+if __name__ == "__main__":
+    unittest.main()


thinking
**Preparing for commit with audit and logging**

I'm planning a brief manual security, performance, and regression audit before committing, then will commit using the commit skill followed by updating progress and activity logs as per the instructions.
exec
/usr/bin/zsh -lc 'cat /home/josh/Documents/Github/RIS_SIONNA/.codex/skills/commit/SKILL.md' in /home/josh/Documents/Github/RIS_SIONNA succeeded in 3ms:
---
name: commit
description: Write conventional commit messages with type, scope, and subject when the user wants to commit changes or save work.
---

# Git Commit

Creates git commits following Conventional Commits format with proper type, scope, and subject.

## Quick Start

```bash
# 1. Stage changes
git add <files>  # or: git add -A

# 2. Create commit (branch commit format)
git commit -m "type(scope): subject

Body explaining HOW and WHY.
Reference: Task X.Y, Req N"
file update:
diff --git a/app/ris/__init__.py b/app/ris/__init__.py
index a34ed971e3d2426533f5eb2eb56416e59d15db65..bafa9ac9ccd2097b564c1c45d7c7b06f3a223b47
--- a/app/ris/__init__.py
+++ b/app/ris/__init__.py
@@ -1,5 +1,13 @@
 """RIS core math primitives and helpers."""
 
+from .ris_config import (  # noqa: F401
+    RIS_LAB_SCHEMA_VERSION,
+    compute_ris_lab_config_hash,
+    load_ris_lab_config,
+    resolve_and_snapshot_ris_lab_config,
+    resolve_ris_lab_config,
+    snapshot_ris_lab_config,
+)
 from .ris_core import (  # noqa: F401
     RisFrame,
     RisGeometry,
diff --git a/app/ris/ris_config.py b/app/ris/ris_config.py
new file mode 100644
index 0000000000000000000000000000000000000000..744c390c8e0c6c83a435e97cc579a09e71756ef6
--- /dev/null
+++ b/app/ris/ris_config.py
@@ -0,0 +1,200 @@
+"""RIS Lab configuration schema and snapshot helpers."""
+
+from __future__ import annotations
+
+import copy
+import hashlib
+import json
+from pathlib import Path
+from typing import Any, Dict, Iterable, Optional
+
+import yaml
+
+from app.io import create_output_dir, save_json, save_yaml
+
+RIS_LAB_SCHEMA_VERSION = 1
+
+DEFAULT_RIS_LAB_CONFIG: Dict[str, Any] = {
+    "schema_version": RIS_LAB_SCHEMA_VERSION,
+    "geometry": {
+        "nx": None,
+        "ny": None,
+        "dx": None,
+        "dy": None,
+        "origin": [0.0, 0.0, 0.0],
+        "normal": [0.0, 0.0, 1.0],
+        "x_axis_hint": [1.0, 0.0, 0.0],
+    },
+    "control": {
+        "mode": "uniform",
+        "params": {"phase_rad": 0.0},
+    },
+    "quantization": {
+        "bits": 0,
+    },
+    "pattern_mode": {
+        "normalization": "peak_0db",
+        "rx_sweep_deg": {"start": -90.0, "stop": 90.0, "step": 2.0},
+    },
+    "link_mode": {
+        "weighting": "inverse_distance",
+        "enabled": False,
+    },
+    "validation": {
+        "normalization": "peak_0db",
+        "rmse_db_max": 2.0,
+        "peak_angle_err_deg_max": 2.0,
+        "peak_db_err_max": 1.5,
+    },
+    "experiment": {
+        "frequency_hz": 28_000_000_000,
+        "tx_incident_angle_deg": -30.0,
+    },
+    "output": {
+        "base_dir": "outputs",
+        "run_id": None,
+    },
+}
+
+_ALIAS_FIELDS = {
+    ("geometry", "nx"): [("geometry", "n")],
+    ("geometry", "ny"): [("geometry", "m")],
+    ("geometry", "dx"): [("geometry", "dx_m")],
+    ("geometry", "dy"): [("geometry", "dy_m")],
+}
+
+
+def _deep_merge(base: Dict[str, Any], override: Dict[str, Any]) -> Dict[str, Any]:
+    for key, value in override.items():
+        if isinstance(value, dict) and isinstance(base.get(key), dict):
+            base[key] = _deep_merge(base[key], value)
+        else:
+            base[key] = value
+    return base
+
+
+def _apply_aliases(config: Dict[str, Any]) -> Dict[str, Any]:
+    updated = copy.deepcopy(config)
+    for (section, key), aliases in _ALIAS_FIELDS.items():
+        section_data = updated.get(section)
+        if not isinstance(section_data, dict):
+            continue
+        if key in section_data:
+            continue
+        for alias_section, alias_key in aliases:
+            alias_data = updated.get(alias_section)
+            if isinstance(alias_data, dict) and alias_key in alias_data:
+                section_data[key] = alias_data[alias_key]
+                break
+        updated[section] = section_data
+    return updated
+
+
+def _missing_required_fields(geometry: Dict[str, Any]) -> list[str]:
+    required = ("nx", "ny", "dx", "dy")
+    missing = []
+    for key in required:
+        value = geometry.get(key)
+        if value is None:
+            missing.append(f"geometry.{key}")
+    return missing
+
+
+def _canonicalize_config(config: Dict[str, Any]) -> Dict[str, Any]:
+    ordered_keys = [
+        "schema_version",
+        "geometry",
+        "control",
+        "quantization",
+        "pattern_mode",
+        "link_mode",
+        "validation",
+        "experiment",
+        "output",
+    ]
+    ordered: Dict[str, Any] = {}
+    for key in ordered_keys:
+        if key in config:
+            ordered[key] = config[key]
+    extras = {k: v for k, v in config.items() if k not in ordered_keys}
+    for key in sorted(extras):
+        ordered[key] = extras[key]
+    return ordered
+
+
+def resolve_ris_lab_config(raw_config: Dict[str, Any]) -> Dict[str, Any]:
+    if not isinstance(raw_config, dict):
+        raise ValueError("RIS Lab config must be a YAML mapping")
+
+    normalized = _apply_aliases(raw_config)
+    resolved = _deep_merge(copy.deepcopy(DEFAULT_RIS_LAB_CONFIG), normalized)
+
+    geometry = resolved.get("geometry")
+    if not isinstance(geometry, dict):
+        raise ValueError("RIS Lab config geometry must be a mapping")
+
+    missing = _missing_required_fields(geometry)
+    if missing:
+        raise ValueError(
+            "RIS Lab config missing required fields: " + ", ".join(missing)
+        )
+
+    return _canonicalize_config(resolved)
+
+
+def load_ris_lab_config(path: str | Path) -> Dict[str, Any]:
+    config_path = Path(path)
+    if not config_path.exists():
+        raise FileNotFoundError(f"RIS Lab config not found: {config_path}")
+    with config_path.open("r", encoding="utf-8") as handle:
+        data = yaml.safe_load(handle)
+    return resolve_ris_lab_config(data)
+
+
+def compute_ris_lab_config_hash(config: Dict[str, Any]) -> str:
+    payload = json.dumps(config, sort_keys=True).encode("utf-8")
+    return hashlib.sha256(payload).hexdigest()
+
+
+def _ensure_output_dir(output_dir: Path) -> Path:
+    output_dir.mkdir(parents=True, exist_ok=True)
+    (output_dir / "plots").mkdir(parents=True, exist_ok=True)
+    (output_dir / "data").mkdir(parents=True, exist_ok=True)
+    return output_dir
+
+
+def snapshot_ris_lab_config(output_dir: Path, config: Dict[str, Any]) -> Dict[str, Any]:
+    output_dir = _ensure_output_dir(output_dir)
+    yaml_path = output_dir / "config.yaml"
+    json_path = output_dir / "config.json"
+    save_yaml(yaml_path, config)
+    save_json(json_path, config)
+
+    config_hash = compute_ris_lab_config_hash(config)
+    summary = {
+        "schema_version": config.get("schema_version", RIS_LAB_SCHEMA_VERSION),
+        "config": {
+            "hash_sha256": config_hash,
+            "path_yaml": str(yaml_path),
+            "path_json": str(json_path),
+        },
+    }
+    save_json(output_dir / "summary.json", summary)
+    return summary
+
+
+def resolve_and_snapshot_ris_lab_config(
+    config_path: str | Path,
+    output_dir: Optional[str | Path] = None,
+) -> tuple[Dict[str, Any], Path, Dict[str, Any]]:
+    config = load_ris_lab_config(config_path)
+    if output_dir is None:
+        output_cfg = config.get("output", {})
+        base_dir = output_cfg.get("base_dir", "outputs")
+        run_id = output_cfg.get("run_id")
+        output_path = create_output_dir(base_dir, run_id=run_id)
+    else:
+        output_path = _ensure_output_dir(Path(output_dir))
+
+    summary = snapshot_ris_lab_config(output_path, config)
+    return config, output_path, summary
diff --git a/tests/test_ris_config.py b/tests/test_ris_config.py
new file mode 100644
index 0000000000000000000000000000000000000000..425e3679bae77cdb6c92bd26bc4d66308a7c610c
--- /dev/null
+++ b/tests/test_ris_config.py
@@ -0,0 +1,58 @@
+import json
+import tempfile
+import unittest
+from pathlib import Path
+
+import yaml
+
+from app.ris.ris_config import (
+    compute_ris_lab_config_hash,
+    resolve_and_snapshot_ris_lab_config,
+    resolve_ris_lab_config,
+)
+
+
+class TestRisLabConfig(unittest.TestCase):
+    def test_minimal_config_resolves_defaults(self) -> None:
+        resolved = resolve_ris_lab_config(
+            {"geometry": {"nx": 4, "ny": 2, "dx": 0.5, "dy": 0.25}}
+        )
+        self.assertEqual(resolved["control"]["mode"], "uniform")
+        self.assertEqual(resolved["quantization"]["bits"], 0)
+        self.assertEqual(resolved["validation"]["rmse_db_max"], 2.0)
+        self.assertEqual(resolved["output"]["base_dir"], "outputs")
+
+    def test_missing_geometry_fields_reports_required(self) -> None:
+        with self.assertRaises(ValueError) as ctx:
+            resolve_ris_lab_config({"geometry": {"nx": 4}})
+        message = str(ctx.exception)
+        self.assertIn("geometry.ny", message)
+        self.assertIn("geometry.dx", message)
+        self.assertIn("geometry.dy", message)
+
+    def test_snapshot_writes_config_files_and_summary(self) -> None:
+        with tempfile.TemporaryDirectory() as tmpdir:
+            tmp_path = Path(tmpdir)
+            config_path = tmp_path / "ris.yaml"
+            yaml.safe_dump(
+                {
+                    "geometry": {"nx": 2, "ny": 2, "dx": 0.1, "dy": 0.2},
+                    "output": {"base_dir": tmpdir, "run_id": "unit-test"},
+                },
+                config_path.open("w", encoding="utf-8"),
+                sort_keys=False,
+            )
+
+            config, output_dir, summary = resolve_and_snapshot_ris_lab_config(config_path)
+            self.assertEqual(output_dir, tmp_path / "unit-test")
+            self.assertTrue((output_dir / "config.yaml").exists())
+            self.assertTrue((output_dir / "config.json").exists())
+            self.assertTrue((output_dir / "summary.json").exists())
+            self.assertEqual(summary["config"]["hash_sha256"], compute_ris_lab_config_hash(config))
+
+            loaded = json.loads((output_dir / "config.json").read_text(encoding="utf-8"))
+            self.assertEqual(loaded["geometry"]["nx"], 2)
+
+
+if __name__ == "__main__":
+    unittest.main()


thinking
**Preparing for review before commit**
exec
/usr/bin/zsh -lc 'git status -sb' in /home/josh/Documents/Github/RIS_SIONNA succeeded in 4ms:
## linux
 M .agents/tasks/prd-ris-lab.json
 M .ralph/activity.log
 M .ralph/errors.log
 M .ralph/runs/run-20260120-175122-20544-iter-1.log
 M app/ris/__init__.py
?? .ralph/.tmp/prompt-20260120-175122-20544-2.md
?? .ralph/.tmp/story-20260120-175122-20544-2.json
?? .ralph/.tmp/story-20260120-175122-20544-2.md
?? .ralph/runs/run-20260120-175122-20544-iter-1.md
?? .ralph/runs/run-20260120-175122-20544-iter-2.log
?? app/ris/ris_config.py
?? tests/test_ris_config.py
file update:
diff --git a/app/ris/__init__.py b/app/ris/__init__.py
index a34ed971e3d2426533f5eb2eb56416e59d15db65..bafa9ac9ccd2097b564c1c45d7c7b06f3a223b47
--- a/app/ris/__init__.py
+++ b/app/ris/__init__.py
@@ -1,5 +1,13 @@
 """RIS core math primitives and helpers."""
 
+from .ris_config import (  # noqa: F401
+    RIS_LAB_SCHEMA_VERSION,
+    compute_ris_lab_config_hash,
+    load_ris_lab_config,
+    resolve_and_snapshot_ris_lab_config,
+    resolve_ris_lab_config,
+    snapshot_ris_lab_config,
+)
 from .ris_core import (  # noqa: F401
     RisFrame,
     RisGeometry,
diff --git a/app/ris/ris_config.py b/app/ris/ris_config.py
new file mode 100644
index 0000000000000000000000000000000000000000..744c390c8e0c6c83a435e97cc579a09e71756ef6
--- /dev/null
+++ b/app/ris/ris_config.py
@@ -0,0 +1,200 @@
+"""RIS Lab configuration schema and snapshot helpers."""
+
+from __future__ import annotations
+
+import copy
+import hashlib
+import json
+from pathlib import Path
+from typing import Any, Dict, Iterable, Optional
+
+import yaml
+
+from app.io import create_output_dir, save_json, save_yaml
+
+RIS_LAB_SCHEMA_VERSION = 1
+
+DEFAULT_RIS_LAB_CONFIG: Dict[str, Any] = {
+    "schema_version": RIS_LAB_SCHEMA_VERSION,
+    "geometry": {
+        "nx": None,
+        "ny": None,
+        "dx": None,
+        "dy": None,
+        "origin": [0.0, 0.0, 0.0],
+        "normal": [0.0, 0.0, 1.0],
+        "x_axis_hint": [1.0, 0.0, 0.0],
+    },
+    "control": {
+        "mode": "uniform",
+        "params": {"phase_rad": 0.0},
+    },
+    "quantization": {
+        "bits": 0,
+    },
+    "pattern_mode": {
+        "normalization": "peak_0db",
+        "rx_sweep_deg": {"start": -90.0, "stop": 90.0, "step": 2.0},
+    },
+    "link_mode": {
+        "weighting": "inverse_distance",
+        "enabled": False,
+    },
+    "validation": {
+        "normalization": "peak_0db",
+        "rmse_db_max": 2.0,
+        "peak_angle_err_deg_max": 2.0,
+        "peak_db_err_max": 1.5,
+    },
+    "experiment": {
+        "frequency_hz": 28_000_000_000,
+        "tx_incident_angle_deg": -30.0,
+    },
+    "output": {
+        "base_dir": "outputs",
+        "run_id": None,
+    },
+}
+
+_ALIAS_FIELDS = {
+    ("geometry", "nx"): [("geometry", "n")],
+    ("geometry", "ny"): [("geometry", "m")],
+    ("geometry", "dx"): [("geometry", "dx_m")],
+    ("geometry", "dy"): [("geometry", "dy_m")],
+}
+
+
+def _deep_merge(base: Dict[str, Any], override: Dict[str, Any]) -> Dict[str, Any]:
+    for key, value in override.items():
+        if isinstance(value, dict) and isinstance(base.get(key), dict):
+            base[key] = _deep_merge(base[key], value)
+        else:
+            base[key] = value
+    return base
+
+
+def _apply_aliases(config: Dict[str, Any]) -> Dict[str, Any]:
+    updated = copy.deepcopy(config)
+    for (section, key), aliases in _ALIAS_FIELDS.items():
+        section_data = updated.get(section)
+        if not isinstance(section_data, dict):
+            continue
+        if key in section_data:
+            continue
+        for alias_section, alias_key in aliases:
+            alias_data = updated.get(alias_section)
+            if isinstance(alias_data, dict) and alias_key in alias_data:
+                section_data[key] = alias_data[alias_key]
+                break
+        updated[section] = section_data
+    return updated
+
+
+def _missing_required_fields(geometry: Dict[str, Any]) -> list[str]:
+    required = ("nx", "ny", "dx", "dy")
+    missing = []
+    for key in required:
+        value = geometry.get(key)
+        if value is None:
+            missing.append(f"geometry.{key}")
+    return missing
+
+
+def _canonicalize_config(config: Dict[str, Any]) -> Dict[str, Any]:
+    ordered_keys = [
+        "schema_version",
+        "geometry",
+        "control",
+        "quantization",
+        "pattern_mode",
+        "link_mode",
+        "validation",
+        "experiment",
+        "output",
+    ]
+    ordered: Dict[str, Any] = {}
+    for key in ordered_keys:
+        if key in config:
+            ordered[key] = config[key]
+    extras = {k: v for k, v in config.items() if k not in ordered_keys}
+    for key in sorted(extras):
+        ordered[key] = extras[key]
+    return ordered
+
+
+def resolve_ris_lab_config(raw_config: Dict[str, Any]) -> Dict[str, Any]:
+    if not isinstance(raw_config, dict):
+        raise ValueError("RIS Lab config must be a YAML mapping")
+
+    normalized = _apply_aliases(raw_config)
+    resolved = _deep_merge(copy.deepcopy(DEFAULT_RIS_LAB_CONFIG), normalized)
+
+    geometry = resolved.get("geometry")
+    if not isinstance(geometry, dict):
+        raise ValueError("RIS Lab config geometry must be a mapping")
+
+    missing = _missing_required_fields(geometry)
+    if missing:
+        raise ValueError(
+            "RIS Lab config missing required fields: " + ", ".join(missing)
+        )
+
+    return _canonicalize_config(resolved)
+
+
+def load_ris_lab_config(path: str | Path) -> Dict[str, Any]:
+    config_path = Path(path)
+    if not config_path.exists():
+        raise FileNotFoundError(f"RIS Lab config not found: {config_path}")
+    with config_path.open("r", encoding="utf-8") as handle:
+        data = yaml.safe_load(handle)
+    return resolve_ris_lab_config(data)
+
+
+def compute_ris_lab_config_hash(config: Dict[str, Any]) -> str:
+    payload = json.dumps(config, sort_keys=True).encode("utf-8")
+    return hashlib.sha256(payload).hexdigest()
+
+
+def _ensure_output_dir(output_dir: Path) -> Path:
+    output_dir.mkdir(parents=True, exist_ok=True)
+    (output_dir / "plots").mkdir(parents=True, exist_ok=True)
+    (output_dir / "data").mkdir(parents=True, exist_ok=True)
+    return output_dir
+
+
+def snapshot_ris_lab_config(output_dir: Path, config: Dict[str, Any]) -> Dict[str, Any]:
+    output_dir = _ensure_output_dir(output_dir)
+    yaml_path = output_dir / "config.yaml"
+    json_path = output_dir / "config.json"
+    save_yaml(yaml_path, config)
+    save_json(json_path, config)
+
+    config_hash = compute_ris_lab_config_hash(config)
+    summary = {
+        "schema_version": config.get("schema_version", RIS_LAB_SCHEMA_VERSION),
+        "config": {
+            "hash_sha256": config_hash,
+            "path_yaml": str(yaml_path),
+            "path_json": str(json_path),
+        },
+    }
+    save_json(output_dir / "summary.json", summary)
+    return summary
+
+
+def resolve_and_snapshot_ris_lab_config(
+    config_path: str | Path,
+    output_dir: Optional[str | Path] = None,
+) -> tuple[Dict[str, Any], Path, Dict[str, Any]]:
+    config = load_ris_lab_config(config_path)
+    if output_dir is None:
+        output_cfg = config.get("output", {})
+        base_dir = output_cfg.get("base_dir", "outputs")
+        run_id = output_cfg.get("run_id")
+        output_path = create_output_dir(base_dir, run_id=run_id)
+    else:
+        output_path = _ensure_output_dir(Path(output_dir))
+
+    summary = snapshot_ris_lab_config(output_path, config)
+    return config, output_path, summary
diff --git a/tests/test_ris_config.py b/tests/test_ris_config.py
new file mode 100644
index 0000000000000000000000000000000000000000..425e3679bae77cdb6c92bd26bc4d66308a7c610c
--- /dev/null
+++ b/tests/test_ris_config.py
@@ -0,0 +1,58 @@
+import json
+import tempfile
+import unittest
+from pathlib import Path
+
+import yaml
+
+from app.ris.ris_config import (
+    compute_ris_lab_config_hash,
+    resolve_and_snapshot_ris_lab_config,
+    resolve_ris_lab_config,
+)
+
+
+class TestRisLabConfig(unittest.TestCase):
+    def test_minimal_config_resolves_defaults(self) -> None:
+        resolved = resolve_ris_lab_config(
+            {"geometry": {"nx": 4, "ny": 2, "dx": 0.5, "dy": 0.25}}
+        )
+        self.assertEqual(resolved["control"]["mode"], "uniform")
+        self.assertEqual(resolved["quantization"]["bits"], 0)
+        self.assertEqual(resolved["validation"]["rmse_db_max"], 2.0)
+        self.assertEqual(resolved["output"]["base_dir"], "outputs")
+
+    def test_missing_geometry_fields_reports_required(self) -> None:
+        with self.assertRaises(ValueError) as ctx:
+            resolve_ris_lab_config({"geometry": {"nx": 4}})
+        message = str(ctx.exception)
+        self.assertIn("geometry.ny", message)
+        self.assertIn("geometry.dx", message)
+        self.assertIn("geometry.dy", message)
+
+    def test_snapshot_writes_config_files_and_summary(self) -> None:
+        with tempfile.TemporaryDirectory() as tmpdir:
+            tmp_path = Path(tmpdir)
+            config_path = tmp_path / "ris.yaml"
+            yaml.safe_dump(
+                {
+                    "geometry": {"nx": 2, "ny": 2, "dx": 0.1, "dy": 0.2},
+                    "output": {"base_dir": tmpdir, "run_id": "unit-test"},
+                },
+                config_path.open("w", encoding="utf-8"),
+                sort_keys=False,
+            )
+
+            config, output_dir, summary = resolve_and_snapshot_ris_lab_config(config_path)
+            self.assertEqual(output_dir, tmp_path / "unit-test")
+            self.assertTrue((output_dir / "config.yaml").exists())
+            self.assertTrue((output_dir / "config.json").exists())
+            self.assertTrue((output_dir / "summary.json").exists())
+            self.assertEqual(summary["config"]["hash_sha256"], compute_ris_lab_config_hash(config))
+
+            loaded = json.loads((output_dir / "config.json").read_text(encoding="utf-8"))
+            self.assertEqual(loaded["geometry"]["nx"], 2)
+
+
+if __name__ == "__main__":
+    unittest.main()



thinking
**Confirming commit includes all changes**

There are pre-existing modifications we didn’t make, but instructions require staging all changes for commit without reverting anything. Next, I'll verify that files we didn’t edit remain untouched to avoid unintended commits.
thinking
**Double-checking unstaged changes before commit**

The PRD JSON and some logs show prior modifications we didn’t make, but instructions require staging everything. I'll review diffs to confirm no unintended edits before committing all changes as directed.
exec
/usr/bin/zsh -lc 'git diff --stat' in /home/josh/Documents/Github/RIS_SIONNA succeeded in 5ms:
 .agents/tasks/prd-ris-lab.json                   |  13 +-
 .ralph/activity.log                              |   6 +
 .ralph/errors.log                                |   1 +
 .ralph/runs/run-20260120-175122-20544-iter-1.log | 558 ++++++++++++++++++++++-
 app/ris/__init__.py                              |   8 +
 5 files changed, 580 insertions(+), 6 deletions(-)
file update:
diff --git a/app/ris/__init__.py b/app/ris/__init__.py
index a34ed971e3d2426533f5eb2eb56416e59d15db65..bafa9ac9ccd2097b564c1c45d7c7b06f3a223b47
--- a/app/ris/__init__.py
+++ b/app/ris/__init__.py
@@ -1,5 +1,13 @@
 """RIS core math primitives and helpers."""
 
+from .ris_config import (  # noqa: F401
+    RIS_LAB_SCHEMA_VERSION,
+    compute_ris_lab_config_hash,
+    load_ris_lab_config,
+    resolve_and_snapshot_ris_lab_config,
+    resolve_ris_lab_config,
+    snapshot_ris_lab_config,
+)
 from .ris_core import (  # noqa: F401
     RisFrame,
     RisGeometry,
diff --git a/app/ris/ris_config.py b/app/ris/ris_config.py
new file mode 100644
index 0000000000000000000000000000000000000000..744c390c8e0c6c83a435e97cc579a09e71756ef6
--- /dev/null
+++ b/app/ris/ris_config.py
@@ -0,0 +1,200 @@
+"""RIS Lab configuration schema and snapshot helpers."""
+
+from __future__ import annotations
+
+import copy
+import hashlib
+import json
+from pathlib import Path
+from typing import Any, Dict, Iterable, Optional
+
+import yaml
+
+from app.io import create_output_dir, save_json, save_yaml
+
+RIS_LAB_SCHEMA_VERSION = 1
+
+DEFAULT_RIS_LAB_CONFIG: Dict[str, Any] = {
+    "schema_version": RIS_LAB_SCHEMA_VERSION,
+    "geometry": {
+        "nx": None,
+        "ny": None,
+        "dx": None,
+        "dy": None,
+        "origin": [0.0, 0.0, 0.0],
+        "normal": [0.0, 0.0, 1.0],
+        "x_axis_hint": [1.0, 0.0, 0.0],
+    },
+    "control": {
+        "mode": "uniform",
+        "params": {"phase_rad": 0.0},
+    },
+    "quantization": {
+        "bits": 0,
+    },
+    "pattern_mode": {
+        "normalization": "peak_0db",
+        "rx_sweep_deg": {"start": -90.0, "stop": 90.0, "step": 2.0},
+    },
+    "link_mode": {
+        "weighting": "inverse_distance",
+        "enabled": False,
+    },
+    "validation": {
+        "normalization": "peak_0db",
+        "rmse_db_max": 2.0,
+        "peak_angle_err_deg_max": 2.0,
+        "peak_db_err_max": 1.5,
+    },
+    "experiment": {
+        "frequency_hz": 28_000_000_000,
+        "tx_incident_angle_deg": -30.0,
+    },
+    "output": {
+        "base_dir": "outputs",
+        "run_id": None,
+    },
+}
+
+_ALIAS_FIELDS = {
+    ("geometry", "nx"): [("geometry", "n")],
+    ("geometry", "ny"): [("geometry", "m")],
+    ("geometry", "dx"): [("geometry", "dx_m")],
+    ("geometry", "dy"): [("geometry", "dy_m")],
+}
+
+
+def _deep_merge(base: Dict[str, Any], override: Dict[str, Any]) -> Dict[str, Any]:
+    for key, value in override.items():
+        if isinstance(value, dict) and isinstance(base.get(key), dict):
+            base[key] = _deep_merge(base[key], value)
+        else:
+            base[key] = value
+    return base
+
+
+def _apply_aliases(config: Dict[str, Any]) -> Dict[str, Any]:
+    updated = copy.deepcopy(config)
+    for (section, key), aliases in _ALIAS_FIELDS.items():
+        section_data = updated.get(section)
+        if not isinstance(section_data, dict):
+            continue
+        if key in section_data:
+            continue
+        for alias_section, alias_key in aliases:
+            alias_data = updated.get(alias_section)
+            if isinstance(alias_data, dict) and alias_key in alias_data:
+                section_data[key] = alias_data[alias_key]
+                break
+        updated[section] = section_data
+    return updated
+
+
+def _missing_required_fields(geometry: Dict[str, Any]) -> list[str]:
+    required = ("nx", "ny", "dx", "dy")
+    missing = []
+    for key in required:
+        value = geometry.get(key)
+        if value is None:
+            missing.append(f"geometry.{key}")
+    return missing
+
+
+def _canonicalize_config(config: Dict[str, Any]) -> Dict[str, Any]:
+    ordered_keys = [
+        "schema_version",
+        "geometry",
+        "control",
+        "quantization",
+        "pattern_mode",
+        "link_mode",
+        "validation",
+        "experiment",
+        "output",
+    ]
+    ordered: Dict[str, Any] = {}
+    for key in ordered_keys:
+        if key in config:
+            ordered[key] = config[key]
+    extras = {k: v for k, v in config.items() if k not in ordered_keys}
+    for key in sorted(extras):
+        ordered[key] = extras[key]
+    return ordered
+
+
+def resolve_ris_lab_config(raw_config: Dict[str, Any]) -> Dict[str, Any]:
+    if not isinstance(raw_config, dict):
+        raise ValueError("RIS Lab config must be a YAML mapping")
+
+    normalized = _apply_aliases(raw_config)
+    resolved = _deep_merge(copy.deepcopy(DEFAULT_RIS_LAB_CONFIG), normalized)
+
+    geometry = resolved.get("geometry")
+    if not isinstance(geometry, dict):
+        raise ValueError("RIS Lab config geometry must be a mapping")
+
+    missing = _missing_required_fields(geometry)
+    if missing:
+        raise ValueError(
+            "RIS Lab config missing required fields: " + ", ".join(missing)
+        )
+
+    return _canonicalize_config(resolved)
+
+
+def load_ris_lab_config(path: str | Path) -> Dict[str, Any]:
+    config_path = Path(path)
+    if not config_path.exists():
+        raise FileNotFoundError(f"RIS Lab config not found: {config_path}")
+    with config_path.open("r", encoding="utf-8") as handle:
+        data = yaml.safe_load(handle)
+    return resolve_ris_lab_config(data)
+
+
+def compute_ris_lab_config_hash(config: Dict[str, Any]) -> str:
+    payload = json.dumps(config, sort_keys=True).encode("utf-8")
+    return hashlib.sha256(payload).hexdigest()
+
+
+def _ensure_output_dir(output_dir: Path) -> Path:
+    output_dir.mkdir(parents=True, exist_ok=True)
+    (output_dir / "plots").mkdir(parents=True, exist_ok=True)
+    (output_dir / "data").mkdir(parents=True, exist_ok=True)
+    return output_dir
+
+
+def snapshot_ris_lab_config(output_dir: Path, config: Dict[str, Any]) -> Dict[str, Any]:
+    output_dir = _ensure_output_dir(output_dir)
+    yaml_path = output_dir / "config.yaml"
+    json_path = output_dir / "config.json"
+    save_yaml(yaml_path, config)
+    save_json(json_path, config)
+
+    config_hash = compute_ris_lab_config_hash(config)
+    summary = {
+        "schema_version": config.get("schema_version", RIS_LAB_SCHEMA_VERSION),
+        "config": {
+            "hash_sha256": config_hash,
+            "path_yaml": str(yaml_path),
+            "path_json": str(json_path),
+        },
+    }
+    save_json(output_dir / "summary.json", summary)
+    return summary
+
+
+def resolve_and_snapshot_ris_lab_config(
+    config_path: str | Path,
+    output_dir: Optional[str | Path] = None,
+) -> tuple[Dict[str, Any], Path, Dict[str, Any]]:
+    config = load_ris_lab_config(config_path)
+    if output_dir is None:
+        output_cfg = config.get("output", {})
+        base_dir = output_cfg.get("base_dir", "outputs")
+        run_id = output_cfg.get("run_id")
+        output_path = create_output_dir(base_dir, run_id=run_id)
+    else:
+        output_path = _ensure_output_dir(Path(output_dir))
+
+    summary = snapshot_ris_lab_config(output_path, config)
+    return config, output_path, summary
diff --git a/tests/test_ris_config.py b/tests/test_ris_config.py
new file mode 100644
index 0000000000000000000000000000000000000000..425e3679bae77cdb6c92bd26bc4d66308a7c610c
--- /dev/null
+++ b/tests/test_ris_config.py
@@ -0,0 +1,58 @@
+import json
+import tempfile
+import unittest
+from pathlib import Path
+
+import yaml
+
+from app.ris.ris_config import (
+    compute_ris_lab_config_hash,
+    resolve_and_snapshot_ris_lab_config,
+    resolve_ris_lab_config,
+)
+
+
+class TestRisLabConfig(unittest.TestCase):
+    def test_minimal_config_resolves_defaults(self) -> None:
+        resolved = resolve_ris_lab_config(
+            {"geometry": {"nx": 4, "ny": 2, "dx": 0.5, "dy": 0.25}}
+        )
+        self.assertEqual(resolved["control"]["mode"], "uniform")
+        self.assertEqual(resolved["quantization"]["bits"], 0)
+        self.assertEqual(resolved["validation"]["rmse_db_max"], 2.0)
+        self.assertEqual(resolved["output"]["base_dir"], "outputs")
+
+    def test_missing_geometry_fields_reports_required(self) -> None:
+        with self.assertRaises(ValueError) as ctx:
+            resolve_ris_lab_config({"geometry": {"nx": 4}})
+        message = str(ctx.exception)
+        self.assertIn("geometry.ny", message)
+        self.assertIn("geometry.dx", message)
+        self.assertIn("geometry.dy", message)
+
+    def test_snapshot_writes_config_files_and_summary(self) -> None:
+        with tempfile.TemporaryDirectory() as tmpdir:
+            tmp_path = Path(tmpdir)
+            config_path = tmp_path / "ris.yaml"
+            yaml.safe_dump(
+                {
+                    "geometry": {"nx": 2, "ny": 2, "dx": 0.1, "dy": 0.2},
+                    "output": {"base_dir": tmpdir, "run_id": "unit-test"},
+                },
+                config_path.open("w", encoding="utf-8"),
+                sort_keys=False,
+            )
+
+            config, output_dir, summary = resolve_and_snapshot_ris_lab_config(config_path)
+            self.assertEqual(output_dir, tmp_path / "unit-test")
+            self.assertTrue((output_dir / "config.yaml").exists())
+            self.assertTrue((output_dir / "config.json").exists())
+            self.assertTrue((output_dir / "summary.json").exists())
+            self.assertEqual(summary["config"]["hash_sha256"], compute_ris_lab_config_hash(config))
+
+            loaded = json.loads((output_dir / "config.json").read_text(encoding="utf-8"))
+            self.assertEqual(loaded["geometry"]["nx"], 2)
+
+
+if __name__ == "__main__":
+    unittest.main()


thinking
**Reviewing modified and untracked files**

Noticed a changed JSON file likely updated externally, so I'll avoid modifying it and just include it as is. Next, I'll check diffs on key files like the ris package's __init__.py to identify relevant changes.
exec
/usr/bin/zsh -lc 'git diff /home/josh/Documents/Github/RIS_SIONNA/app/ris/__init__.py' in /home/josh/Documents/Github/RIS_SIONNA succeeded in 3ms:
diff --git a/app/ris/__init__.py b/app/ris/__init__.py
index a34ed97..bafa9ac 100644
--- a/app/ris/__init__.py
+++ b/app/ris/__init__.py
@@ -1,5 +1,13 @@
 """RIS core math primitives and helpers."""
 
+from .ris_config import (  # noqa: F401
+    RIS_LAB_SCHEMA_VERSION,
+    compute_ris_lab_config_hash,
+    load_ris_lab_config,
+    resolve_and_snapshot_ris_lab_config,
+    resolve_ris_lab_config,
+    snapshot_ris_lab_config,
+)
 from .ris_core import (  # noqa: F401
     RisFrame,
     RisGeometry,
file update:
diff --git a/app/ris/__init__.py b/app/ris/__init__.py
index a34ed971e3d2426533f5eb2eb56416e59d15db65..bafa9ac9ccd2097b564c1c45d7c7b06f3a223b47
--- a/app/ris/__init__.py
+++ b/app/ris/__init__.py
@@ -1,5 +1,13 @@
 """RIS core math primitives and helpers."""
 
+from .ris_config import (  # noqa: F401
+    RIS_LAB_SCHEMA_VERSION,
+    compute_ris_lab_config_hash,
+    load_ris_lab_config,
+    resolve_and_snapshot_ris_lab_config,
+    resolve_ris_lab_config,
+    snapshot_ris_lab_config,
+)
 from .ris_core import (  # noqa: F401
     RisFrame,
     RisGeometry,
diff --git a/app/ris/ris_config.py b/app/ris/ris_config.py
new file mode 100644
index 0000000000000000000000000000000000000000..744c390c8e0c6c83a435e97cc579a09e71756ef6
--- /dev/null
+++ b/app/ris/ris_config.py
@@ -0,0 +1,200 @@
+"""RIS Lab configuration schema and snapshot helpers."""
+
+from __future__ import annotations
+
+import copy
+import hashlib
+import json
+from pathlib import Path
+from typing import Any, Dict, Iterable, Optional
+
+import yaml
+
+from app.io import create_output_dir, save_json, save_yaml
+
+RIS_LAB_SCHEMA_VERSION = 1
+
+DEFAULT_RIS_LAB_CONFIG: Dict[str, Any] = {
+    "schema_version": RIS_LAB_SCHEMA_VERSION,
+    "geometry": {
+        "nx": None,
+        "ny": None,
+        "dx": None,
+        "dy": None,
+        "origin": [0.0, 0.0, 0.0],
+        "normal": [0.0, 0.0, 1.0],
+        "x_axis_hint": [1.0, 0.0, 0.0],
+    },
+    "control": {
+        "mode": "uniform",
+        "params": {"phase_rad": 0.0},
+    },
+    "quantization": {
+        "bits": 0,
+    },
+    "pattern_mode": {
+        "normalization": "peak_0db",
+        "rx_sweep_deg": {"start": -90.0, "stop": 90.0, "step": 2.0},
+    },
+    "link_mode": {
+        "weighting": "inverse_distance",
+        "enabled": False,
+    },
+    "validation": {
+        "normalization": "peak_0db",
+        "rmse_db_max": 2.0,
+        "peak_angle_err_deg_max": 2.0,
+        "peak_db_err_max": 1.5,
+    },
+    "experiment": {
+        "frequency_hz": 28_000_000_000,
+        "tx_incident_angle_deg": -30.0,
+    },
+    "output": {
+        "base_dir": "outputs",
+        "run_id": None,
+    },
+}
+
+_ALIAS_FIELDS = {
+    ("geometry", "nx"): [("geometry", "n")],
+    ("geometry", "ny"): [("geometry", "m")],
+    ("geometry", "dx"): [("geometry", "dx_m")],
+    ("geometry", "dy"): [("geometry", "dy_m")],
+}
+
+
+def _deep_merge(base: Dict[str, Any], override: Dict[str, Any]) -> Dict[str, Any]:
+    for key, value in override.items():
+        if isinstance(value, dict) and isinstance(base.get(key), dict):
+            base[key] = _deep_merge(base[key], value)
+        else:
+            base[key] = value
+    return base
+
+
+def _apply_aliases(config: Dict[str, Any]) -> Dict[str, Any]:
+    updated = copy.deepcopy(config)
+    for (section, key), aliases in _ALIAS_FIELDS.items():
+        section_data = updated.get(section)
+        if not isinstance(section_data, dict):
+            continue
+        if key in section_data:
+            continue
+        for alias_section, alias_key in aliases:
+            alias_data = updated.get(alias_section)
+            if isinstance(alias_data, dict) and alias_key in alias_data:
+                section_data[key] = alias_data[alias_key]
+                break
+        updated[section] = section_data
+    return updated
+
+
+def _missing_required_fields(geometry: Dict[str, Any]) -> list[str]:
+    required = ("nx", "ny", "dx", "dy")
+    missing = []
+    for key in required:
+        value = geometry.get(key)
+        if value is None:
+            missing.append(f"geometry.{key}")
+    return missing
+
+
+def _canonicalize_config(config: Dict[str, Any]) -> Dict[str, Any]:
+    ordered_keys = [
+        "schema_version",
+        "geometry",
+        "control",
+        "quantization",
+        "pattern_mode",
+        "link_mode",
+        "validation",
+        "experiment",
+        "output",
+    ]
+    ordered: Dict[str, Any] = {}
+    for key in ordered_keys:
+        if key in config:
+            ordered[key] = config[key]
+    extras = {k: v for k, v in config.items() if k not in ordered_keys}
+    for key in sorted(extras):
+        ordered[key] = extras[key]
+    return ordered
+
+
+def resolve_ris_lab_config(raw_config: Dict[str, Any]) -> Dict[str, Any]:
+    if not isinstance(raw_config, dict):
+        raise ValueError("RIS Lab config must be a YAML mapping")
+
+    normalized = _apply_aliases(raw_config)
+    resolved = _deep_merge(copy.deepcopy(DEFAULT_RIS_LAB_CONFIG), normalized)
+
+    geometry = resolved.get("geometry")
+    if not isinstance(geometry, dict):
+        raise ValueError("RIS Lab config geometry must be a mapping")
+
+    missing = _missing_required_fields(geometry)
+    if missing:
+        raise ValueError(
+            "RIS Lab config missing required fields: " + ", ".join(missing)
+        )
+
+    return _canonicalize_config(resolved)
+
+
+def load_ris_lab_config(path: str | Path) -> Dict[str, Any]:
+    config_path = Path(path)
+    if not config_path.exists():
+        raise FileNotFoundError(f"RIS Lab config not found: {config_path}")
+    with config_path.open("r", encoding="utf-8") as handle:
+        data = yaml.safe_load(handle)
+    return resolve_ris_lab_config(data)
+
+
+def compute_ris_lab_config_hash(config: Dict[str, Any]) -> str:
+    payload = json.dumps(config, sort_keys=True).encode("utf-8")
+    return hashlib.sha256(payload).hexdigest()
+
+
+def _ensure_output_dir(output_dir: Path) -> Path:
+    output_dir.mkdir(parents=True, exist_ok=True)
+    (output_dir / "plots").mkdir(parents=True, exist_ok=True)
+    (output_dir / "data").mkdir(parents=True, exist_ok=True)
+    return output_dir
+
+
+def snapshot_ris_lab_config(output_dir: Path, config: Dict[str, Any]) -> Dict[str, Any]:
+    output_dir = _ensure_output_dir(output_dir)
+    yaml_path = output_dir / "config.yaml"
+    json_path = output_dir / "config.json"
+    save_yaml(yaml_path, config)
+    save_json(json_path, config)
+
+    config_hash = compute_ris_lab_config_hash(config)
+    summary = {
+        "schema_version": config.get("schema_version", RIS_LAB_SCHEMA_VERSION),
+        "config": {
+            "hash_sha256": config_hash,
+            "path_yaml": str(yaml_path),
+            "path_json": str(json_path),
+        },
+    }
+    save_json(output_dir / "summary.json", summary)
+    return summary
+
+
+def resolve_and_snapshot_ris_lab_config(
+    config_path: str | Path,
+    output_dir: Optional[str | Path] = None,
+) -> tuple[Dict[str, Any], Path, Dict[str, Any]]:
+    config = load_ris_lab_config(config_path)
+    if output_dir is None:
+        output_cfg = config.get("output", {})
+        base_dir = output_cfg.get("base_dir", "outputs")
+        run_id = output_cfg.get("run_id")
+        output_path = create_output_dir(base_dir, run_id=run_id)
+    else:
+        output_path = _ensure_output_dir(Path(output_dir))
+
+    summary = snapshot_ris_lab_config(output_path, config)
+    return config, output_path, summary
diff --git a/tests/test_ris_config.py b/tests/test_ris_config.py
new file mode 100644
index 0000000000000000000000000000000000000000..425e3679bae77cdb6c92bd26bc4d66308a7c610c
--- /dev/null
+++ b/tests/test_ris_config.py
@@ -0,0 +1,58 @@
+import json
+import tempfile
+import unittest
+from pathlib import Path
+
+import yaml
+
+from app.ris.ris_config import (
+    compute_ris_lab_config_hash,
+    resolve_and_snapshot_ris_lab_config,
+    resolve_ris_lab_config,
+)
+
+
+class TestRisLabConfig(unittest.TestCase):
+    def test_minimal_config_resolves_defaults(self) -> None:
+        resolved = resolve_ris_lab_config(
+            {"geometry": {"nx": 4, "ny": 2, "dx": 0.5, "dy": 0.25}}
+        )
+        self.assertEqual(resolved["control"]["mode"], "uniform")
+        self.assertEqual(resolved["quantization"]["bits"], 0)
+        self.assertEqual(resolved["validation"]["rmse_db_max"], 2.0)
+        self.assertEqual(resolved["output"]["base_dir"], "outputs")
+
+    def test_missing_geometry_fields_reports_required(self) -> None:
+        with self.assertRaises(ValueError) as ctx:
+            resolve_ris_lab_config({"geometry": {"nx": 4}})
+        message = str(ctx.exception)
+        self.assertIn("geometry.ny", message)
+        self.assertIn("geometry.dx", message)
+        self.assertIn("geometry.dy", message)
+
+    def test_snapshot_writes_config_files_and_summary(self) -> None:
+        with tempfile.TemporaryDirectory() as tmpdir:
+            tmp_path = Path(tmpdir)
+            config_path = tmp_path / "ris.yaml"
+            yaml.safe_dump(
+                {
+                    "geometry": {"nx": 2, "ny": 2, "dx": 0.1, "dy": 0.2},
+                    "output": {"base_dir": tmpdir, "run_id": "unit-test"},
+                },
+                config_path.open("w", encoding="utf-8"),
+                sort_keys=False,
+            )
+
+            config, output_dir, summary = resolve_and_snapshot_ris_lab_config(config_path)
+            self.assertEqual(output_dir, tmp_path / "unit-test")
+            self.assertTrue((output_dir / "config.yaml").exists())
+            self.assertTrue((output_dir / "config.json").exists())
+            self.assertTrue((output_dir / "summary.json").exists())
+            self.assertEqual(summary["config"]["hash_sha256"], compute_ris_lab_config_hash(config))
+
+            loaded = json.loads((output_dir / "config.json").read_text(encoding="utf-8"))
+            self.assertEqual(loaded["geometry"]["nx"], 2)
+
+
+if __name__ == "__main__":
+    unittest.main()


thinking
**Planning validation and logs check**
exec
/usr/bin/zsh -lc 'tail -n 20 /home/josh/Documents/Github/RIS_SIONNA/.ralph/errors.log' in /home/josh/Documents/Github/RIS_SIONNA succeeded in 3ms:
# Error Log

> Failures and repeated issues. Use this to add guardrails.

[2026-01-20 17:57:10] ITERATION 1 left uncommitted changes; review run summary at /home/josh/Documents/Github/RIS_SIONNA/.ralph/runs/run-20260120-175122-20544-iter-1.md
file update:
diff --git a/app/ris/__init__.py b/app/ris/__init__.py
index a34ed971e3d2426533f5eb2eb56416e59d15db65..bafa9ac9ccd2097b564c1c45d7c7b06f3a223b47
--- a/app/ris/__init__.py
+++ b/app/ris/__init__.py
@@ -1,5 +1,13 @@
 """RIS core math primitives and helpers."""
 
+from .ris_config import (  # noqa: F401
+    RIS_LAB_SCHEMA_VERSION,
+    compute_ris_lab_config_hash,
+    load_ris_lab_config,
+    resolve_and_snapshot_ris_lab_config,
+    resolve_ris_lab_config,
+    snapshot_ris_lab_config,
+)
 from .ris_core import (  # noqa: F401
     RisFrame,
     RisGeometry,
diff --git a/app/ris/ris_config.py b/app/ris/ris_config.py
new file mode 100644
index 0000000000000000000000000000000000000000..744c390c8e0c6c83a435e97cc579a09e71756ef6
--- /dev/null
+++ b/app/ris/ris_config.py
@@ -0,0 +1,200 @@
+"""RIS Lab configuration schema and snapshot helpers."""
+
+from __future__ import annotations
+
+import copy
+import hashlib
+import json
+from pathlib import Path
+from typing import Any, Dict, Iterable, Optional
+
+import yaml
+
+from app.io import create_output_dir, save_json, save_yaml
+
+RIS_LAB_SCHEMA_VERSION = 1
+
+DEFAULT_RIS_LAB_CONFIG: Dict[str, Any] = {
+    "schema_version": RIS_LAB_SCHEMA_VERSION,
+    "geometry": {
+        "nx": None,
+        "ny": None,
+        "dx": None,
+        "dy": None,
+        "origin": [0.0, 0.0, 0.0],
+        "normal": [0.0, 0.0, 1.0],
+        "x_axis_hint": [1.0, 0.0, 0.0],
+    },
+    "control": {
+        "mode": "uniform",
+        "params": {"phase_rad": 0.0},
+    },
+    "quantization": {
+        "bits": 0,
+    },
+    "pattern_mode": {
+        "normalization": "peak_0db",
+        "rx_sweep_deg": {"start": -90.0, "stop": 90.0, "step": 2.0},
+    },
+    "link_mode": {
+        "weighting": "inverse_distance",
+        "enabled": False,
+    },
+    "validation": {
+        "normalization": "peak_0db",
+        "rmse_db_max": 2.0,
+        "peak_angle_err_deg_max": 2.0,
+        "peak_db_err_max": 1.5,
+    },
+    "experiment": {
+        "frequency_hz": 28_000_000_000,
+        "tx_incident_angle_deg": -30.0,
+    },
+    "output": {
+        "base_dir": "outputs",
+        "run_id": None,
+    },
+}
+
+_ALIAS_FIELDS = {
+    ("geometry", "nx"): [("geometry", "n")],
+    ("geometry", "ny"): [("geometry", "m")],
+    ("geometry", "dx"): [("geometry", "dx_m")],
+    ("geometry", "dy"): [("geometry", "dy_m")],
+}
+
+
+def _deep_merge(base: Dict[str, Any], override: Dict[str, Any]) -> Dict[str, Any]:
+    for key, value in override.items():
+        if isinstance(value, dict) and isinstance(base.get(key), dict):
+            base[key] = _deep_merge(base[key], value)
+        else:
+            base[key] = value
+    return base
+
+
+def _apply_aliases(config: Dict[str, Any]) -> Dict[str, Any]:
+    updated = copy.deepcopy(config)
+    for (section, key), aliases in _ALIAS_FIELDS.items():
+        section_data = updated.get(section)
+        if not isinstance(section_data, dict):
+            continue
+        if key in section_data:
+            continue
+        for alias_section, alias_key in aliases:
+            alias_data = updated.get(alias_section)
+            if isinstance(alias_data, dict) and alias_key in alias_data:
+                section_data[key] = alias_data[alias_key]
+                break
+        updated[section] = section_data
+    return updated
+
+
+def _missing_required_fields(geometry: Dict[str, Any]) -> list[str]:
+    required = ("nx", "ny", "dx", "dy")
+    missing = []
+    for key in required:
+        value = geometry.get(key)
+        if value is None:
+            missing.append(f"geometry.{key}")
+    return missing
+
+
+def _canonicalize_config(config: Dict[str, Any]) -> Dict[str, Any]:
+    ordered_keys = [
+        "schema_version",
+        "geometry",
+        "control",
+        "quantization",
+        "pattern_mode",
+        "link_mode",
+        "validation",
+        "experiment",
+        "output",
+    ]
+    ordered: Dict[str, Any] = {}
+    for key in ordered_keys:
+        if key in config:
+            ordered[key] = config[key]
+    extras = {k: v for k, v in config.items() if k not in ordered_keys}
+    for key in sorted(extras):
+        ordered[key] = extras[key]
+    return ordered
+
+
+def resolve_ris_lab_config(raw_config: Dict[str, Any]) -> Dict[str, Any]:
+    if not isinstance(raw_config, dict):
+        raise ValueError("RIS Lab config must be a YAML mapping")
+
+    normalized = _apply_aliases(raw_config)
+    resolved = _deep_merge(copy.deepcopy(DEFAULT_RIS_LAB_CONFIG), normalized)
+
+    geometry = resolved.get("geometry")
+    if not isinstance(geometry, dict):
+        raise ValueError("RIS Lab config geometry must be a mapping")
+
+    missing = _missing_required_fields(geometry)
+    if missing:
+        raise ValueError(
+            "RIS Lab config missing required fields: " + ", ".join(missing)
+        )
+
+    return _canonicalize_config(resolved)
+
+
+def load_ris_lab_config(path: str | Path) -> Dict[str, Any]:
+    config_path = Path(path)
+    if not config_path.exists():
+        raise FileNotFoundError(f"RIS Lab config not found: {config_path}")
+    with config_path.open("r", encoding="utf-8") as handle:
+        data = yaml.safe_load(handle)
+    return resolve_ris_lab_config(data)
+
+
+def compute_ris_lab_config_hash(config: Dict[str, Any]) -> str:
+    payload = json.dumps(config, sort_keys=True).encode("utf-8")
+    return hashlib.sha256(payload).hexdigest()
+
+
+def _ensure_output_dir(output_dir: Path) -> Path:
+    output_dir.mkdir(parents=True, exist_ok=True)
+    (output_dir / "plots").mkdir(parents=True, exist_ok=True)
+    (output_dir / "data").mkdir(parents=True, exist_ok=True)
+    return output_dir
+
+
+def snapshot_ris_lab_config(output_dir: Path, config: Dict[str, Any]) -> Dict[str, Any]:
+    output_dir = _ensure_output_dir(output_dir)
+    yaml_path = output_dir / "config.yaml"
+    json_path = output_dir / "config.json"
+    save_yaml(yaml_path, config)
+    save_json(json_path, config)
+
+    config_hash = compute_ris_lab_config_hash(config)
+    summary = {
+        "schema_version": config.get("schema_version", RIS_LAB_SCHEMA_VERSION),
+        "config": {
+            "hash_sha256": config_hash,
+            "path_yaml": str(yaml_path),
+            "path_json": str(json_path),
+        },
+    }
+    save_json(output_dir / "summary.json", summary)
+    return summary
+
+
+def resolve_and_snapshot_ris_lab_config(
+    config_path: str | Path,
+    output_dir: Optional[str | Path] = None,
+) -> tuple[Dict[str, Any], Path, Dict[str, Any]]:
+    config = load_ris_lab_config(config_path)
+    if output_dir is None:
+        output_cfg = config.get("output", {})
+        base_dir = output_cfg.get("base_dir", "outputs")
+        run_id = output_cfg.get("run_id")
+        output_path = create_output_dir(base_dir, run_id=run_id)
+    else:
+        output_path = _ensure_output_dir(Path(output_dir))
+
+    summary = snapshot_ris_lab_config(output_path, config)
+    return config, output_path, summary
diff --git a/tests/test_ris_config.py b/tests/test_ris_config.py
new file mode 100644
index 0000000000000000000000000000000000000000..425e3679bae77cdb6c92bd26bc4d66308a7c610c
--- /dev/null
+++ b/tests/test_ris_config.py
@@ -0,0 +1,58 @@
+import json
+import tempfile
+import unittest
+from pathlib import Path
+
+import yaml
+
+from app.ris.ris_config import (
+    compute_ris_lab_config_hash,
+    resolve_and_snapshot_ris_lab_config,
+    resolve_ris_lab_config,
+)
+
+
+class TestRisLabConfig(unittest.TestCase):
+    def test_minimal_config_resolves_defaults(self) -> None:
+        resolved = resolve_ris_lab_config(
+            {"geometry": {"nx": 4, "ny": 2, "dx": 0.5, "dy": 0.25}}
+        )
+        self.assertEqual(resolved["control"]["mode"], "uniform")
+        self.assertEqual(resolved["quantization"]["bits"], 0)
+        self.assertEqual(resolved["validation"]["rmse_db_max"], 2.0)
+        self.assertEqual(resolved["output"]["base_dir"], "outputs")
+
+    def test_missing_geometry_fields_reports_required(self) -> None:
+        with self.assertRaises(ValueError) as ctx:
+            resolve_ris_lab_config({"geometry": {"nx": 4}})
+        message = str(ctx.exception)
+        self.assertIn("geometry.ny", message)
+        self.assertIn("geometry.dx", message)
+        self.assertIn("geometry.dy", message)
+
+    def test_snapshot_writes_config_files_and_summary(self) -> None:
+        with tempfile.TemporaryDirectory() as tmpdir:
+            tmp_path = Path(tmpdir)
+            config_path = tmp_path / "ris.yaml"
+            yaml.safe_dump(
+                {
+                    "geometry": {"nx": 2, "ny": 2, "dx": 0.1, "dy": 0.2},
+                    "output": {"base_dir": tmpdir, "run_id": "unit-test"},
+                },
+                config_path.open("w", encoding="utf-8"),
+                sort_keys=False,
+            )
+
+            config, output_dir, summary = resolve_and_snapshot_ris_lab_config(config_path)
+            self.assertEqual(output_dir, tmp_path / "unit-test")
+            self.assertTrue((output_dir / "config.yaml").exists())
+            self.assertTrue((output_dir / "config.json").exists())
+            self.assertTrue((output_dir / "summary.json").exists())
+            self.assertEqual(summary["config"]["hash_sha256"], compute_ris_lab_config_hash(config))
+
+            loaded = json.loads((output_dir / "config.json").read_text(encoding="utf-8"))
+            self.assertEqual(loaded["geometry"]["nx"], 2)
+
+
+if __name__ == "__main__":
+    unittest.main()


thinking
**Verifying minor errors.log change**

Checking the diff for errors.log to confirm if the single-line change is just a newline or trivial.
exec
/usr/bin/zsh -lc 'git diff /home/josh/Documents/Github/RIS_SIONNA/.ralph/errors.log' in /home/josh/Documents/Github/RIS_SIONNA succeeded in 3ms:
diff --git a/.ralph/errors.log b/.ralph/errors.log
index 77a64ff..de3120a 100644
--- a/.ralph/errors.log
+++ b/.ralph/errors.log
@@ -2,3 +2,4 @@
 
 > Failures and repeated issues. Use this to add guardrails.
 
+[2026-01-20 17:57:10] ITERATION 1 left uncommitted changes; review run summary at /home/josh/Documents/Github/RIS_SIONNA/.ralph/runs/run-20260120-175122-20544-iter-1.md
file update:
diff --git a/app/ris/__init__.py b/app/ris/__init__.py
index a34ed971e3d2426533f5eb2eb56416e59d15db65..bafa9ac9ccd2097b564c1c45d7c7b06f3a223b47
--- a/app/ris/__init__.py
+++ b/app/ris/__init__.py
@@ -1,5 +1,13 @@
 """RIS core math primitives and helpers."""
 
+from .ris_config import (  # noqa: F401
+    RIS_LAB_SCHEMA_VERSION,
+    compute_ris_lab_config_hash,
+    load_ris_lab_config,
+    resolve_and_snapshot_ris_lab_config,
+    resolve_ris_lab_config,
+    snapshot_ris_lab_config,
+)
 from .ris_core import (  # noqa: F401
     RisFrame,
     RisGeometry,
diff --git a/app/ris/ris_config.py b/app/ris/ris_config.py
new file mode 100644
index 0000000000000000000000000000000000000000..744c390c8e0c6c83a435e97cc579a09e71756ef6
--- /dev/null
+++ b/app/ris/ris_config.py
@@ -0,0 +1,200 @@
+"""RIS Lab configuration schema and snapshot helpers."""
+
+from __future__ import annotations
+
+import copy
+import hashlib
+import json
+from pathlib import Path
+from typing import Any, Dict, Iterable, Optional
+
+import yaml
+
+from app.io import create_output_dir, save_json, save_yaml
+
+RIS_LAB_SCHEMA_VERSION = 1
+
+DEFAULT_RIS_LAB_CONFIG: Dict[str, Any] = {
+    "schema_version": RIS_LAB_SCHEMA_VERSION,
+    "geometry": {
+        "nx": None,
+        "ny": None,
+        "dx": None,
+        "dy": None,
+        "origin": [0.0, 0.0, 0.0],
+        "normal": [0.0, 0.0, 1.0],
+        "x_axis_hint": [1.0, 0.0, 0.0],
+    },
+    "control": {
+        "mode": "uniform",
+        "params": {"phase_rad": 0.0},
+    },
+    "quantization": {
+        "bits": 0,
+    },
+    "pattern_mode": {
+        "normalization": "peak_0db",
+        "rx_sweep_deg": {"start": -90.0, "stop": 90.0, "step": 2.0},
+    },
+    "link_mode": {
+        "weighting": "inverse_distance",
+        "enabled": False,
+    },
+    "validation": {
+        "normalization": "peak_0db",
+        "rmse_db_max": 2.0,
+        "peak_angle_err_deg_max": 2.0,
+        "peak_db_err_max": 1.5,
+    },
+    "experiment": {
+        "frequency_hz": 28_000_000_000,
+        "tx_incident_angle_deg": -30.0,
+    },
+    "output": {
+        "base_dir": "outputs",
+        "run_id": None,
+    },
+}
+
+_ALIAS_FIELDS = {
+    ("geometry", "nx"): [("geometry", "n")],
+    ("geometry", "ny"): [("geometry", "m")],
+    ("geometry", "dx"): [("geometry", "dx_m")],
+    ("geometry", "dy"): [("geometry", "dy_m")],
+}
+
+
+def _deep_merge(base: Dict[str, Any], override: Dict[str, Any]) -> Dict[str, Any]:
+    for key, value in override.items():
+        if isinstance(value, dict) and isinstance(base.get(key), dict):
+            base[key] = _deep_merge(base[key], value)
+        else:
+            base[key] = value
+    return base
+
+
+def _apply_aliases(config: Dict[str, Any]) -> Dict[str, Any]:
+    updated = copy.deepcopy(config)
+    for (section, key), aliases in _ALIAS_FIELDS.items():
+        section_data = updated.get(section)
+        if not isinstance(section_data, dict):
+            continue
+        if key in section_data:
+            continue
+        for alias_section, alias_key in aliases:
+            alias_data = updated.get(alias_section)
+            if isinstance(alias_data, dict) and alias_key in alias_data:
+                section_data[key] = alias_data[alias_key]
+                break
+        updated[section] = section_data
+    return updated
+
+
+def _missing_required_fields(geometry: Dict[str, Any]) -> list[str]:
+    required = ("nx", "ny", "dx", "dy")
+    missing = []
+    for key in required:
+        value = geometry.get(key)
+        if value is None:
+            missing.append(f"geometry.{key}")
+    return missing
+
+
+def _canonicalize_config(config: Dict[str, Any]) -> Dict[str, Any]:
+    ordered_keys = [
+        "schema_version",
+        "geometry",
+        "control",
+        "quantization",
+        "pattern_mode",
+        "link_mode",
+        "validation",
+        "experiment",
+        "output",
+    ]
+    ordered: Dict[str, Any] = {}
+    for key in ordered_keys:
+        if key in config:
+            ordered[key] = config[key]
+    extras = {k: v for k, v in config.items() if k not in ordered_keys}
+    for key in sorted(extras):
+        ordered[key] = extras[key]
+    return ordered
+
+
+def resolve_ris_lab_config(raw_config: Dict[str, Any]) -> Dict[str, Any]:
+    if not isinstance(raw_config, dict):
+        raise ValueError("RIS Lab config must be a YAML mapping")
+
+    normalized = _apply_aliases(raw_config)
+    resolved = _deep_merge(copy.deepcopy(DEFAULT_RIS_LAB_CONFIG), normalized)
+
+    geometry = resolved.get("geometry")
+    if not isinstance(geometry, dict):
+        raise ValueError("RIS Lab config geometry must be a mapping")
+
+    missing = _missing_required_fields(geometry)
+    if missing:
+        raise ValueError(
+            "RIS Lab config missing required fields: " + ", ".join(missing)
+        )
+
+    return _canonicalize_config(resolved)
+
+
+def load_ris_lab_config(path: str | Path) -> Dict[str, Any]:
+    config_path = Path(path)
+    if not config_path.exists():
+        raise FileNotFoundError(f"RIS Lab config not found: {config_path}")
+    with config_path.open("r", encoding="utf-8") as handle:
+        data = yaml.safe_load(handle)
+    return resolve_ris_lab_config(data)
+
+
+def compute_ris_lab_config_hash(config: Dict[str, Any]) -> str:
+    payload = json.dumps(config, sort_keys=True).encode("utf-8")
+    return hashlib.sha256(payload).hexdigest()
+
+
+def _ensure_output_dir(output_dir: Path) -> Path:
+    output_dir.mkdir(parents=True, exist_ok=True)
+    (output_dir / "plots").mkdir(parents=True, exist_ok=True)
+    (output_dir / "data").mkdir(parents=True, exist_ok=True)
+    return output_dir
+
+
+def snapshot_ris_lab_config(output_dir: Path, config: Dict[str, Any]) -> Dict[str, Any]:
+    output_dir = _ensure_output_dir(output_dir)
+    yaml_path = output_dir / "config.yaml"
+    json_path = output_dir / "config.json"
+    save_yaml(yaml_path, config)
+    save_json(json_path, config)
+
+    config_hash = compute_ris_lab_config_hash(config)
+    summary = {
+        "schema_version": config.get("schema_version", RIS_LAB_SCHEMA_VERSION),
+        "config": {
+            "hash_sha256": config_hash,
+            "path_yaml": str(yaml_path),
+            "path_json": str(json_path),
+        },
+    }
+    save_json(output_dir / "summary.json", summary)
+    return summary
+
+
+def resolve_and_snapshot_ris_lab_config(
+    config_path: str | Path,
+    output_dir: Optional[str | Path] = None,
+) -> tuple[Dict[str, Any], Path, Dict[str, Any]]:
+    config = load_ris_lab_config(config_path)
+    if output_dir is None:
+        output_cfg = config.get("output", {})
+        base_dir = output_cfg.get("base_dir", "outputs")
+        run_id = output_cfg.get("run_id")
+        output_path = create_output_dir(base_dir, run_id=run_id)
+    else:
+        output_path = _ensure_output_dir(Path(output_dir))
+
+    summary = snapshot_ris_lab_config(output_path, config)
+    return config, output_path, summary
diff --git a/tests/test_ris_config.py b/tests/test_ris_config.py
new file mode 100644
index 0000000000000000000000000000000000000000..425e3679bae77cdb6c92bd26bc4d66308a7c610c
--- /dev/null
+++ b/tests/test_ris_config.py
@@ -0,0 +1,58 @@
+import json
+import tempfile
+import unittest
+from pathlib import Path
+
+import yaml
+
+from app.ris.ris_config import (
+    compute_ris_lab_config_hash,
+    resolve_and_snapshot_ris_lab_config,
+    resolve_ris_lab_config,
+)
+
+
+class TestRisLabConfig(unittest.TestCase):
+    def test_minimal_config_resolves_defaults(self) -> None:
+        resolved = resolve_ris_lab_config(
+            {"geometry": {"nx": 4, "ny": 2, "dx": 0.5, "dy": 0.25}}
+        )
+        self.assertEqual(resolved["control"]["mode"], "uniform")
+        self.assertEqual(resolved["quantization"]["bits"], 0)
+        self.assertEqual(resolved["validation"]["rmse_db_max"], 2.0)
+        self.assertEqual(resolved["output"]["base_dir"], "outputs")
+
+    def test_missing_geometry_fields_reports_required(self) -> None:
+        with self.assertRaises(ValueError) as ctx:
+            resolve_ris_lab_config({"geometry": {"nx": 4}})
+        message = str(ctx.exception)
+        self.assertIn("geometry.ny", message)
+        self.assertIn("geometry.dx", message)
+        self.assertIn("geometry.dy", message)
+
+    def test_snapshot_writes_config_files_and_summary(self) -> None:
+        with tempfile.TemporaryDirectory() as tmpdir:
+            tmp_path = Path(tmpdir)
+            config_path = tmp_path / "ris.yaml"
+            yaml.safe_dump(
+                {
+                    "geometry": {"nx": 2, "ny": 2, "dx": 0.1, "dy": 0.2},
+                    "output": {"base_dir": tmpdir, "run_id": "unit-test"},
+                },
+                config_path.open("w", encoding="utf-8"),
+                sort_keys=False,
+            )
+
+            config, output_dir, summary = resolve_and_snapshot_ris_lab_config(config_path)
+            self.assertEqual(output_dir, tmp_path / "unit-test")
+            self.assertTrue((output_dir / "config.yaml").exists())
+            self.assertTrue((output_dir / "config.json").exists())
+            self.assertTrue((output_dir / "summary.json").exists())
+            self.assertEqual(summary["config"]["hash_sha256"], compute_ris_lab_config_hash(config))
+
+            loaded = json.loads((output_dir / "config.json").read_text(encoding="utf-8"))
+            self.assertEqual(loaded["geometry"]["nx"], 2)
+
+
+if __name__ == "__main__":
+    unittest.main()



thinking
**Noticing unexpected preexisting modifications**

I see modifications to PRD and run logs that I didn't make in this run but appeared before; since instructions say to stop and ask on unexpected changes, I’ll wait for user guidance before proceeding.
thinking
**Treating preexisting changes as expected and preparing to commit**

Due to conflicts in instructions, I’m proceeding without user prompts, treating prior uncommitted changes as expected; next, I’ll clean unused imports in config, note test failures, and stage new/untracked files before committing.
file update
M /home/josh/Documents/Github/RIS_SIONNA/app/ris/ris_config.py
@@ -8,3 +8,3 @@
 from pathlib import Path
-from typing import Any, Dict, Iterable, Optional
+from typing import Any, Dict, Optional
 
apply_patch(auto_approved=true) exited 0 in 5ms:
Success. Updated the following files:
M /home/josh/Documents/Github/RIS_SIONNA/app/ris/ris_config.py
file update:
diff --git a/app/ris/__init__.py b/app/ris/__init__.py
index a34ed971e3d2426533f5eb2eb56416e59d15db65..bafa9ac9ccd2097b564c1c45d7c7b06f3a223b47
--- a/app/ris/__init__.py
+++ b/app/ris/__init__.py
@@ -1,5 +1,13 @@
 """RIS core math primitives and helpers."""
 
+from .ris_config import (  # noqa: F401
+    RIS_LAB_SCHEMA_VERSION,
+    compute_ris_lab_config_hash,
+    load_ris_lab_config,
+    resolve_and_snapshot_ris_lab_config,
+    resolve_ris_lab_config,
+    snapshot_ris_lab_config,
+)
 from .ris_core import (  # noqa: F401
     RisFrame,
     RisGeometry,
diff --git a/app/ris/ris_config.py b/app/ris/ris_config.py
new file mode 100644
index 0000000000000000000000000000000000000000..d1bdcffc0da5d306d0f4f328064e4cbc1b453b6d
--- /dev/null
+++ b/app/ris/ris_config.py
@@ -0,0 +1,200 @@
+"""RIS Lab configuration schema and snapshot helpers."""
+
+from __future__ import annotations
+
+import copy
+import hashlib
+import json
+from pathlib import Path
+from typing import Any, Dict, Optional
+
+import yaml
+
+from app.io import create_output_dir, save_json, save_yaml
+
+RIS_LAB_SCHEMA_VERSION = 1
+
+DEFAULT_RIS_LAB_CONFIG: Dict[str, Any] = {
+    "schema_version": RIS_LAB_SCHEMA_VERSION,
+    "geometry": {
+        "nx": None,
+        "ny": None,
+        "dx": None,
+        "dy": None,
+        "origin": [0.0, 0.0, 0.0],
+        "normal": [0.0, 0.0, 1.0],
+        "x_axis_hint": [1.0, 0.0, 0.0],
+    },
+    "control": {
+        "mode": "uniform",
+        "params": {"phase_rad": 0.0},
+    },
+    "quantization": {
+        "bits": 0,
+    },
+    "pattern_mode": {
+        "normalization": "peak_0db",
+        "rx_sweep_deg": {"start": -90.0, "stop": 90.0, "step": 2.0},
+    },
+    "link_mode": {
+        "weighting": "inverse_distance",
+        "enabled": False,
+    },
+    "validation": {
+        "normalization": "peak_0db",
+        "rmse_db_max": 2.0,
+        "peak_angle_err_deg_max": 2.0,
+        "peak_db_err_max": 1.5,
+    },
+    "experiment": {
+        "frequency_hz": 28_000_000_000,
+        "tx_incident_angle_deg": -30.0,
+    },
+    "output": {
+        "base_dir": "outputs",
+        "run_id": None,
+    },
+}
+
+_ALIAS_FIELDS = {
+    ("geometry", "nx"): [("geometry", "n")],
+    ("geometry", "ny"): [("geometry", "m")],
+    ("geometry", "dx"): [("geometry", "dx_m")],
+    ("geometry", "dy"): [("geometry", "dy_m")],
+}
+
+
+def _deep_merge(base: Dict[str, Any], override: Dict[str, Any]) -> Dict[str, Any]:
+    for key, value in override.items():
+        if isinstance(value, dict) and isinstance(base.get(key), dict):
+            base[key] = _deep_merge(base[key], value)
+        else:
+            base[key] = value
+    return base
+
+
+def _apply_aliases(config: Dict[str, Any]) -> Dict[str, Any]:
+    updated = copy.deepcopy(config)
+    for (section, key), aliases in _ALIAS_FIELDS.items():
+        section_data = updated.get(section)
+        if not isinstance(section_data, dict):
+            continue
+        if key in section_data:
+            continue
+        for alias_section, alias_key in aliases:
+            alias_data = updated.get(alias_section)
+            if isinstance(alias_data, dict) and alias_key in alias_data:
+                section_data[key] = alias_data[alias_key]
+                break
+        updated[section] = section_data
+    return updated
+
+
+def _missing_required_fields(geometry: Dict[str, Any]) -> list[str]:
+    required = ("nx", "ny", "dx", "dy")
+    missing = []
+    for key in required:
+        value = geometry.get(key)
+        if value is None:
+            missing.append(f"geometry.{key}")
+    return missing
+
+
+def _canonicalize_config(config: Dict[str, Any]) -> Dict[str, Any]:
+    ordered_keys = [
+        "schema_version",
+        "geometry",
+        "control",
+        "quantization",
+        "pattern_mode",
+        "link_mode",
+        "validation",
+        "experiment",
+        "output",
+    ]
+    ordered: Dict[str, Any] = {}
+    for key in ordered_keys:
+        if key in config:
+            ordered[key] = config[key]
+    extras = {k: v for k, v in config.items() if k not in ordered_keys}
+    for key in sorted(extras):
+        ordered[key] = extras[key]
+    return ordered
+
+
+def resolve_ris_lab_config(raw_config: Dict[str, Any]) -> Dict[str, Any]:
+    if not isinstance(raw_config, dict):
+        raise ValueError("RIS Lab config must be a YAML mapping")
+
+    normalized = _apply_aliases(raw_config)
+    resolved = _deep_merge(copy.deepcopy(DEFAULT_RIS_LAB_CONFIG), normalized)
+
+    geometry = resolved.get("geometry")
+    if not isinstance(geometry, dict):
+        raise ValueError("RIS Lab config geometry must be a mapping")
+
+    missing = _missing_required_fields(geometry)
+    if missing:
+        raise ValueError(
+            "RIS Lab config missing required fields: " + ", ".join(missing)
+        )
+
+    return _canonicalize_config(resolved)
+
+
+def load_ris_lab_config(path: str | Path) -> Dict[str, Any]:
+    config_path = Path(path)
+    if not config_path.exists():
+        raise FileNotFoundError(f"RIS Lab config not found: {config_path}")
+    with config_path.open("r", encoding="utf-8") as handle:
+        data = yaml.safe_load(handle)
+    return resolve_ris_lab_config(data)
+
+
+def compute_ris_lab_config_hash(config: Dict[str, Any]) -> str:
+    payload = json.dumps(config, sort_keys=True).encode("utf-8")
+    return hashlib.sha256(payload).hexdigest()
+
+
+def _ensure_output_dir(output_dir: Path) -> Path:
+    output_dir.mkdir(parents=True, exist_ok=True)
+    (output_dir / "plots").mkdir(parents=True, exist_ok=True)
+    (output_dir / "data").mkdir(parents=True, exist_ok=True)
+    return output_dir
+
+
+def snapshot_ris_lab_config(output_dir: Path, config: Dict[str, Any]) -> Dict[str, Any]:
+    output_dir = _ensure_output_dir(output_dir)
+    yaml_path = output_dir / "config.yaml"
+    json_path = output_dir / "config.json"
+    save_yaml(yaml_path, config)
+    save_json(json_path, config)
+
+    config_hash = compute_ris_lab_config_hash(config)
+    summary = {
+        "schema_version": config.get("schema_version", RIS_LAB_SCHEMA_VERSION),
+        "config": {
+            "hash_sha256": config_hash,
+            "path_yaml": str(yaml_path),
+            "path_json": str(json_path),
+        },
+    }
+    save_json(output_dir / "summary.json", summary)
+    return summary
+
+
+def resolve_and_snapshot_ris_lab_config(
+    config_path: str | Path,
+    output_dir: Optional[str | Path] = None,
+) -> tuple[Dict[str, Any], Path, Dict[str, Any]]:
+    config = load_ris_lab_config(config_path)
+    if output_dir is None:
+        output_cfg = config.get("output", {})
+        base_dir = output_cfg.get("base_dir", "outputs")
+        run_id = output_cfg.get("run_id")
+        output_path = create_output_dir(base_dir, run_id=run_id)
+    else:
+        output_path = _ensure_output_dir(Path(output_dir))
+
+    summary = snapshot_ris_lab_config(output_path, config)
+    return config, output_path, summary
diff --git a/tests/test_ris_config.py b/tests/test_ris_config.py
new file mode 100644
index 0000000000000000000000000000000000000000..425e3679bae77cdb6c92bd26bc4d66308a7c610c
--- /dev/null
+++ b/tests/test_ris_config.py
@@ -0,0 +1,58 @@
+import json
+import tempfile
+import unittest
+from pathlib import Path
+
+import yaml
+
+from app.ris.ris_config import (
+    compute_ris_lab_config_hash,
+    resolve_and_snapshot_ris_lab_config,
+    resolve_ris_lab_config,
+)
+
+
+class TestRisLabConfig(unittest.TestCase):
+    def test_minimal_config_resolves_defaults(self) -> None:
+        resolved = resolve_ris_lab_config(
+            {"geometry": {"nx": 4, "ny": 2, "dx": 0.5, "dy": 0.25}}
+        )
+        self.assertEqual(resolved["control"]["mode"], "uniform")
+        self.assertEqual(resolved["quantization"]["bits"], 0)
+        self.assertEqual(resolved["validation"]["rmse_db_max"], 2.0)
+        self.assertEqual(resolved["output"]["base_dir"], "outputs")
+
+    def test_missing_geometry_fields_reports_required(self) -> None:
+        with self.assertRaises(ValueError) as ctx:
+            resolve_ris_lab_config({"geometry": {"nx": 4}})
+        message = str(ctx.exception)
+        self.assertIn("geometry.ny", message)
+        self.assertIn("geometry.dx", message)
+        self.assertIn("geometry.dy", message)
+
+    def test_snapshot_writes_config_files_and_summary(self) -> None:
+        with tempfile.TemporaryDirectory() as tmpdir:
+            tmp_path = Path(tmpdir)
+            config_path = tmp_path / "ris.yaml"
+            yaml.safe_dump(
+                {
+                    "geometry": {"nx": 2, "ny": 2, "dx": 0.1, "dy": 0.2},
+                    "output": {"base_dir": tmpdir, "run_id": "unit-test"},
+                },
+                config_path.open("w", encoding="utf-8"),
+                sort_keys=False,
+            )
+
+            config, output_dir, summary = resolve_and_snapshot_ris_lab_config(config_path)
+            self.assertEqual(output_dir, tmp_path / "unit-test")
+            self.assertTrue((output_dir / "config.yaml").exists())
+            self.assertTrue((output_dir / "config.json").exists())
+            self.assertTrue((output_dir / "summary.json").exists())
+            self.assertEqual(summary["config"]["hash_sha256"], compute_ris_lab_config_hash(config))
+
+            loaded = json.loads((output_dir / "config.json").read_text(encoding="utf-8"))
+            self.assertEqual(loaded["geometry"]["nx"], 2)
+
+
+if __name__ == "__main__":
+    unittest.main()

file update:
diff --git a/app/ris/__init__.py b/app/ris/__init__.py
index a34ed971e3d2426533f5eb2eb56416e59d15db65..bafa9ac9ccd2097b564c1c45d7c7b06f3a223b47
--- a/app/ris/__init__.py
+++ b/app/ris/__init__.py
@@ -1,5 +1,13 @@
 """RIS core math primitives and helpers."""
 
+from .ris_config import (  # noqa: F401
+    RIS_LAB_SCHEMA_VERSION,
+    compute_ris_lab_config_hash,
+    load_ris_lab_config,
+    resolve_and_snapshot_ris_lab_config,
+    resolve_ris_lab_config,
+    snapshot_ris_lab_config,
+)
 from .ris_core import (  # noqa: F401
     RisFrame,
     RisGeometry,
diff --git a/app/ris/ris_config.py b/app/ris/ris_config.py
new file mode 100644
index 0000000000000000000000000000000000000000..d1bdcffc0da5d306d0f4f328064e4cbc1b453b6d
--- /dev/null
+++ b/app/ris/ris_config.py
@@ -0,0 +1,200 @@
+"""RIS Lab configuration schema and snapshot helpers."""
+
+from __future__ import annotations
+
+import copy
+import hashlib
+import json
+from pathlib import Path
+from typing import Any, Dict, Optional
+
+import yaml
+
+from app.io import create_output_dir, save_json, save_yaml
+
+RIS_LAB_SCHEMA_VERSION = 1
+
+DEFAULT_RIS_LAB_CONFIG: Dict[str, Any] = {
+    "schema_version": RIS_LAB_SCHEMA_VERSION,
+    "geometry": {
+        "nx": None,
+        "ny": None,
+        "dx": None,
+        "dy": None,
+        "origin": [0.0, 0.0, 0.0],
+        "normal": [0.0, 0.0, 1.0],
+        "x_axis_hint": [1.0, 0.0, 0.0],
+    },
+    "control": {
+        "mode": "uniform",
+        "params": {"phase_rad": 0.0},
+    },
+    "quantization": {
+        "bits": 0,
+    },
+    "pattern_mode": {
+        "normalization": "peak_0db",
+        "rx_sweep_deg": {"start": -90.0, "stop": 90.0, "step": 2.0},
+    },
+    "link_mode": {
+        "weighting": "inverse_distance",
+        "enabled": False,
+    },
+    "validation": {
+        "normalization": "peak_0db",
+        "rmse_db_max": 2.0,
+        "peak_angle_err_deg_max": 2.0,
+        "peak_db_err_max": 1.5,
+    },
+    "experiment": {
+        "frequency_hz": 28_000_000_000,
+        "tx_incident_angle_deg": -30.0,
+    },
+    "output": {
+        "base_dir": "outputs",
+        "run_id": None,
+    },
+}
+
+_ALIAS_FIELDS = {
+    ("geometry", "nx"): [("geometry", "n")],
+    ("geometry", "ny"): [("geometry", "m")],
+    ("geometry", "dx"): [("geometry", "dx_m")],
+    ("geometry", "dy"): [("geometry", "dy_m")],
+}
+
+
+def _deep_merge(base: Dict[str, Any], override: Dict[str, Any]) -> Dict[str, Any]:
+    for key, value in override.items():
+        if isinstance(value, dict) and isinstance(base.get(key), dict):
+            base[key] = _deep_merge(base[key], value)
+        else:
+            base[key] = value
+    return base
+
+
+def _apply_aliases(config: Dict[str, Any]) -> Dict[str, Any]:
+    updated = copy.deepcopy(config)
+    for (section, key), aliases in _ALIAS_FIELDS.items():
+        section_data = updated.get(section)
+        if not isinstance(section_data, dict):
+            continue
+        if key in section_data:
+            continue
+        for alias_section, alias_key in aliases:
+            alias_data = updated.get(alias_section)
+            if isinstance(alias_data, dict) and alias_key in alias_data:
+                section_data[key] = alias_data[alias_key]
+                break
+        updated[section] = section_data
+    return updated
+
+
+def _missing_required_fields(geometry: Dict[str, Any]) -> list[str]:
+    required = ("nx", "ny", "dx", "dy")
+    missing = []
+    for key in required:
+        value = geometry.get(key)
+        if value is None:
+            missing.append(f"geometry.{key}")
+    return missing
+
+
+def _canonicalize_config(config: Dict[str, Any]) -> Dict[str, Any]:
+    ordered_keys = [
+        "schema_version",
+        "geometry",
+        "control",
+        "quantization",
+        "pattern_mode",
+        "link_mode",
+        "validation",
+        "experiment",
+        "output",
+    ]
+    ordered: Dict[str, Any] = {}
+    for key in ordered_keys:
+        if key in config:
+            ordered[key] = config[key]
+    extras = {k: v for k, v in config.items() if k not in ordered_keys}
+    for key in sorted(extras):
+        ordered[key] = extras[key]
+    return ordered
+
+
+def resolve_ris_lab_config(raw_config: Dict[str, Any]) -> Dict[str, Any]:
+    if not isinstance(raw_config, dict):
+        raise ValueError("RIS Lab config must be a YAML mapping")
+
+    normalized = _apply_aliases(raw_config)
+    resolved = _deep_merge(copy.deepcopy(DEFAULT_RIS_LAB_CONFIG), normalized)
+
+    geometry = resolved.get("geometry")
+    if not isinstance(geometry, dict):
+        raise ValueError("RIS Lab config geometry must be a mapping")
+
+    missing = _missing_required_fields(geometry)
+    if missing:
+        raise ValueError(
+            "RIS Lab config missing required fields: " + ", ".join(missing)
+        )
+
+    return _canonicalize_config(resolved)
+
+
+def load_ris_lab_config(path: str | Path) -> Dict[str, Any]:
+    config_path = Path(path)
+    if not config_path.exists():
+        raise FileNotFoundError(f"RIS Lab config not found: {config_path}")
+    with config_path.open("r", encoding="utf-8") as handle:
+        data = yaml.safe_load(handle)
+    return resolve_ris_lab_config(data)
+
+
+def compute_ris_lab_config_hash(config: Dict[str, Any]) -> str:
+    payload = json.dumps(config, sort_keys=True).encode("utf-8")
+    return hashlib.sha256(payload).hexdigest()
+
+
+def _ensure_output_dir(output_dir: Path) -> Path:
+    output_dir.mkdir(parents=True, exist_ok=True)
+    (output_dir / "plots").mkdir(parents=True, exist_ok=True)
+    (output_dir / "data").mkdir(parents=True, exist_ok=True)
+    return output_dir
+
+
+def snapshot_ris_lab_config(output_dir: Path, config: Dict[str, Any]) -> Dict[str, Any]:
+    output_dir = _ensure_output_dir(output_dir)
+    yaml_path = output_dir / "config.yaml"
+    json_path = output_dir / "config.json"
+    save_yaml(yaml_path, config)
+    save_json(json_path, config)
+
+    config_hash = compute_ris_lab_config_hash(config)
+    summary = {
+        "schema_version": config.get("schema_version", RIS_LAB_SCHEMA_VERSION),
+        "config": {
+            "hash_sha256": config_hash,
+            "path_yaml": str(yaml_path),
+            "path_json": str(json_path),
+        },
+    }
+    save_json(output_dir / "summary.json", summary)
+    return summary
+
+
+def resolve_and_snapshot_ris_lab_config(
+    config_path: str | Path,
+    output_dir: Optional[str | Path] = None,
+) -> tuple[Dict[str, Any], Path, Dict[str, Any]]:
+    config = load_ris_lab_config(config_path)
+    if output_dir is None:
+        output_cfg = config.get("output", {})
+        base_dir = output_cfg.get("base_dir", "outputs")
+        run_id = output_cfg.get("run_id")
+        output_path = create_output_dir(base_dir, run_id=run_id)
+    else:
+        output_path = _ensure_output_dir(Path(output_dir))
+
+    summary = snapshot_ris_lab_config(output_path, config)
+    return config, output_path, summary
diff --git a/tests/test_ris_config.py b/tests/test_ris_config.py
new file mode 100644
index 0000000000000000000000000000000000000000..425e3679bae77cdb6c92bd26bc4d66308a7c610c
--- /dev/null
+++ b/tests/test_ris_config.py
@@ -0,0 +1,58 @@
+import json
+import tempfile
+import unittest
+from pathlib import Path
+
+import yaml
+
+from app.ris.ris_config import (
+    compute_ris_lab_config_hash,
+    resolve_and_snapshot_ris_lab_config,
+    resolve_ris_lab_config,
+)
+
+
+class TestRisLabConfig(unittest.TestCase):
+    def test_minimal_config_resolves_defaults(self) -> None:
+        resolved = resolve_ris_lab_config(
+            {"geometry": {"nx": 4, "ny": 2, "dx": 0.5, "dy": 0.25}}
+        )
+        self.assertEqual(resolved["control"]["mode"], "uniform")
+        self.assertEqual(resolved["quantization"]["bits"], 0)
+        self.assertEqual(resolved["validation"]["rmse_db_max"], 2.0)
+        self.assertEqual(resolved["output"]["base_dir"], "outputs")
+
+    def test_missing_geometry_fields_reports_required(self) -> None:
+        with self.assertRaises(ValueError) as ctx:
+            resolve_ris_lab_config({"geometry": {"nx": 4}})
+        message = str(ctx.exception)
+        self.assertIn("geometry.ny", message)
+        self.assertIn("geometry.dx", message)
+        self.assertIn("geometry.dy", message)
+
+    def test_snapshot_writes_config_files_and_summary(self) -> None:
+        with tempfile.TemporaryDirectory() as tmpdir:
+            tmp_path = Path(tmpdir)
+            config_path = tmp_path / "ris.yaml"
+            yaml.safe_dump(
+                {
+                    "geometry": {"nx": 2, "ny": 2, "dx": 0.1, "dy": 0.2},
+                    "output": {"base_dir": tmpdir, "run_id": "unit-test"},
+                },
+                config_path.open("w", encoding="utf-8"),
+                sort_keys=False,
+            )
+
+            config, output_dir, summary = resolve_and_snapshot_ris_lab_config(config_path)
+            self.assertEqual(output_dir, tmp_path / "unit-test")
+            self.assertTrue((output_dir / "config.yaml").exists())
+            self.assertTrue((output_dir / "config.json").exists())
+            self.assertTrue((output_dir / "summary.json").exists())
+            self.assertEqual(summary["config"]["hash_sha256"], compute_ris_lab_config_hash(config))
+
+            loaded = json.loads((output_dir / "config.json").read_text(encoding="utf-8"))
+            self.assertEqual(loaded["geometry"]["nx"], 2)
+
+
+if __name__ == "__main__":
+    unittest.main()


thinking
**Rerunning tests after code modification**

I'll rerun the tests to verify all changes still pass since the file was modified after the initial test run failed.
exec
/usr/bin/zsh -lc '.venv/bin/python -m pytest' in /home/josh/Documents/Github/RIS_SIONNA succeeded in 437ms:
============================= test session starts ==============================
platform linux -- Python 3.12.3, pytest-9.0.2, pluggy-1.6.0
rootdir: /home/josh/Documents/Github/RIS_SIONNA
configfile: pyproject.toml
collected 11 items

tests/test_alignment.py ..                                               [ 18%]
tests/test_ris_config.py ...                                             [ 45%]
tests/test_ris_core.py ......                                            [100%]

============================== 11 passed in 0.27s ==============================
file update:
diff --git a/app/ris/__init__.py b/app/ris/__init__.py
index a34ed971e3d2426533f5eb2eb56416e59d15db65..bafa9ac9ccd2097b564c1c45d7c7b06f3a223b47
--- a/app/ris/__init__.py
+++ b/app/ris/__init__.py
@@ -1,5 +1,13 @@
 """RIS core math primitives and helpers."""
 
+from .ris_config import (  # noqa: F401
+    RIS_LAB_SCHEMA_VERSION,
+    compute_ris_lab_config_hash,
+    load_ris_lab_config,
+    resolve_and_snapshot_ris_lab_config,
+    resolve_ris_lab_config,
+    snapshot_ris_lab_config,
+)
 from .ris_core import (  # noqa: F401
     RisFrame,
     RisGeometry,
diff --git a/app/ris/ris_config.py b/app/ris/ris_config.py
new file mode 100644
index 0000000000000000000000000000000000000000..d1bdcffc0da5d306d0f4f328064e4cbc1b453b6d
--- /dev/null
+++ b/app/ris/ris_config.py
@@ -0,0 +1,200 @@
+"""RIS Lab configuration schema and snapshot helpers."""
+
+from __future__ import annotations
+
+import copy
+import hashlib
+import json
+from pathlib import Path
+from typing import Any, Dict, Optional
+
+import yaml
+
+from app.io import create_output_dir, save_json, save_yaml
+
+RIS_LAB_SCHEMA_VERSION = 1
+
+DEFAULT_RIS_LAB_CONFIG: Dict[str, Any] = {
+    "schema_version": RIS_LAB_SCHEMA_VERSION,
+    "geometry": {
+        "nx": None,
+        "ny": None,
+        "dx": None,
+        "dy": None,
+        "origin": [0.0, 0.0, 0.0],
+        "normal": [0.0, 0.0, 1.0],
+        "x_axis_hint": [1.0, 0.0, 0.0],
+    },
+    "control": {
+        "mode": "uniform",
+        "params": {"phase_rad": 0.0},
+    },
+    "quantization": {
+        "bits": 0,
+    },
+    "pattern_mode": {
+        "normalization": "peak_0db",
+        "rx_sweep_deg": {"start": -90.0, "stop": 90.0, "step": 2.0},
+    },
+    "link_mode": {
+        "weighting": "inverse_distance",
+        "enabled": False,
+    },
+    "validation": {
+        "normalization": "peak_0db",
+        "rmse_db_max": 2.0,
+        "peak_angle_err_deg_max": 2.0,
+        "peak_db_err_max": 1.5,
+    },
+    "experiment": {
+        "frequency_hz": 28_000_000_000,
+        "tx_incident_angle_deg": -30.0,
+    },
+    "output": {
+        "base_dir": "outputs",
+        "run_id": None,
+    },
+}
+
+_ALIAS_FIELDS = {
+    ("geometry", "nx"): [("geometry", "n")],
+    ("geometry", "ny"): [("geometry", "m")],
+    ("geometry", "dx"): [("geometry", "dx_m")],
+    ("geometry", "dy"): [("geometry", "dy_m")],
+}
+
+
+def _deep_merge(base: Dict[str, Any], override: Dict[str, Any]) -> Dict[str, Any]:
+    for key, value in override.items():
+        if isinstance(value, dict) and isinstance(base.get(key), dict):
+            base[key] = _deep_merge(base[key], value)
+        else:
+            base[key] = value
+    return base
+
+
+def _apply_aliases(config: Dict[str, Any]) -> Dict[str, Any]:
+    updated = copy.deepcopy(config)
+    for (section, key), aliases in _ALIAS_FIELDS.items():
+        section_data = updated.get(section)
+        if not isinstance(section_data, dict):
+            continue
+        if key in section_data:
+            continue
+        for alias_section, alias_key in aliases:
+            alias_data = updated.get(alias_section)
+            if isinstance(alias_data, dict) and alias_key in alias_data:
+                section_data[key] = alias_data[alias_key]
+                break
+        updated[section] = section_data
+    return updated
+
+
+def _missing_required_fields(geometry: Dict[str, Any]) -> list[str]:
+    required = ("nx", "ny", "dx", "dy")
+    missing = []
+    for key in required:
+        value = geometry.get(key)
+        if value is None:
+            missing.append(f"geometry.{key}")
+    return missing
+
+
+def _canonicalize_config(config: Dict[str, Any]) -> Dict[str, Any]:
+    ordered_keys = [
+        "schema_version",
+        "geometry",
+        "control",
+        "quantization",
+        "pattern_mode",
+        "link_mode",
+        "validation",
+        "experiment",
+        "output",
+    ]
+    ordered: Dict[str, Any] = {}
+    for key in ordered_keys:
+        if key in config:
+            ordered[key] = config[key]
+    extras = {k: v for k, v in config.items() if k not in ordered_keys}
+    for key in sorted(extras):
+        ordered[key] = extras[key]
+    return ordered
+
+
+def resolve_ris_lab_config(raw_config: Dict[str, Any]) -> Dict[str, Any]:
+    if not isinstance(raw_config, dict):
+        raise ValueError("RIS Lab config must be a YAML mapping")
+
+    normalized = _apply_aliases(raw_config)
+    resolved = _deep_merge(copy.deepcopy(DEFAULT_RIS_LAB_CONFIG), normalized)
+
+    geometry = resolved.get("geometry")
+    if not isinstance(geometry, dict):
+        raise ValueError("RIS Lab config geometry must be a mapping")
+
+    missing = _missing_required_fields(geometry)
+    if missing:
+        raise ValueError(
+            "RIS Lab config missing required fields: " + ", ".join(missing)
+        )
+
+    return _canonicalize_config(resolved)
+
+
+def load_ris_lab_config(path: str | Path) -> Dict[str, Any]:
+    config_path = Path(path)
+    if not config_path.exists():
+        raise FileNotFoundError(f"RIS Lab config not found: {config_path}")
+    with config_path.open("r", encoding="utf-8") as handle:
+        data = yaml.safe_load(handle)
+    return resolve_ris_lab_config(data)
+
+
+def compute_ris_lab_config_hash(config: Dict[str, Any]) -> str:
+    payload = json.dumps(config, sort_keys=True).encode("utf-8")
+    return hashlib.sha256(payload).hexdigest()
+
+
+def _ensure_output_dir(output_dir: Path) -> Path:
+    output_dir.mkdir(parents=True, exist_ok=True)
+    (output_dir / "plots").mkdir(parents=True, exist_ok=True)
+    (output_dir / "data").mkdir(parents=True, exist_ok=True)
+    return output_dir
+
+
+def snapshot_ris_lab_config(output_dir: Path, config: Dict[str, Any]) -> Dict[str, Any]:
+    output_dir = _ensure_output_dir(output_dir)
+    yaml_path = output_dir / "config.yaml"
+    json_path = output_dir / "config.json"
+    save_yaml(yaml_path, config)
+    save_json(json_path, config)
+
+    config_hash = compute_ris_lab_config_hash(config)
+    summary = {
+        "schema_version": config.get("schema_version", RIS_LAB_SCHEMA_VERSION),
+        "config": {
+            "hash_sha256": config_hash,
+            "path_yaml": str(yaml_path),
+            "path_json": str(json_path),
+        },
+    }
+    save_json(output_dir / "summary.json", summary)
+    return summary
+
+
+def resolve_and_snapshot_ris_lab_config(
+    config_path: str | Path,
+    output_dir: Optional[str | Path] = None,
+) -> tuple[Dict[str, Any], Path, Dict[str, Any]]:
+    config = load_ris_lab_config(config_path)
+    if output_dir is None:
+        output_cfg = config.get("output", {})
+        base_dir = output_cfg.get("base_dir", "outputs")
+        run_id = output_cfg.get("run_id")
+        output_path = create_output_dir(base_dir, run_id=run_id)
+    else:
+        output_path = _ensure_output_dir(Path(output_dir))
+
+    summary = snapshot_ris_lab_config(output_path, config)
+    return config, output_path, summary
diff --git a/tests/test_ris_config.py b/tests/test_ris_config.py
new file mode 100644
index 0000000000000000000000000000000000000000..425e3679bae77cdb6c92bd26bc4d66308a7c610c
--- /dev/null
+++ b/tests/test_ris_config.py
@@ -0,0 +1,58 @@
+import json
+import tempfile
+import unittest
+from pathlib import Path
+
+import yaml
+
+from app.ris.ris_config import (
+    compute_ris_lab_config_hash,
+    resolve_and_snapshot_ris_lab_config,
+    resolve_ris_lab_config,
+)
+
+
+class TestRisLabConfig(unittest.TestCase):
+    def test_minimal_config_resolves_defaults(self) -> None:
+        resolved = resolve_ris_lab_config(
+            {"geometry": {"nx": 4, "ny": 2, "dx": 0.5, "dy": 0.25}}
+        )
+        self.assertEqual(resolved["control"]["mode"], "uniform")
+        self.assertEqual(resolved["quantization"]["bits"], 0)
+        self.assertEqual(resolved["validation"]["rmse_db_max"], 2.0)
+        self.assertEqual(resolved["output"]["base_dir"], "outputs")
+
+    def test_missing_geometry_fields_reports_required(self) -> None:
+        with self.assertRaises(ValueError) as ctx:
+            resolve_ris_lab_config({"geometry": {"nx": 4}})
+        message = str(ctx.exception)
+        self.assertIn("geometry.ny", message)
+        self.assertIn("geometry.dx", message)
+        self.assertIn("geometry.dy", message)
+
+    def test_snapshot_writes_config_files_and_summary(self) -> None:
+        with tempfile.TemporaryDirectory() as tmpdir:
+            tmp_path = Path(tmpdir)
+            config_path = tmp_path / "ris.yaml"
+            yaml.safe_dump(
+                {
+                    "geometry": {"nx": 2, "ny": 2, "dx": 0.1, "dy": 0.2},
+                    "output": {"base_dir": tmpdir, "run_id": "unit-test"},
+                },
+                config_path.open("w", encoding="utf-8"),
+                sort_keys=False,
+            )
+
+            config, output_dir, summary = resolve_and_snapshot_ris_lab_config(config_path)
+            self.assertEqual(output_dir, tmp_path / "unit-test")
+            self.assertTrue((output_dir / "config.yaml").exists())
+            self.assertTrue((output_dir / "config.json").exists())
+            self.assertTrue((output_dir / "summary.json").exists())
+            self.assertEqual(summary["config"]["hash_sha256"], compute_ris_lab_config_hash(config))
+
+            loaded = json.loads((output_dir / "config.json").read_text(encoding="utf-8"))
+            self.assertEqual(loaded["geometry"]["nx"], 2)
+
+
+if __name__ == "__main__":
+    unittest.main()


thinking
**Noting activity log need**
exec
/usr/bin/zsh -lc 'ralph log "Re-ran tests after config update"' in /home/josh/Documents/Github/RIS_SIONNA succeeded in 88ms:
Using local templates: /home/josh/Documents/Github/RIS_SIONNA/.agents/ralph
file update:
diff --git a/app/ris/__init__.py b/app/ris/__init__.py
index a34ed971e3d2426533f5eb2eb56416e59d15db65..bafa9ac9ccd2097b564c1c45d7c7b06f3a223b47
--- a/app/ris/__init__.py
+++ b/app/ris/__init__.py
@@ -1,5 +1,13 @@
 """RIS core math primitives and helpers."""
 
+from .ris_config import (  # noqa: F401
+    RIS_LAB_SCHEMA_VERSION,
+    compute_ris_lab_config_hash,
+    load_ris_lab_config,
+    resolve_and_snapshot_ris_lab_config,
+    resolve_ris_lab_config,
+    snapshot_ris_lab_config,
+)
 from .ris_core import (  # noqa: F401
     RisFrame,
     RisGeometry,
diff --git a/app/ris/ris_config.py b/app/ris/ris_config.py
new file mode 100644
index 0000000000000000000000000000000000000000..d1bdcffc0da5d306d0f4f328064e4cbc1b453b6d
--- /dev/null
+++ b/app/ris/ris_config.py
@@ -0,0 +1,200 @@
+"""RIS Lab configuration schema and snapshot helpers."""
+
+from __future__ import annotations
+
+import copy
+import hashlib
+import json
+from pathlib import Path
+from typing import Any, Dict, Optional
+
+import yaml
+
+from app.io import create_output_dir, save_json, save_yaml
+
+RIS_LAB_SCHEMA_VERSION = 1
+
+DEFAULT_RIS_LAB_CONFIG: Dict[str, Any] = {
+    "schema_version": RIS_LAB_SCHEMA_VERSION,
+    "geometry": {
+        "nx": None,
+        "ny": None,
+        "dx": None,
+        "dy": None,
+        "origin": [0.0, 0.0, 0.0],
+        "normal": [0.0, 0.0, 1.0],
+        "x_axis_hint": [1.0, 0.0, 0.0],
+    },
+    "control": {
+        "mode": "uniform",
+        "params": {"phase_rad": 0.0},
+    },
+    "quantization": {
+        "bits": 0,
+    },
+    "pattern_mode": {
+        "normalization": "peak_0db",
+        "rx_sweep_deg": {"start": -90.0, "stop": 90.0, "step": 2.0},
+    },
+    "link_mode": {
+        "weighting": "inverse_distance",
+        "enabled": False,
+    },
+    "validation": {
+        "normalization": "peak_0db",
+        "rmse_db_max": 2.0,
+        "peak_angle_err_deg_max": 2.0,
+        "peak_db_err_max": 1.5,
+    },
+    "experiment": {
+        "frequency_hz": 28_000_000_000,
+        "tx_incident_angle_deg": -30.0,
+    },
+    "output": {
+        "base_dir": "outputs",
+        "run_id": None,
+    },
+}
+
+_ALIAS_FIELDS = {
+    ("geometry", "nx"): [("geometry", "n")],
+    ("geometry", "ny"): [("geometry", "m")],
+    ("geometry", "dx"): [("geometry", "dx_m")],
+    ("geometry", "dy"): [("geometry", "dy_m")],
+}
+
+
+def _deep_merge(base: Dict[str, Any], override: Dict[str, Any]) -> Dict[str, Any]:
+    for key, value in override.items():
+        if isinstance(value, dict) and isinstance(base.get(key), dict):
+            base[key] = _deep_merge(base[key], value)
+        else:
+            base[key] = value
+    return base
+
+
+def _apply_aliases(config: Dict[str, Any]) -> Dict[str, Any]:
+    updated = copy.deepcopy(config)
+    for (section, key), aliases in _ALIAS_FIELDS.items():
+        section_data = updated.get(section)
+        if not isinstance(section_data, dict):
+            continue
+        if key in section_data:
+            continue
+        for alias_section, alias_key in aliases:
+            alias_data = updated.get(alias_section)
+            if isinstance(alias_data, dict) and alias_key in alias_data:
+                section_data[key] = alias_data[alias_key]
+                break
+        updated[section] = section_data
+    return updated
+
+
+def _missing_required_fields(geometry: Dict[str, Any]) -> list[str]:
+    required = ("nx", "ny", "dx", "dy")
+    missing = []
+    for key in required:
+        value = geometry.get(key)
+        if value is None:
+            missing.append(f"geometry.{key}")
+    return missing
+
+
+def _canonicalize_config(config: Dict[str, Any]) -> Dict[str, Any]:
+    ordered_keys = [
+        "schema_version",
+        "geometry",
+        "control",
+        "quantization",
+        "pattern_mode",
+        "link_mode",
+        "validation",
+        "experiment",
+        "output",
+    ]
+    ordered: Dict[str, Any] = {}
+    for key in ordered_keys:
+        if key in config:
+            ordered[key] = config[key]
+    extras = {k: v for k, v in config.items() if k not in ordered_keys}
+    for key in sorted(extras):
+        ordered[key] = extras[key]
+    return ordered
+
+
+def resolve_ris_lab_config(raw_config: Dict[str, Any]) -> Dict[str, Any]:
+    if not isinstance(raw_config, dict):
+        raise ValueError("RIS Lab config must be a YAML mapping")
+
+    normalized = _apply_aliases(raw_config)
+    resolved = _deep_merge(copy.deepcopy(DEFAULT_RIS_LAB_CONFIG), normalized)
+
+    geometry = resolved.get("geometry")
+    if not isinstance(geometry, dict):
+        raise ValueError("RIS Lab config geometry must be a mapping")
+
+    missing = _missing_required_fields(geometry)
+    if missing:
+        raise ValueError(
+            "RIS Lab config missing required fields: " + ", ".join(missing)
+        )
+
+    return _canonicalize_config(resolved)
+
+
+def load_ris_lab_config(path: str | Path) -> Dict[str, Any]:
+    config_path = Path(path)
+    if not config_path.exists():
+        raise FileNotFoundError(f"RIS Lab config not found: {config_path}")
+    with config_path.open("r", encoding="utf-8") as handle:
+        data = yaml.safe_load(handle)
+    return resolve_ris_lab_config(data)
+
+
+def compute_ris_lab_config_hash(config: Dict[str, Any]) -> str:
+    payload = json.dumps(config, sort_keys=True).encode("utf-8")
+    return hashlib.sha256(payload).hexdigest()
+
+
+def _ensure_output_dir(output_dir: Path) -> Path:
+    output_dir.mkdir(parents=True, exist_ok=True)
+    (output_dir / "plots").mkdir(parents=True, exist_ok=True)
+    (output_dir / "data").mkdir(parents=True, exist_ok=True)
+    return output_dir
+
+
+def snapshot_ris_lab_config(output_dir: Path, config: Dict[str, Any]) -> Dict[str, Any]:
+    output_dir = _ensure_output_dir(output_dir)
+    yaml_path = output_dir / "config.yaml"
+    json_path = output_dir / "config.json"
+    save_yaml(yaml_path, config)
+    save_json(json_path, config)
+
+    config_hash = compute_ris_lab_config_hash(config)
+    summary = {
+        "schema_version": config.get("schema_version", RIS_LAB_SCHEMA_VERSION),
+        "config": {
+            "hash_sha256": config_hash,
+            "path_yaml": str(yaml_path),
+            "path_json": str(json_path),
+        },
+    }
+    save_json(output_dir / "summary.json", summary)
+    return summary
+
+
+def resolve_and_snapshot_ris_lab_config(
+    config_path: str | Path,
+    output_dir: Optional[str | Path] = None,
+) -> tuple[Dict[str, Any], Path, Dict[str, Any]]:
+    config = load_ris_lab_config(config_path)
+    if output_dir is None:
+        output_cfg = config.get("output", {})
+        base_dir = output_cfg.get("base_dir", "outputs")
+        run_id = output_cfg.get("run_id")
+        output_path = create_output_dir(base_dir, run_id=run_id)
+    else:
+        output_path = _ensure_output_dir(Path(output_dir))
+
+    summary = snapshot_ris_lab_config(output_path, config)
+    return config, output_path, summary
diff --git a/tests/test_ris_config.py b/tests/test_ris_config.py
new file mode 100644
index 0000000000000000000000000000000000000000..425e3679bae77cdb6c92bd26bc4d66308a7c610c
--- /dev/null
+++ b/tests/test_ris_config.py
@@ -0,0 +1,58 @@
+import json
+import tempfile
+import unittest
+from pathlib import Path
+
+import yaml
+
+from app.ris.ris_config import (
+    compute_ris_lab_config_hash,
+    resolve_and_snapshot_ris_lab_config,
+    resolve_ris_lab_config,
+)
+
+
+class TestRisLabConfig(unittest.TestCase):
+    def test_minimal_config_resolves_defaults(self) -> None:
+        resolved = resolve_ris_lab_config(
+            {"geometry": {"nx": 4, "ny": 2, "dx": 0.5, "dy": 0.25}}
+        )
+        self.assertEqual(resolved["control"]["mode"], "uniform")
+        self.assertEqual(resolved["quantization"]["bits"], 0)
+        self.assertEqual(resolved["validation"]["rmse_db_max"], 2.0)
+        self.assertEqual(resolved["output"]["base_dir"], "outputs")
+
+    def test_missing_geometry_fields_reports_required(self) -> None:
+        with self.assertRaises(ValueError) as ctx:
+            resolve_ris_lab_config({"geometry": {"nx": 4}})
+        message = str(ctx.exception)
+        self.assertIn("geometry.ny", message)
+        self.assertIn("geometry.dx", message)
+        self.assertIn("geometry.dy", message)
+
+    def test_snapshot_writes_config_files_and_summary(self) -> None:
+        with tempfile.TemporaryDirectory() as tmpdir:
+            tmp_path = Path(tmpdir)
+            config_path = tmp_path / "ris.yaml"
+            yaml.safe_dump(
+                {
+                    "geometry": {"nx": 2, "ny": 2, "dx": 0.1, "dy": 0.2},
+                    "output": {"base_dir": tmpdir, "run_id": "unit-test"},
+                },
+                config_path.open("w", encoding="utf-8"),
+                sort_keys=False,
+            )
+
+            config, output_dir, summary = resolve_and_snapshot_ris_lab_config(config_path)
+            self.assertEqual(output_dir, tmp_path / "unit-test")
+            self.assertTrue((output_dir / "config.yaml").exists())
+            self.assertTrue((output_dir / "config.json").exists())
+            self.assertTrue((output_dir / "summary.json").exists())
+            self.assertEqual(summary["config"]["hash_sha256"], compute_ris_lab_config_hash(config))
+
+            loaded = json.loads((output_dir / "config.json").read_text(encoding="utf-8"))
+            self.assertEqual(loaded["geometry"]["nx"], 2)
+
+
+if __name__ == "__main__":
+    unittest.main()


thinking
**Preparing for commit with review**
exec
/usr/bin/zsh -lc 'git status -sb' in /home/josh/Documents/Github/RIS_SIONNA succeeded in 4ms:
## linux
 M .agents/tasks/prd-ris-lab.json
 M .ralph/activity.log
 M .ralph/errors.log
 M .ralph/runs/run-20260120-175122-20544-iter-1.log
 M app/ris/__init__.py
?? .ralph/.tmp/prompt-20260120-175122-20544-2.md
?? .ralph/.tmp/story-20260120-175122-20544-2.json
?? .ralph/.tmp/story-20260120-175122-20544-2.md
?? .ralph/runs/run-20260120-175122-20544-iter-1.md
?? .ralph/runs/run-20260120-175122-20544-iter-2.log
?? app/ris/ris_config.py
?? tests/test_ris_config.py
file update:
diff --git a/app/ris/__init__.py b/app/ris/__init__.py
index a34ed971e3d2426533f5eb2eb56416e59d15db65..bafa9ac9ccd2097b564c1c45d7c7b06f3a223b47
--- a/app/ris/__init__.py
+++ b/app/ris/__init__.py
@@ -1,5 +1,13 @@
 """RIS core math primitives and helpers."""
 
+from .ris_config import (  # noqa: F401
+    RIS_LAB_SCHEMA_VERSION,
+    compute_ris_lab_config_hash,
+    load_ris_lab_config,
+    resolve_and_snapshot_ris_lab_config,
+    resolve_ris_lab_config,
+    snapshot_ris_lab_config,
+)
 from .ris_core import (  # noqa: F401
     RisFrame,
     RisGeometry,
diff --git a/app/ris/ris_config.py b/app/ris/ris_config.py
new file mode 100644
index 0000000000000000000000000000000000000000..d1bdcffc0da5d306d0f4f328064e4cbc1b453b6d
--- /dev/null
+++ b/app/ris/ris_config.py
@@ -0,0 +1,200 @@
+"""RIS Lab configuration schema and snapshot helpers."""
+
+from __future__ import annotations
+
+import copy
+import hashlib
+import json
+from pathlib import Path
+from typing import Any, Dict, Optional
+
+import yaml
+
+from app.io import create_output_dir, save_json, save_yaml
+
+RIS_LAB_SCHEMA_VERSION = 1
+
+DEFAULT_RIS_LAB_CONFIG: Dict[str, Any] = {
+    "schema_version": RIS_LAB_SCHEMA_VERSION,
+    "geometry": {
+        "nx": None,
+        "ny": None,
+        "dx": None,
+        "dy": None,
+        "origin": [0.0, 0.0, 0.0],
+        "normal": [0.0, 0.0, 1.0],
+        "x_axis_hint": [1.0, 0.0, 0.0],
+    },
+    "control": {
+        "mode": "uniform",
+        "params": {"phase_rad": 0.0},
+    },
+    "quantization": {
+        "bits": 0,
+    },
+    "pattern_mode": {
+        "normalization": "peak_0db",
+        "rx_sweep_deg": {"start": -90.0, "stop": 90.0, "step": 2.0},
+    },
+    "link_mode": {
+        "weighting": "inverse_distance",
+        "enabled": False,
+    },
+    "validation": {
+        "normalization": "peak_0db",
+        "rmse_db_max": 2.0,
+        "peak_angle_err_deg_max": 2.0,
+        "peak_db_err_max": 1.5,
+    },
+    "experiment": {
+        "frequency_hz": 28_000_000_000,
+        "tx_incident_angle_deg": -30.0,
+    },
+    "output": {
+        "base_dir": "outputs",
+        "run_id": None,
+    },
+}
+
+_ALIAS_FIELDS = {
+    ("geometry", "nx"): [("geometry", "n")],
+    ("geometry", "ny"): [("geometry", "m")],
+    ("geometry", "dx"): [("geometry", "dx_m")],
+    ("geometry", "dy"): [("geometry", "dy_m")],
+}
+
+
+def _deep_merge(base: Dict[str, Any], override: Dict[str, Any]) -> Dict[str, Any]:
+    for key, value in override.items():
+        if isinstance(value, dict) and isinstance(base.get(key), dict):
+            base[key] = _deep_merge(base[key], value)
+        else:
+            base[key] = value
+    return base
+
+
+def _apply_aliases(config: Dict[str, Any]) -> Dict[str, Any]:
+    updated = copy.deepcopy(config)
+    for (section, key), aliases in _ALIAS_FIELDS.items():
+        section_data = updated.get(section)
+        if not isinstance(section_data, dict):
+            continue
+        if key in section_data:
+            continue
+        for alias_section, alias_key in aliases:
+            alias_data = updated.get(alias_section)
+            if isinstance(alias_data, dict) and alias_key in alias_data:
+                section_data[key] = alias_data[alias_key]
+                break
+        updated[section] = section_data
+    return updated
+
+
+def _missing_required_fields(geometry: Dict[str, Any]) -> list[str]:
+    required = ("nx", "ny", "dx", "dy")
+    missing = []
+    for key in required:
+        value = geometry.get(key)
+        if value is None:
+            missing.append(f"geometry.{key}")
+    return missing
+
+
+def _canonicalize_config(config: Dict[str, Any]) -> Dict[str, Any]:
+    ordered_keys = [
+        "schema_version",
+        "geometry",
+        "control",
+        "quantization",
+        "pattern_mode",
+        "link_mode",
+        "validation",
+        "experiment",
+        "output",
+    ]
+    ordered: Dict[str, Any] = {}
+    for key in ordered_keys:
+        if key in config:
+            ordered[key] = config[key]
+    extras = {k: v for k, v in config.items() if k not in ordered_keys}
+    for key in sorted(extras):
+        ordered[key] = extras[key]
+    return ordered
+
+
+def resolve_ris_lab_config(raw_config: Dict[str, Any]) -> Dict[str, Any]:
+    if not isinstance(raw_config, dict):
+        raise ValueError("RIS Lab config must be a YAML mapping")
+
+    normalized = _apply_aliases(raw_config)
+    resolved = _deep_merge(copy.deepcopy(DEFAULT_RIS_LAB_CONFIG), normalized)
+
+    geometry = resolved.get("geometry")
+    if not isinstance(geometry, dict):
+        raise ValueError("RIS Lab config geometry must be a mapping")
+
+    missing = _missing_required_fields(geometry)
+    if missing:
+        raise ValueError(
+            "RIS Lab config missing required fields: " + ", ".join(missing)
+        )
+
+    return _canonicalize_config(resolved)
+
+
+def load_ris_lab_config(path: str | Path) -> Dict[str, Any]:
+    config_path = Path(path)
+    if not config_path.exists():
+        raise FileNotFoundError(f"RIS Lab config not found: {config_path}")
+    with config_path.open("r", encoding="utf-8") as handle:
+        data = yaml.safe_load(handle)
+    return resolve_ris_lab_config(data)
+
+
+def compute_ris_lab_config_hash(config: Dict[str, Any]) -> str:
+    payload = json.dumps(config, sort_keys=True).encode("utf-8")
+    return hashlib.sha256(payload).hexdigest()
+
+
+def _ensure_output_dir(output_dir: Path) -> Path:
+    output_dir.mkdir(parents=True, exist_ok=True)
+    (output_dir / "plots").mkdir(parents=True, exist_ok=True)
+    (output_dir / "data").mkdir(parents=True, exist_ok=True)
+    return output_dir
+
+
+def snapshot_ris_lab_config(output_dir: Path, config: Dict[str, Any]) -> Dict[str, Any]:
+    output_dir = _ensure_output_dir(output_dir)
+    yaml_path = output_dir / "config.yaml"
+    json_path = output_dir / "config.json"
+    save_yaml(yaml_path, config)
+    save_json(json_path, config)
+
+    config_hash = compute_ris_lab_config_hash(config)
+    summary = {
+        "schema_version": config.get("schema_version", RIS_LAB_SCHEMA_VERSION),
+        "config": {
+            "hash_sha256": config_hash,
+            "path_yaml": str(yaml_path),
+            "path_json": str(json_path),
+        },
+    }
+    save_json(output_dir / "summary.json", summary)
+    return summary
+
+
+def resolve_and_snapshot_ris_lab_config(
+    config_path: str | Path,
+    output_dir: Optional[str | Path] = None,
+) -> tuple[Dict[str, Any], Path, Dict[str, Any]]:
+    config = load_ris_lab_config(config_path)
+    if output_dir is None:
+        output_cfg = config.get("output", {})
+        base_dir = output_cfg.get("base_dir", "outputs")
+        run_id = output_cfg.get("run_id")
+        output_path = create_output_dir(base_dir, run_id=run_id)
+    else:
+        output_path = _ensure_output_dir(Path(output_dir))
+
+    summary = snapshot_ris_lab_config(output_path, config)
+    return config, output_path, summary
diff --git a/tests/test_ris_config.py b/tests/test_ris_config.py
new file mode 100644
index 0000000000000000000000000000000000000000..425e3679bae77cdb6c92bd26bc4d66308a7c610c
--- /dev/null
+++ b/tests/test_ris_config.py
@@ -0,0 +1,58 @@
+import json
+import tempfile
+import unittest
+from pathlib import Path
+
+import yaml
+
+from app.ris.ris_config import (
+    compute_ris_lab_config_hash,
+    resolve_and_snapshot_ris_lab_config,
+    resolve_ris_lab_config,
+)
+
+
+class TestRisLabConfig(unittest.TestCase):
+    def test_minimal_config_resolves_defaults(self) -> None:
+        resolved = resolve_ris_lab_config(
+            {"geometry": {"nx": 4, "ny": 2, "dx": 0.5, "dy": 0.25}}
+        )
+        self.assertEqual(resolved["control"]["mode"], "uniform")
+        self.assertEqual(resolved["quantization"]["bits"], 0)
+        self.assertEqual(resolved["validation"]["rmse_db_max"], 2.0)
+        self.assertEqual(resolved["output"]["base_dir"], "outputs")
+
+    def test_missing_geometry_fields_reports_required(self) -> None:
+        with self.assertRaises(ValueError) as ctx:
+            resolve_ris_lab_config({"geometry": {"nx": 4}})
+        message = str(ctx.exception)
+        self.assertIn("geometry.ny", message)
+        self.assertIn("geometry.dx", message)
+        self.assertIn("geometry.dy", message)
+
+    def test_snapshot_writes_config_files_and_summary(self) -> None:
+        with tempfile.TemporaryDirectory() as tmpdir:
+            tmp_path = Path(tmpdir)
+            config_path = tmp_path / "ris.yaml"
+            yaml.safe_dump(
+                {
+                    "geometry": {"nx": 2, "ny": 2, "dx": 0.1, "dy": 0.2},
+                    "output": {"base_dir": tmpdir, "run_id": "unit-test"},
+                },
+                config_path.open("w", encoding="utf-8"),
+                sort_keys=False,
+            )
+
+            config, output_dir, summary = resolve_and_snapshot_ris_lab_config(config_path)
+            self.assertEqual(output_dir, tmp_path / "unit-test")
+            self.assertTrue((output_dir / "config.yaml").exists())
+            self.assertTrue((output_dir / "config.json").exists())
+            self.assertTrue((output_dir / "summary.json").exists())
+            self.assertEqual(summary["config"]["hash_sha256"], compute_ris_lab_config_hash(config))
+
+            loaded = json.loads((output_dir / "config.json").read_text(encoding="utf-8"))
+            self.assertEqual(loaded["geometry"]["nx"], 2)
+
+
+if __name__ == "__main__":
+    unittest.main()


thinking
**Reviewing new config before commit**

I'm staging all changes but will inspect the diff and new config file carefully before committing to check for any security, performance, or regression issues.
exec
/usr/bin/zsh -lc "sed -n '1,260p' /home/josh/Documents/Github/RIS_SIONNA/app/ris/ris_config.py" in /home/josh/Documents/Github/RIS_SIONNA succeeded in 3ms:
"""RIS Lab configuration schema and snapshot helpers."""

from __future__ import annotations

import copy
import hashlib
import json
from pathlib import Path
from typing import Any, Dict, Optional

import yaml

from app.io import create_output_dir, save_json, save_yaml

RIS_LAB_SCHEMA_VERSION = 1

DEFAULT_RIS_LAB_CONFIG: Dict[str, Any] = {
    "schema_version": RIS_LAB_SCHEMA_VERSION,
    "geometry": {
        "nx": None,
file update:
diff --git a/app/ris/__init__.py b/app/ris/__init__.py
index a34ed971e3d2426533f5eb2eb56416e59d15db65..bafa9ac9ccd2097b564c1c45d7c7b06f3a223b47
--- a/app/ris/__init__.py
+++ b/app/ris/__init__.py
@@ -1,5 +1,13 @@
 """RIS core math primitives and helpers."""
 
+from .ris_config import (  # noqa: F401
+    RIS_LAB_SCHEMA_VERSION,
+    compute_ris_lab_config_hash,
+    load_ris_lab_config,
+    resolve_and_snapshot_ris_lab_config,
+    resolve_ris_lab_config,
+    snapshot_ris_lab_config,
+)
 from .ris_core import (  # noqa: F401
     RisFrame,
     RisGeometry,
diff --git a/app/ris/ris_config.py b/app/ris/ris_config.py
new file mode 100644
index 0000000000000000000000000000000000000000..d1bdcffc0da5d306d0f4f328064e4cbc1b453b6d
--- /dev/null
+++ b/app/ris/ris_config.py
@@ -0,0 +1,200 @@
+"""RIS Lab configuration schema and snapshot helpers."""
+
+from __future__ import annotations
+
+import copy
+import hashlib
+import json
+from pathlib import Path
+from typing import Any, Dict, Optional
+
+import yaml
+
+from app.io import create_output_dir, save_json, save_yaml
+
+RIS_LAB_SCHEMA_VERSION = 1
+
+DEFAULT_RIS_LAB_CONFIG: Dict[str, Any] = {
+    "schema_version": RIS_LAB_SCHEMA_VERSION,
+    "geometry": {
+        "nx": None,
+        "ny": None,
+        "dx": None,
+        "dy": None,
+        "origin": [0.0, 0.0, 0.0],
+        "normal": [0.0, 0.0, 1.0],
+        "x_axis_hint": [1.0, 0.0, 0.0],
+    },
+    "control": {
+        "mode": "uniform",
+        "params": {"phase_rad": 0.0},
+    },
+    "quantization": {
+        "bits": 0,
+    },
+    "pattern_mode": {
+        "normalization": "peak_0db",
+        "rx_sweep_deg": {"start": -90.0, "stop": 90.0, "step": 2.0},
+    },
+    "link_mode": {
+        "weighting": "inverse_distance",
+        "enabled": False,
+    },
+    "validation": {
+        "normalization": "peak_0db",
+        "rmse_db_max": 2.0,
+        "peak_angle_err_deg_max": 2.0,
+        "peak_db_err_max": 1.5,
+    },
+    "experiment": {
+        "frequency_hz": 28_000_000_000,
+        "tx_incident_angle_deg": -30.0,
+    },
+    "output": {
+        "base_dir": "outputs",
+        "run_id": None,
+    },
+}
+
+_ALIAS_FIELDS = {
+    ("geometry", "nx"): [("geometry", "n")],
+    ("geometry", "ny"): [("geometry", "m")],
+    ("geometry", "dx"): [("geometry", "dx_m")],
+    ("geometry", "dy"): [("geometry", "dy_m")],
+}
+
+
+def _deep_merge(base: Dict[str, Any], override: Dict[str, Any]) -> Dict[str, Any]:
+    for key, value in override.items():
+        if isinstance(value, dict) and isinstance(base.get(key), dict):
+            base[key] = _deep_merge(base[key], value)
+        else:
+            base[key] = value
+    return base
+
+
+def _apply_aliases(config: Dict[str, Any]) -> Dict[str, Any]:
+    updated = copy.deepcopy(config)
+    for (section, key), aliases in _ALIAS_FIELDS.items():
+        section_data = updated.get(section)
+        if not isinstance(section_data, dict):
+            continue
+        if key in section_data:
+            continue
+        for alias_section, alias_key in aliases:
+            alias_data = updated.get(alias_section)
+            if isinstance(alias_data, dict) and alias_key in alias_data:
+                section_data[key] = alias_data[alias_key]
+                break
+        updated[section] = section_data
+    return updated
+
+
+def _missing_required_fields(geometry: Dict[str, Any]) -> list[str]:
+    required = ("nx", "ny", "dx", "dy")
+    missing = []
+    for key in required:
+        value = geometry.get(key)
+        if value is None:
+            missing.append(f"geometry.{key}")
+    return missing
+
+
+def _canonicalize_config(config: Dict[str, Any]) -> Dict[str, Any]:
+    ordered_keys = [
+        "schema_version",
+        "geometry",
+        "control",
+        "quantization",
+        "pattern_mode",
+        "link_mode",
+        "validation",
+        "experiment",
+        "output",
+    ]
+    ordered: Dict[str, Any] = {}
+    for key in ordered_keys:
+        if key in config:
+            ordered[key] = config[key]
+    extras = {k: v for k, v in config.items() if k not in ordered_keys}
+    for key in sorted(extras):
+        ordered[key] = extras[key]
+    return ordered
+
+
+def resolve_ris_lab_config(raw_config: Dict[str, Any]) -> Dict[str, Any]:
+    if not isinstance(raw_config, dict):
+        raise ValueError("RIS Lab config must be a YAML mapping")
+
+    normalized = _apply_aliases(raw_config)
+    resolved = _deep_merge(copy.deepcopy(DEFAULT_RIS_LAB_CONFIG), normalized)
+
+    geometry = resolved.get("geometry")
+    if not isinstance(geometry, dict):
+        raise ValueError("RIS Lab config geometry must be a mapping")
+
+    missing = _missing_required_fields(geometry)
+    if missing:
+        raise ValueError(
+            "RIS Lab config missing required fields: " + ", ".join(missing)
+        )
+
+    return _canonicalize_config(resolved)
+
+
+def load_ris_lab_config(path: str | Path) -> Dict[str, Any]:
+    config_path = Path(path)
+    if not config_path.exists():
+        raise FileNotFoundError(f"RIS Lab config not found: {config_path}")
+    with config_path.open("r", encoding="utf-8") as handle:
+        data = yaml.safe_load(handle)
+    return resolve_ris_lab_config(data)
+
+
+def compute_ris_lab_config_hash(config: Dict[str, Any]) -> str:
+    payload = json.dumps(config, sort_keys=True).encode("utf-8")
+    return hashlib.sha256(payload).hexdigest()
+
+
+def _ensure_output_dir(output_dir: Path) -> Path:
+    output_dir.mkdir(parents=True, exist_ok=True)
+    (output_dir / "plots").mkdir(parents=True, exist_ok=True)
+    (output_dir / "data").mkdir(parents=True, exist_ok=True)
+    return output_dir
+
+
+def snapshot_ris_lab_config(output_dir: Path, config: Dict[str, Any]) -> Dict[str, Any]:
+    output_dir = _ensure_output_dir(output_dir)
+    yaml_path = output_dir / "config.yaml"
+    json_path = output_dir / "config.json"
+    save_yaml(yaml_path, config)
+    save_json(json_path, config)
+
+    config_hash = compute_ris_lab_config_hash(config)
+    summary = {
+        "schema_version": config.get("schema_version", RIS_LAB_SCHEMA_VERSION),
+        "config": {
+            "hash_sha256": config_hash,
+            "path_yaml": str(yaml_path),
+            "path_json": str(json_path),
+        },
+    }
+    save_json(output_dir / "summary.json", summary)
+    return summary
+
+
+def resolve_and_snapshot_ris_lab_config(
+    config_path: str | Path,
+    output_dir: Optional[str | Path] = None,
+) -> tuple[Dict[str, Any], Path, Dict[str, Any]]:
+    config = load_ris_lab_config(config_path)
+    if output_dir is None:
+        output_cfg = config.get("output", {})
+        base_dir = output_cfg.get("base_dir", "outputs")
+        run_id = output_cfg.get("run_id")
+        output_path = create_output_dir(base_dir, run_id=run_id)
+    else:
+        output_path = _ensure_output_dir(Path(output_dir))
+
+    summary = snapshot_ris_lab_config(output_path, config)
+    return config, output_path, summary
diff --git a/tests/test_ris_config.py b/tests/test_ris_config.py
new file mode 100644
index 0000000000000000000000000000000000000000..425e3679bae77cdb6c92bd26bc4d66308a7c610c
--- /dev/null
+++ b/tests/test_ris_config.py
@@ -0,0 +1,58 @@
+import json
+import tempfile
+import unittest
+from pathlib import Path
+
+import yaml
+
+from app.ris.ris_config import (
+    compute_ris_lab_config_hash,
+    resolve_and_snapshot_ris_lab_config,
+    resolve_ris_lab_config,
+)
+
+
+class TestRisLabConfig(unittest.TestCase):
+    def test_minimal_config_resolves_defaults(self) -> None:
+        resolved = resolve_ris_lab_config(
+            {"geometry": {"nx": 4, "ny": 2, "dx": 0.5, "dy": 0.25}}
+        )
+        self.assertEqual(resolved["control"]["mode"], "uniform")
+        self.assertEqual(resolved["quantization"]["bits"], 0)
+        self.assertEqual(resolved["validation"]["rmse_db_max"], 2.0)
+        self.assertEqual(resolved["output"]["base_dir"], "outputs")
+
+    def test_missing_geometry_fields_reports_required(self) -> None:
+        with self.assertRaises(ValueError) as ctx:
+            resolve_ris_lab_config({"geometry": {"nx": 4}})
+        message = str(ctx.exception)
+        self.assertIn("geometry.ny", message)
+        self.assertIn("geometry.dx", message)
+        self.assertIn("geometry.dy", message)
+
+    def test_snapshot_writes_config_files_and_summary(self) -> None:
+        with tempfile.TemporaryDirectory() as tmpdir:
+            tmp_path = Path(tmpdir)
+            config_path = tmp_path / "ris.yaml"
+            yaml.safe_dump(
+                {
+                    "geometry": {"nx": 2, "ny": 2, "dx": 0.1, "dy": 0.2},
+                    "output": {"base_dir": tmpdir, "run_id": "unit-test"},
+                },
+                config_path.open("w", encoding="utf-8"),
+                sort_keys=False,
+            )
+
+            config, output_dir, summary = resolve_and_snapshot_ris_lab_config(config_path)
+            self.assertEqual(output_dir, tmp_path / "unit-test")
+            self.assertTrue((output_dir / "config.yaml").exists())
+            self.assertTrue((output_dir / "config.json").exists())
+            self.assertTrue((output_dir / "summary.json").exists())
+            self.assertEqual(summary["config"]["hash_sha256"], compute_ris_lab_config_hash(config))
+
+            loaded = json.loads((output_dir / "config.json").read_text(encoding="utf-8"))
+            self.assertEqual(loaded["geometry"]["nx"], 2)
+
+
+if __name__ == "__main__":
+    unittest.main()


thinking
**Reviewing security and staging changes**

The code uses YAML safe_load for security, output paths align with config to prevent injection risks, and no regressions affect main code. Next step is staging all changes with git add -A.
exec
/usr/bin/zsh -lc 'git add -A' in /home/josh/Documents/Github/RIS_SIONNA succeeded in 8ms:

file update:
diff --git a/app/ris/__init__.py b/app/ris/__init__.py
index a34ed971e3d2426533f5eb2eb56416e59d15db65..bafa9ac9ccd2097b564c1c45d7c7b06f3a223b47
--- a/app/ris/__init__.py
+++ b/app/ris/__init__.py
@@ -1,5 +1,13 @@
 """RIS core math primitives and helpers."""
 
+from .ris_config import (  # noqa: F401
+    RIS_LAB_SCHEMA_VERSION,
+    compute_ris_lab_config_hash,
+    load_ris_lab_config,
+    resolve_and_snapshot_ris_lab_config,
+    resolve_ris_lab_config,
+    snapshot_ris_lab_config,
+)
 from .ris_core import (  # noqa: F401
     RisFrame,
     RisGeometry,
diff --git a/app/ris/ris_config.py b/app/ris/ris_config.py
new file mode 100644
index 0000000000000000000000000000000000000000..d1bdcffc0da5d306d0f4f328064e4cbc1b453b6d
--- /dev/null
+++ b/app/ris/ris_config.py
@@ -0,0 +1,200 @@
+"""RIS Lab configuration schema and snapshot helpers."""
+
+from __future__ import annotations
+
+import copy
+import hashlib
+import json
+from pathlib import Path
+from typing import Any, Dict, Optional
+
+import yaml
+
+from app.io import create_output_dir, save_json, save_yaml
+
+RIS_LAB_SCHEMA_VERSION = 1
+
+DEFAULT_RIS_LAB_CONFIG: Dict[str, Any] = {
+    "schema_version": RIS_LAB_SCHEMA_VERSION,
+    "geometry": {
+        "nx": None,
+        "ny": None,
+        "dx": None,
+        "dy": None,
+        "origin": [0.0, 0.0, 0.0],
+        "normal": [0.0, 0.0, 1.0],
+        "x_axis_hint": [1.0, 0.0, 0.0],
+    },
+    "control": {
+        "mode": "uniform",
+        "params": {"phase_rad": 0.0},
+    },
+    "quantization": {
+        "bits": 0,
+    },
+    "pattern_mode": {
+        "normalization": "peak_0db",
+        "rx_sweep_deg": {"start": -90.0, "stop": 90.0, "step": 2.0},
+    },
+    "link_mode": {
+        "weighting": "inverse_distance",
+        "enabled": False,
+    },
+    "validation": {
+        "normalization": "peak_0db",
+        "rmse_db_max": 2.0,
+        "peak_angle_err_deg_max": 2.0,
+        "peak_db_err_max": 1.5,
+    },
+    "experiment": {
+        "frequency_hz": 28_000_000_000,
+        "tx_incident_angle_deg": -30.0,
+    },
+    "output": {
+        "base_dir": "outputs",
+        "run_id": None,
+    },
+}
+
+_ALIAS_FIELDS = {
+    ("geometry", "nx"): [("geometry", "n")],
+    ("geometry", "ny"): [("geometry", "m")],
+    ("geometry", "dx"): [("geometry", "dx_m")],
+    ("geometry", "dy"): [("geometry", "dy_m")],
+}
+
+
+def _deep_merge(base: Dict[str, Any], override: Dict[str, Any]) -> Dict[str, Any]:
+    for key, value in override.items():
+        if isinstance(value, dict) and isinstance(base.get(key), dict):
+            base[key] = _deep_merge(base[key], value)
+        else:
+            base[key] = value
+    return base
+
+
+def _apply_aliases(config: Dict[str, Any]) -> Dict[str, Any]:
+    updated = copy.deepcopy(config)
+    for (section, key), aliases in _ALIAS_FIELDS.items():
+        section_data = updated.get(section)
+        if not isinstance(section_data, dict):
+            continue
+        if key in section_data:
+            continue
+        for alias_section, alias_key in aliases:
+            alias_data = updated.get(alias_section)
+            if isinstance(alias_data, dict) and alias_key in alias_data:
+                section_data[key] = alias_data[alias_key]
+                break
+        updated[section] = section_data
+    return updated
+
+
+def _missing_required_fields(geometry: Dict[str, Any]) -> list[str]:
+    required = ("nx", "ny", "dx", "dy")
+    missing = []
+    for key in required:
+        value = geometry.get(key)
+        if value is None:
+            missing.append(f"geometry.{key}")
+    return missing
+
+
+def _canonicalize_config(config: Dict[str, Any]) -> Dict[str, Any]:
+    ordered_keys = [
+        "schema_version",
+        "geometry",
+        "control",
+        "quantization",
+        "pattern_mode",
+        "link_mode",
+        "validation",
+        "experiment",
+        "output",
+    ]
+    ordered: Dict[str, Any] = {}
+    for key in ordered_keys:
+        if key in config:
+            ordered[key] = config[key]
+    extras = {k: v for k, v in config.items() if k not in ordered_keys}
+    for key in sorted(extras):
+        ordered[key] = extras[key]
+    return ordered
+
+
+def resolve_ris_lab_config(raw_config: Dict[str, Any]) -> Dict[str, Any]:
+    if not isinstance(raw_config, dict):
+        raise ValueError("RIS Lab config must be a YAML mapping")
+
+    normalized = _apply_aliases(raw_config)
+    resolved = _deep_merge(copy.deepcopy(DEFAULT_RIS_LAB_CONFIG), normalized)
+
+    geometry = resolved.get("geometry")
+    if not isinstance(geometry, dict):
+        raise ValueError("RIS Lab config geometry must be a mapping")
+
+    missing = _missing_required_fields(geometry)
+    if missing:
+        raise ValueError(
+            "RIS Lab config missing required fields: " + ", ".join(missing)
+        )
+
+    return _canonicalize_config(resolved)
+
+
+def load_ris_lab_config(path: str | Path) -> Dict[str, Any]:
+    config_path = Path(path)
+    if not config_path.exists():
+        raise FileNotFoundError(f"RIS Lab config not found: {config_path}")
+    with config_path.open("r", encoding="utf-8") as handle:
+        data = yaml.safe_load(handle)
+    return resolve_ris_lab_config(data)
+
+
+def compute_ris_lab_config_hash(config: Dict[str, Any]) -> str:
+    payload = json.dumps(config, sort_keys=True).encode("utf-8")
+    return hashlib.sha256(payload).hexdigest()
+
+
+def _ensure_output_dir(output_dir: Path) -> Path:
+    output_dir.mkdir(parents=True, exist_ok=True)
+    (output_dir / "plots").mkdir(parents=True, exist_ok=True)
+    (output_dir / "data").mkdir(parents=True, exist_ok=True)
+    return output_dir
+
+
+def snapshot_ris_lab_config(output_dir: Path, config: Dict[str, Any]) -> Dict[str, Any]:
+    output_dir = _ensure_output_dir(output_dir)
+    yaml_path = output_dir / "config.yaml"
+    json_path = output_dir / "config.json"
+    save_yaml(yaml_path, config)
+    save_json(json_path, config)
+
+    config_hash = compute_ris_lab_config_hash(config)
+    summary = {
+        "schema_version": config.get("schema_version", RIS_LAB_SCHEMA_VERSION),
+        "config": {
+            "hash_sha256": config_hash,
+            "path_yaml": str(yaml_path),
+            "path_json": str(json_path),
+        },
+    }
+    save_json(output_dir / "summary.json", summary)
+    return summary
+
+
+def resolve_and_snapshot_ris_lab_config(
+    config_path: str | Path,
+    output_dir: Optional[str | Path] = None,
+) -> tuple[Dict[str, Any], Path, Dict[str, Any]]:
+    config = load_ris_lab_config(config_path)
+    if output_dir is None:
+        output_cfg = config.get("output", {})
+        base_dir = output_cfg.get("base_dir", "outputs")
+        run_id = output_cfg.get("run_id")
+        output_path = create_output_dir(base_dir, run_id=run_id)
+    else:
+        output_path = _ensure_output_dir(Path(output_dir))
+
+    summary = snapshot_ris_lab_config(output_path, config)
+    return config, output_path, summary
diff --git a/tests/test_ris_config.py b/tests/test_ris_config.py
new file mode 100644
index 0000000000000000000000000000000000000000..425e3679bae77cdb6c92bd26bc4d66308a7c610c
--- /dev/null
+++ b/tests/test_ris_config.py
@@ -0,0 +1,58 @@
+import json
+import tempfile
+import unittest
+from pathlib import Path
+
+import yaml
+
+from app.ris.ris_config import (
+    compute_ris_lab_config_hash,
+    resolve_and_snapshot_ris_lab_config,
+    resolve_ris_lab_config,
+)
+
+
+class TestRisLabConfig(unittest.TestCase):
+    def test_minimal_config_resolves_defaults(self) -> None:
+        resolved = resolve_ris_lab_config(
+            {"geometry": {"nx": 4, "ny": 2, "dx": 0.5, "dy": 0.25}}
+        )
+        self.assertEqual(resolved["control"]["mode"], "uniform")
+        self.assertEqual(resolved["quantization"]["bits"], 0)
+        self.assertEqual(resolved["validation"]["rmse_db_max"], 2.0)
+        self.assertEqual(resolved["output"]["base_dir"], "outputs")
+
+    def test_missing_geometry_fields_reports_required(self) -> None:
+        with self.assertRaises(ValueError) as ctx:
+            resolve_ris_lab_config({"geometry": {"nx": 4}})
+        message = str(ctx.exception)
+        self.assertIn("geometry.ny", message)
+        self.assertIn("geometry.dx", message)
+        self.assertIn("geometry.dy", message)
+
+    def test_snapshot_writes_config_files_and_summary(self) -> None:
+        with tempfile.TemporaryDirectory() as tmpdir:
+            tmp_path = Path(tmpdir)
+            config_path = tmp_path / "ris.yaml"
+            yaml.safe_dump(
+                {
+                    "geometry": {"nx": 2, "ny": 2, "dx": 0.1, "dy": 0.2},
+                    "output": {"base_dir": tmpdir, "run_id": "unit-test"},
+                },
+                config_path.open("w", encoding="utf-8"),
+                sort_keys=False,
+            )
+
+            config, output_dir, summary = resolve_and_snapshot_ris_lab_config(config_path)
+            self.assertEqual(output_dir, tmp_path / "unit-test")
+            self.assertTrue((output_dir / "config.yaml").exists())
+            self.assertTrue((output_dir / "config.json").exists())
+            self.assertTrue((output_dir / "summary.json").exists())
+            self.assertEqual(summary["config"]["hash_sha256"], compute_ris_lab_config_hash(config))
+
+            loaded = json.loads((output_dir / "config.json").read_text(encoding="utf-8"))
+            self.assertEqual(loaded["geometry"]["nx"], 2)
+
+
+if __name__ == "__main__":
+    unittest.main()


thinking
**Committing new config schema with detailed message**

I'm preparing a commit with type and scope plus a detailed body explaining the addition of config schema, snapshots, tests, and referencing US-002 for clarity.
exec
/usr/bin/zsh -lc "git commit -m \"feat(ris-lab): add config schema snapshots\" -m \"Add RIS Lab config defaults, validation, and snapshot helper.\\nWrite config.yaml/config.json + summary hash for runs.\\nInclude tests for defaults, missing fields, and snapshot output.\\n\\nReference: US-002\"" in /home/josh/Documents/Github/RIS_SIONNA succeeded in 10ms:
[linux 22d2964] feat(ris-lab): add config schema snapshots
 12 files changed, 9209 insertions(+), 6 deletions(-)
 create mode 100644 .ralph/.tmp/prompt-20260120-175122-20544-2.md
 create mode 100644 .ralph/.tmp/story-20260120-175122-20544-2.json
 create mode 100644 .ralph/.tmp/story-20260120-175122-20544-2.md
 create mode 100644 .ralph/runs/run-20260120-175122-20544-iter-1.md
 create mode 100644 .ralph/runs/run-20260120-175122-20544-iter-2.log
 create mode 100644 app/ris/ris_config.py
 create mode 100644 tests/test_ris_config.py
file update:
diff --git a/app/ris/__init__.py b/app/ris/__init__.py
index a34ed971e3d2426533f5eb2eb56416e59d15db65..bafa9ac9ccd2097b564c1c45d7c7b06f3a223b47
--- a/app/ris/__init__.py
+++ b/app/ris/__init__.py
@@ -1,5 +1,13 @@
 """RIS core math primitives and helpers."""
 
+from .ris_config import (  # noqa: F401
+    RIS_LAB_SCHEMA_VERSION,
+    compute_ris_lab_config_hash,
+    load_ris_lab_config,
+    resolve_and_snapshot_ris_lab_config,
+    resolve_ris_lab_config,
+    snapshot_ris_lab_config,
+)
 from .ris_core import (  # noqa: F401
     RisFrame,
     RisGeometry,
diff --git a/app/ris/ris_config.py b/app/ris/ris_config.py
new file mode 100644
index 0000000000000000000000000000000000000000..d1bdcffc0da5d306d0f4f328064e4cbc1b453b6d
--- /dev/null
+++ b/app/ris/ris_config.py
@@ -0,0 +1,200 @@
+"""RIS Lab configuration schema and snapshot helpers."""
+
+from __future__ import annotations
+
+import copy
+import hashlib
+import json
+from pathlib import Path
+from typing import Any, Dict, Optional
+
+import yaml
+
+from app.io import create_output_dir, save_json, save_yaml
+
+RIS_LAB_SCHEMA_VERSION = 1
+
+DEFAULT_RIS_LAB_CONFIG: Dict[str, Any] = {
+    "schema_version": RIS_LAB_SCHEMA_VERSION,
+    "geometry": {
+        "nx": None,
+        "ny": None,
+        "dx": None,
+        "dy": None,
+        "origin": [0.0, 0.0, 0.0],
+        "normal": [0.0, 0.0, 1.0],
+        "x_axis_hint": [1.0, 0.0, 0.0],
+    },
+    "control": {
+        "mode": "uniform",
+        "params": {"phase_rad": 0.0},
+    },
+    "quantization": {
+        "bits": 0,
+    },
+    "pattern_mode": {
+        "normalization": "peak_0db",
+        "rx_sweep_deg": {"start": -90.0, "stop": 90.0, "step": 2.0},
+    },
+    "link_mode": {
+        "weighting": "inverse_distance",
+        "enabled": False,
+    },
+    "validation": {
+        "normalization": "peak_0db",
+        "rmse_db_max": 2.0,
+        "peak_angle_err_deg_max": 2.0,
+        "peak_db_err_max": 1.5,
+    },
+    "experiment": {
+        "frequency_hz": 28_000_000_000,
+        "tx_incident_angle_deg": -30.0,
+    },
+    "output": {
+        "base_dir": "outputs",
+        "run_id": None,
+    },
+}
+
+_ALIAS_FIELDS = {
+    ("geometry", "nx"): [("geometry", "n")],
+    ("geometry", "ny"): [("geometry", "m")],
+    ("geometry", "dx"): [("geometry", "dx_m")],
+    ("geometry", "dy"): [("geometry", "dy_m")],
+}
+
+
+def _deep_merge(base: Dict[str, Any], override: Dict[str, Any]) -> Dict[str, Any]:
+    for key, value in override.items():
+        if isinstance(value, dict) and isinstance(base.get(key), dict):
+            base[key] = _deep_merge(base[key], value)
+        else:
+            base[key] = value
+    return base
+
+
+def _apply_aliases(config: Dict[str, Any]) -> Dict[str, Any]:
+    updated = copy.deepcopy(config)
+    for (section, key), aliases in _ALIAS_FIELDS.items():
+        section_data = updated.get(section)
+        if not isinstance(section_data, dict):
+            continue
+        if key in section_data:
+            continue
+        for alias_section, alias_key in aliases:
+            alias_data = updated.get(alias_section)
+            if isinstance(alias_data, dict) and alias_key in alias_data:
+                section_data[key] = alias_data[alias_key]
+                break
+        updated[section] = section_data
+    return updated
+
+
+def _missing_required_fields(geometry: Dict[str, Any]) -> list[str]:
+    required = ("nx", "ny", "dx", "dy")
+    missing = []
+    for key in required:
+        value = geometry.get(key)
+        if value is None:
+            missing.append(f"geometry.{key}")
+    return missing
+
+
+def _canonicalize_config(config: Dict[str, Any]) -> Dict[str, Any]:
+    ordered_keys = [
+        "schema_version",
+        "geometry",
+        "control",
+        "quantization",
+        "pattern_mode",
+        "link_mode",
+        "validation",
+        "experiment",
+        "output",
+    ]
+    ordered: Dict[str, Any] = {}
+    for key in ordered_keys:
+        if key in config:
+            ordered[key] = config[key]
+    extras = {k: v for k, v in config.items() if k not in ordered_keys}
+    for key in sorted(extras):
+        ordered[key] = extras[key]
+    return ordered
+
+
+def resolve_ris_lab_config(raw_config: Dict[str, Any]) -> Dict[str, Any]:
+    if not isinstance(raw_config, dict):
+        raise ValueError("RIS Lab config must be a YAML mapping")
+
+    normalized = _apply_aliases(raw_config)
+    resolved = _deep_merge(copy.deepcopy(DEFAULT_RIS_LAB_CONFIG), normalized)
+
+    geometry = resolved.get("geometry")
+    if not isinstance(geometry, dict):
+        raise ValueError("RIS Lab config geometry must be a mapping")
+
+    missing = _missing_required_fields(geometry)
+    if missing:
+        raise ValueError(
+            "RIS Lab config missing required fields: " + ", ".join(missing)
+        )
+
+    return _canonicalize_config(resolved)
+
+
+def load_ris_lab_config(path: str | Path) -> Dict[str, Any]:
+    config_path = Path(path)
+    if not config_path.exists():
+        raise FileNotFoundError(f"RIS Lab config not found: {config_path}")
+    with config_path.open("r", encoding="utf-8") as handle:
+        data = yaml.safe_load(handle)
+    return resolve_ris_lab_config(data)
+
+
+def compute_ris_lab_config_hash(config: Dict[str, Any]) -> str:
+    payload = json.dumps(config, sort_keys=True).encode("utf-8")
+    return hashlib.sha256(payload).hexdigest()
+
+
+def _ensure_output_dir(output_dir: Path) -> Path:
+    output_dir.mkdir(parents=True, exist_ok=True)
+    (output_dir / "plots").mkdir(parents=True, exist_ok=True)
+    (output_dir / "data").mkdir(parents=True, exist_ok=True)
+    return output_dir
+
+
+def snapshot_ris_lab_config(output_dir: Path, config: Dict[str, Any]) -> Dict[str, Any]:
+    output_dir = _ensure_output_dir(output_dir)
+    yaml_path = output_dir / "config.yaml"
+    json_path = output_dir / "config.json"
+    save_yaml(yaml_path, config)
+    save_json(json_path, config)
+
+    config_hash = compute_ris_lab_config_hash(config)
+    summary = {
+        "schema_version": config.get("schema_version", RIS_LAB_SCHEMA_VERSION),
+        "config": {
+            "hash_sha256": config_hash,
+            "path_yaml": str(yaml_path),
+            "path_json": str(json_path),
+        },
+    }
+    save_json(output_dir / "summary.json", summary)
+    return summary
+
+
+def resolve_and_snapshot_ris_lab_config(
+    config_path: str | Path,
+    output_dir: Optional[str | Path] = None,
+) -> tuple[Dict[str, Any], Path, Dict[str, Any]]:
+    config = load_ris_lab_config(config_path)
+    if output_dir is None:
+        output_cfg = config.get("output", {})
+        base_dir = output_cfg.get("base_dir", "outputs")
+        run_id = output_cfg.get("run_id")
+        output_path = create_output_dir(base_dir, run_id=run_id)
+    else:
+        output_path = _ensure_output_dir(Path(output_dir))
+
+    summary = snapshot_ris_lab_config(output_path, config)
+    return config, output_path, summary
diff --git a/tests/test_ris_config.py b/tests/test_ris_config.py
new file mode 100644
index 0000000000000000000000000000000000000000..425e3679bae77cdb6c92bd26bc4d66308a7c610c
--- /dev/null
+++ b/tests/test_ris_config.py
@@ -0,0 +1,58 @@
+import json
+import tempfile
+import unittest
+from pathlib import Path
+
+import yaml
+
+from app.ris.ris_config import (
+    compute_ris_lab_config_hash,
+    resolve_and_snapshot_ris_lab_config,
+    resolve_ris_lab_config,
+)
+
+
+class TestRisLabConfig(unittest.TestCase):
+    def test_minimal_config_resolves_defaults(self) -> None:
+        resolved = resolve_ris_lab_config(
+            {"geometry": {"nx": 4, "ny": 2, "dx": 0.5, "dy": 0.25}}
+        )
+        self.assertEqual(resolved["control"]["mode"], "uniform")
+        self.assertEqual(resolved["quantization"]["bits"], 0)
+        self.assertEqual(resolved["validation"]["rmse_db_max"], 2.0)
+        self.assertEqual(resolved["output"]["base_dir"], "outputs")
+
+    def test_missing_geometry_fields_reports_required(self) -> None:
+        with self.assertRaises(ValueError) as ctx:
+            resolve_ris_lab_config({"geometry": {"nx": 4}})
+        message = str(ctx.exception)
+        self.assertIn("geometry.ny", message)
+        self.assertIn("geometry.dx", message)
+        self.assertIn("geometry.dy", message)
+
+    def test_snapshot_writes_config_files_and_summary(self) -> None:
+        with tempfile.TemporaryDirectory() as tmpdir:
+            tmp_path = Path(tmpdir)
+            config_path = tmp_path / "ris.yaml"
+            yaml.safe_dump(
+                {
+                    "geometry": {"nx": 2, "ny": 2, "dx": 0.1, "dy": 0.2},
+                    "output": {"base_dir": tmpdir, "run_id": "unit-test"},
+                },
+                config_path.open("w", encoding="utf-8"),
+                sort_keys=False,
+            )
+
+            config, output_dir, summary = resolve_and_snapshot_ris_lab_config(config_path)
+            self.assertEqual(output_dir, tmp_path / "unit-test")
+            self.assertTrue((output_dir / "config.yaml").exists())
+            self.assertTrue((output_dir / "config.json").exists())
+            self.assertTrue((output_dir / "summary.json").exists())
+            self.assertEqual(summary["config"]["hash_sha256"], compute_ris_lab_config_hash(config))
+
+            loaded = json.loads((output_dir / "config.json").read_text(encoding="utf-8"))
+            self.assertEqual(loaded["geometry"]["nx"], 2)
+
+
+if __name__ == "__main__":
+    unittest.main()


thinking
**Verifying clean git status**

The commit added many files with large insertions, likely logs, so I'm checking git status now to confirm the working directory is clean.
exec
/usr/bin/zsh -lc 'git status --porcelain' in /home/josh/Documents/Github/RIS_SIONNA succeeded in 4ms:
 M .ralph/runs/run-20260120-175122-20544-iter-2.log
file update:
diff --git a/app/ris/__init__.py b/app/ris/__init__.py
index a34ed971e3d2426533f5eb2eb56416e59d15db65..bafa9ac9ccd2097b564c1c45d7c7b06f3a223b47
--- a/app/ris/__init__.py
+++ b/app/ris/__init__.py
@@ -1,5 +1,13 @@
 """RIS core math primitives and helpers."""
 
+from .ris_config import (  # noqa: F401
+    RIS_LAB_SCHEMA_VERSION,
+    compute_ris_lab_config_hash,
+    load_ris_lab_config,
+    resolve_and_snapshot_ris_lab_config,
+    resolve_ris_lab_config,
+    snapshot_ris_lab_config,
+)
 from .ris_core import (  # noqa: F401
     RisFrame,
     RisGeometry,
diff --git a/app/ris/ris_config.py b/app/ris/ris_config.py
new file mode 100644
index 0000000000000000000000000000000000000000..d1bdcffc0da5d306d0f4f328064e4cbc1b453b6d
--- /dev/null
+++ b/app/ris/ris_config.py
@@ -0,0 +1,200 @@
+"""RIS Lab configuration schema and snapshot helpers."""
+
+from __future__ import annotations
+
+import copy
+import hashlib
+import json
+from pathlib import Path
+from typing import Any, Dict, Optional
+
+import yaml
+
+from app.io import create_output_dir, save_json, save_yaml
+
+RIS_LAB_SCHEMA_VERSION = 1
+
+DEFAULT_RIS_LAB_CONFIG: Dict[str, Any] = {
+    "schema_version": RIS_LAB_SCHEMA_VERSION,
+    "geometry": {
+        "nx": None,
+        "ny": None,
+        "dx": None,
+        "dy": None,
+        "origin": [0.0, 0.0, 0.0],
+        "normal": [0.0, 0.0, 1.0],
+        "x_axis_hint": [1.0, 0.0, 0.0],
+    },
+    "control": {
+        "mode": "uniform",
+        "params": {"phase_rad": 0.0},
+    },
+    "quantization": {
+        "bits": 0,
+    },
+    "pattern_mode": {
+        "normalization": "peak_0db",
+        "rx_sweep_deg": {"start": -90.0, "stop": 90.0, "step": 2.0},
+    },
+    "link_mode": {
+        "weighting": "inverse_distance",
+        "enabled": False,
+    },
+    "validation": {
+        "normalization": "peak_0db",
+        "rmse_db_max": 2.0,
+        "peak_angle_err_deg_max": 2.0,
+        "peak_db_err_max": 1.5,
+    },
+    "experiment": {
+        "frequency_hz": 28_000_000_000,
+        "tx_incident_angle_deg": -30.0,
+    },
+    "output": {
+        "base_dir": "outputs",
+        "run_id": None,
+    },
+}
+
+_ALIAS_FIELDS = {
+    ("geometry", "nx"): [("geometry", "n")],
+    ("geometry", "ny"): [("geometry", "m")],
+    ("geometry", "dx"): [("geometry", "dx_m")],
+    ("geometry", "dy"): [("geometry", "dy_m")],
+}
+
+
+def _deep_merge(base: Dict[str, Any], override: Dict[str, Any]) -> Dict[str, Any]:
+    for key, value in override.items():
+        if isinstance(value, dict) and isinstance(base.get(key), dict):
+            base[key] = _deep_merge(base[key], value)
+        else:
+            base[key] = value
+    return base
+
+
+def _apply_aliases(config: Dict[str, Any]) -> Dict[str, Any]:
+    updated = copy.deepcopy(config)
+    for (section, key), aliases in _ALIAS_FIELDS.items():
+        section_data = updated.get(section)
+        if not isinstance(section_data, dict):
+            continue
+        if key in section_data:
+            continue
+        for alias_section, alias_key in aliases:
+            alias_data = updated.get(alias_section)
+            if isinstance(alias_data, dict) and alias_key in alias_data:
+                section_data[key] = alias_data[alias_key]
+                break
+        updated[section] = section_data
+    return updated
+
+
+def _missing_required_fields(geometry: Dict[str, Any]) -> list[str]:
+    required = ("nx", "ny", "dx", "dy")
+    missing = []
+    for key in required:
+        value = geometry.get(key)
+        if value is None:
+            missing.append(f"geometry.{key}")
+    return missing
+
+
+def _canonicalize_config(config: Dict[str, Any]) -> Dict[str, Any]:
+    ordered_keys = [
+        "schema_version",
+        "geometry",
+        "control",
+        "quantization",
+        "pattern_mode",
+        "link_mode",
+        "validation",
+        "experiment",
+        "output",
+    ]
+    ordered: Dict[str, Any] = {}
+    for key in ordered_keys:
+        if key in config:
+            ordered[key] = config[key]
+    extras = {k: v for k, v in config.items() if k not in ordered_keys}
+    for key in sorted(extras):
+        ordered[key] = extras[key]
+    return ordered
+
+
+def resolve_ris_lab_config(raw_config: Dict[str, Any]) -> Dict[str, Any]:
+    if not isinstance(raw_config, dict):
+        raise ValueError("RIS Lab config must be a YAML mapping")
+
+    normalized = _apply_aliases(raw_config)
+    resolved = _deep_merge(copy.deepcopy(DEFAULT_RIS_LAB_CONFIG), normalized)
+
+    geometry = resolved.get("geometry")
+    if not isinstance(geometry, dict):
+        raise ValueError("RIS Lab config geometry must be a mapping")
+
+    missing = _missing_required_fields(geometry)
+    if missing:
+        raise ValueError(
+            "RIS Lab config missing required fields: " + ", ".join(missing)
+        )
+
+    return _canonicalize_config(resolved)
+
+
+def load_ris_lab_config(path: str | Path) -> Dict[str, Any]:
+    config_path = Path(path)
+    if not config_path.exists():
+        raise FileNotFoundError(f"RIS Lab config not found: {config_path}")
+    with config_path.open("r", encoding="utf-8") as handle:
+        data = yaml.safe_load(handle)
+    return resolve_ris_lab_config(data)
+
+
+def compute_ris_lab_config_hash(config: Dict[str, Any]) -> str:
+    payload = json.dumps(config, sort_keys=True).encode("utf-8")
+    return hashlib.sha256(payload).hexdigest()
+
+
+def _ensure_output_dir(output_dir: Path) -> Path:
+    output_dir.mkdir(parents=True, exist_ok=True)
+    (output_dir / "plots").mkdir(parents=True, exist_ok=True)
+    (output_dir / "data").mkdir(parents=True, exist_ok=True)
+    return output_dir
+
+
+def snapshot_ris_lab_config(output_dir: Path, config: Dict[str, Any]) -> Dict[str, Any]:
+    output_dir = _ensure_output_dir(output_dir)
+    yaml_path = output_dir / "config.yaml"
+    json_path = output_dir / "config.json"
+    save_yaml(yaml_path, config)
+    save_json(json_path, config)
+
+    config_hash = compute_ris_lab_config_hash(config)
+    summary = {
+        "schema_version": config.get("schema_version", RIS_LAB_SCHEMA_VERSION),
+        "config": {
+            "hash_sha256": config_hash,
+            "path_yaml": str(yaml_path),
+            "path_json": str(json_path),
+        },
+    }
+    save_json(output_dir / "summary.json", summary)
+    return summary
+
+
+def resolve_and_snapshot_ris_lab_config(
+    config_path: str | Path,
+    output_dir: Optional[str | Path] = None,
+) -> tuple[Dict[str, Any], Path, Dict[str, Any]]:
+    config = load_ris_lab_config(config_path)
+    if output_dir is None:
+        output_cfg = config.get("output", {})
+        base_dir = output_cfg.get("base_dir", "outputs")
+        run_id = output_cfg.get("run_id")
+        output_path = create_output_dir(base_dir, run_id=run_id)
+    else:
+        output_path = _ensure_output_dir(Path(output_dir))
+
+    summary = snapshot_ris_lab_config(output_path, config)
+    return config, output_path, summary
diff --git a/tests/test_ris_config.py b/tests/test_ris_config.py
new file mode 100644
index 0000000000000000000000000000000000000000..425e3679bae77cdb6c92bd26bc4d66308a7c610c
--- /dev/null
+++ b/tests/test_ris_config.py
@@ -0,0 +1,58 @@
+import json
+import tempfile
+import unittest
+from pathlib import Path
+
+import yaml
+
+from app.ris.ris_config import (
+    compute_ris_lab_config_hash,
+    resolve_and_snapshot_ris_lab_config,
+    resolve_ris_lab_config,
+)
+
+
+class TestRisLabConfig(unittest.TestCase):
+    def test_minimal_config_resolves_defaults(self) -> None:
+        resolved = resolve_ris_lab_config(
+            {"geometry": {"nx": 4, "ny": 2, "dx": 0.5, "dy": 0.25}}
+        )
+        self.assertEqual(resolved["control"]["mode"], "uniform")
+        self.assertEqual(resolved["quantization"]["bits"], 0)
+        self.assertEqual(resolved["validation"]["rmse_db_max"], 2.0)
+        self.assertEqual(resolved["output"]["base_dir"], "outputs")
+
+    def test_missing_geometry_fields_reports_required(self) -> None:
+        with self.assertRaises(ValueError) as ctx:
+            resolve_ris_lab_config({"geometry": {"nx": 4}})
+        message = str(ctx.exception)
+        self.assertIn("geometry.ny", message)
+        self.assertIn("geometry.dx", message)
+        self.assertIn("geometry.dy", message)
+
+    def test_snapshot_writes_config_files_and_summary(self) -> None:
+        with tempfile.TemporaryDirectory() as tmpdir:
+            tmp_path = Path(tmpdir)
+            config_path = tmp_path / "ris.yaml"
+            yaml.safe_dump(
+                {
+                    "geometry": {"nx": 2, "ny": 2, "dx": 0.1, "dy": 0.2},
+                    "output": {"base_dir": tmpdir, "run_id": "unit-test"},
+                },
+                config_path.open("w", encoding="utf-8"),
+                sort_keys=False,
+            )
+
+            config, output_dir, summary = resolve_and_snapshot_ris_lab_config(config_path)
+            self.assertEqual(output_dir, tmp_path / "unit-test")
+            self.assertTrue((output_dir / "config.yaml").exists())
+            self.assertTrue((output_dir / "config.json").exists())
+            self.assertTrue((output_dir / "summary.json").exists())
+            self.assertEqual(summary["config"]["hash_sha256"], compute_ris_lab_config_hash(config))
+
+            loaded = json.loads((output_dir / "config.json").read_text(encoding="utf-8"))
+            self.assertEqual(loaded["geometry"]["nx"], 2)
+
+
+if __name__ == "__main__":
+    unittest.main()


thinking
**Assessing unexpected run log change**

The run log updated after commit, likely by the system or tool itself, so staging and committing this new change is necessary to keep the working tree clean as required.
exec
/usr/bin/zsh -lc 'git diff /home/josh/Documents/Github/RIS_SIONNA/.ralph/runs/run-20260120-175122-20544-iter-2.log' in /home/josh/Documents/Github/RIS_SIONNA succeeded in 6ms:
diff --git a/.ralph/runs/run-20260120-175122-20544-iter-2.log b/.ralph/runs/run-20260120-175122-20544-iter-2.log
index ccd16ac..9167338 100644
--- a/.ralph/runs/run-20260120-175122-20544-iter-2.log
+++ b/.ralph/runs/run-20260120-175122-20544-iter-2.log
@@ -8163,4 +8163,906 @@ thinking
 
 The code uses YAML safe_load for security, output paths align with config to prevent injection risks, and no regressions affect main code. Next step is staging all changes with git add -A.
 exec
-/usr/bin/zsh -lc 'git add -A' in /home/josh/Documents/Github/RIS_SIONNA
\ No newline at end of file
+/usr/bin/zsh -lc 'git add -A' in /home/josh/Documents/Github/RIS_SIONNA succeeded in 8ms:
+
+file update:
+diff --git a/app/ris/__init__.py b/app/ris/__init__.py
+index a34ed971e3d2426533f5eb2eb56416e59d15db65..bafa9ac9ccd2097b564c1c45d7c7b06f3a223b47
+--- a/app/ris/__init__.py
++++ b/app/ris/__init__.py
+@@ -1,5 +1,13 @@
+ """RIS core math primitives and helpers."""
+ 
file update:
diff --git a/app/ris/__init__.py b/app/ris/__init__.py
index a34ed971e3d2426533f5eb2eb56416e59d15db65..bafa9ac9ccd2097b564c1c45d7c7b06f3a223b47
--- a/app/ris/__init__.py
+++ b/app/ris/__init__.py
@@ -1,5 +1,13 @@
 """RIS core math primitives and helpers."""
 
+from .ris_config import (  # noqa: F401
+    RIS_LAB_SCHEMA_VERSION,
+    compute_ris_lab_config_hash,
+    load_ris_lab_config,
+    resolve_and_snapshot_ris_lab_config,
+    resolve_ris_lab_config,
+    snapshot_ris_lab_config,
+)
 from .ris_core import (  # noqa: F401
     RisFrame,
     RisGeometry,
diff --git a/app/ris/ris_config.py b/app/ris/ris_config.py
new file mode 100644
index 0000000000000000000000000000000000000000..d1bdcffc0da5d306d0f4f328064e4cbc1b453b6d
--- /dev/null
+++ b/app/ris/ris_config.py
@@ -0,0 +1,200 @@
+"""RIS Lab configuration schema and snapshot helpers."""
+
+from __future__ import annotations
+
+import copy
+import hashlib
+import json
+from pathlib import Path
+from typing import Any, Dict, Optional
+
+import yaml
+
+from app.io import create_output_dir, save_json, save_yaml
+
+RIS_LAB_SCHEMA_VERSION = 1
+
+DEFAULT_RIS_LAB_CONFIG: Dict[str, Any] = {
+    "schema_version": RIS_LAB_SCHEMA_VERSION,
+    "geometry": {
+        "nx": None,
+        "ny": None,
+        "dx": None,
+        "dy": None,
+        "origin": [0.0, 0.0, 0.0],
+        "normal": [0.0, 0.0, 1.0],
+        "x_axis_hint": [1.0, 0.0, 0.0],
+    },
+    "control": {
+        "mode": "uniform",
+        "params": {"phase_rad": 0.0},
+    },
+    "quantization": {
+        "bits": 0,
+    },
+    "pattern_mode": {
+        "normalization": "peak_0db",
+        "rx_sweep_deg": {"start": -90.0, "stop": 90.0, "step": 2.0},
+    },
+    "link_mode": {
+        "weighting": "inverse_distance",
+        "enabled": False,
+    },
+    "validation": {
+        "normalization": "peak_0db",
+        "rmse_db_max": 2.0,
+        "peak_angle_err_deg_max": 2.0,
+        "peak_db_err_max": 1.5,
+    },
+    "experiment": {
+        "frequency_hz": 28_000_000_000,
+        "tx_incident_angle_deg": -30.0,
+    },
+    "output": {
+        "base_dir": "outputs",
+        "run_id": None,
+    },
+}
+
+_ALIAS_FIELDS = {
+    ("geometry", "nx"): [("geometry", "n")],
+    ("geometry", "ny"): [("geometry", "m")],
+    ("geometry", "dx"): [("geometry", "dx_m")],
+    ("geometry", "dy"): [("geometry", "dy_m")],
+}
+
+
+def _deep_merge(base: Dict[str, Any], override: Dict[str, Any]) -> Dict[str, Any]:
+    for key, value in override.items():
+        if isinstance(value, dict) and isinstance(base.get(key), dict):
+            base[key] = _deep_merge(base[key], value)
+        else:
+            base[key] = value
+    return base
+
+
+def _apply_aliases(config: Dict[str, Any]) -> Dict[str, Any]:
+    updated = copy.deepcopy(config)
+    for (section, key), aliases in _ALIAS_FIELDS.items():
+        section_data = updated.get(section)
+        if not isinstance(section_data, dict):
+            continue
+        if key in section_data:
+            continue
+        for alias_section, alias_key in aliases:
+            alias_data = updated.get(alias_section)
+            if isinstance(alias_data, dict) and alias_key in alias_data:
+                section_data[key] = alias_data[alias_key]
+                break
+        updated[section] = section_data
+    return updated
+
+
+def _missing_required_fields(geometry: Dict[str, Any]) -> list[str]:
+    required = ("nx", "ny", "dx", "dy")
+    missing = []
+    for key in required:
+        value = geometry.get(key)
+        if value is None:
+            missing.append(f"geometry.{key}")
+    return missing
+
+
+def _canonicalize_config(config: Dict[str, Any]) -> Dict[str, Any]:
+    ordered_keys = [
+        "schema_version",
+        "geometry",
+        "control",
+        "quantization",
+        "pattern_mode",
+        "link_mode",
+        "validation",
+        "experiment",
+        "output",
+    ]
+    ordered: Dict[str, Any] = {}
+    for key in ordered_keys:
+        if key in config:
+            ordered[key] = config[key]
+    extras = {k: v for k, v in config.items() if k not in ordered_keys}
+    for key in sorted(extras):
+        ordered[key] = extras[key]
+    return ordered
+
+
+def resolve_ris_lab_config(raw_config: Dict[str, Any]) -> Dict[str, Any]:
+    if not isinstance(raw_config, dict):
+        raise ValueError("RIS Lab config must be a YAML mapping")
+
+    normalized = _apply_aliases(raw_config)
+    resolved = _deep_merge(copy.deepcopy(DEFAULT_RIS_LAB_CONFIG), normalized)
+
+    geometry = resolved.get("geometry")
+    if not isinstance(geometry, dict):
+        raise ValueError("RIS Lab config geometry must be a mapping")
+
+    missing = _missing_required_fields(geometry)
+    if missing:
+        raise ValueError(
+            "RIS Lab config missing required fields: " + ", ".join(missing)
+        )
+
+    return _canonicalize_config(resolved)
+
+
+def load_ris_lab_config(path: str | Path) -> Dict[str, Any]:
+    config_path = Path(path)
+    if not config_path.exists():
+        raise FileNotFoundError(f"RIS Lab config not found: {config_path}")
+    with config_path.open("r", encoding="utf-8") as handle:
+        data = yaml.safe_load(handle)
+    return resolve_ris_lab_config(data)
+
+
+def compute_ris_lab_config_hash(config: Dict[str, Any]) -> str:
+    payload = json.dumps(config, sort_keys=True).encode("utf-8")
+    return hashlib.sha256(payload).hexdigest()
+
+
+def _ensure_output_dir(output_dir: Path) -> Path:
+    output_dir.mkdir(parents=True, exist_ok=True)
+    (output_dir / "plots").mkdir(parents=True, exist_ok=True)
+    (output_dir / "data").mkdir(parents=True, exist_ok=True)
+    return output_dir
+
+
+def snapshot_ris_lab_config(output_dir: Path, config: Dict[str, Any]) -> Dict[str, Any]:
+    output_dir = _ensure_output_dir(output_dir)
+    yaml_path = output_dir / "config.yaml"
+    json_path = output_dir / "config.json"
+    save_yaml(yaml_path, config)
+    save_json(json_path, config)
+
+    config_hash = compute_ris_lab_config_hash(config)
+    summary = {
+        "schema_version": config.get("schema_version", RIS_LAB_SCHEMA_VERSION),
+        "config": {
+            "hash_sha256": config_hash,
+            "path_yaml": str(yaml_path),
+            "path_json": str(json_path),
+        },
+    }
+    save_json(output_dir / "summary.json", summary)
+    return summary
+
+
+def resolve_and_snapshot_ris_lab_config(
+    config_path: str | Path,
+    output_dir: Optional[str | Path] = None,
+) -> tuple[Dict[str, Any], Path, Dict[str, Any]]:
+    config = load_ris_lab_config(config_path)
+    if output_dir is None:
+        output_cfg = config.get("output", {})
+        base_dir = output_cfg.get("base_dir", "outputs")
+        run_id = output_cfg.get("run_id")
+        output_path = create_output_dir(base_dir, run_id=run_id)
+    else:
+        output_path = _ensure_output_dir(Path(output_dir))
+
+    summary = snapshot_ris_lab_config(output_path, config)
+    return config, output_path, summary
diff --git a/tests/test_ris_config.py b/tests/test_ris_config.py
new file mode 100644
index 0000000000000000000000000000000000000000..425e3679bae77cdb6c92bd26bc4d66308a7c610c
--- /dev/null
+++ b/tests/test_ris_config.py
@@ -0,0 +1,58 @@
+import json
+import tempfile
+import unittest
+from pathlib import Path
+
+import yaml
+
+from app.ris.ris_config import (
+    compute_ris_lab_config_hash,
+    resolve_and_snapshot_ris_lab_config,
+    resolve_ris_lab_config,
+)
+
+
+class TestRisLabConfig(unittest.TestCase):
+    def test_minimal_config_resolves_defaults(self) -> None:
+        resolved = resolve_ris_lab_config(
+            {"geometry": {"nx": 4, "ny": 2, "dx": 0.5, "dy": 0.25}}
+        )
+        self.assertEqual(resolved["control"]["mode"], "uniform")
+        self.assertEqual(resolved["quantization"]["bits"], 0)
+        self.assertEqual(resolved["validation"]["rmse_db_max"], 2.0)
+        self.assertEqual(resolved["output"]["base_dir"], "outputs")
+
+    def test_missing_geometry_fields_reports_required(self) -> None:
+        with self.assertRaises(ValueError) as ctx:
+            resolve_ris_lab_config({"geometry": {"nx": 4}})
+        message = str(ctx.exception)
+        self.assertIn("geometry.ny", message)
+        self.assertIn("geometry.dx", message)
+        self.assertIn("geometry.dy", message)
+
+    def test_snapshot_writes_config_files_and_summary(self) -> None:
+        with tempfile.TemporaryDirectory() as tmpdir:
+            tmp_path = Path(tmpdir)
+            config_path = tmp_path / "ris.yaml"
+            yaml.safe_dump(
+                {
+                    "geometry": {"nx": 2, "ny": 2, "dx": 0.1, "dy": 0.2},
+                    "output": {"base_dir": tmpdir, "run_id": "unit-test"},
+                },
+                config_path.open("w", encoding="utf-8"),
+                sort_keys=False,
+            )
+
+            config, output_dir, summary = resolve_and_snapshot_ris_lab_config(config_path)
+            self.assertEqual(output_dir, tmp_path / "unit-test")
+            self.assertTrue((output_dir / "config.yaml").exists())
+            self.assertTrue((output_dir / "config.json").exists())
+            self.assertTrue((output_dir / "summary.json").exists())
+            self.assertEqual(summary["config"]["hash_sha256"], compute_ris_lab_config_hash(config))
+
+            loaded = json.loads((output_dir / "config.json").read_text(encoding="utf-8"))
+            self.assertEqual(loaded["geometry"]["nx"], 2)
+
+
+if __name__ == "__main__":
+    unittest.main()


thinking
**Committing updated run log**

I'm staging the updated run log file and preparing to commit with a message indicating a run log update; I plan to log the activity after the commit.
